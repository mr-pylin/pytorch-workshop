{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: space-between; align-items: center;\">\n",
    "    <div style=\"text-align: left; flex: 4\">\n",
    "        <strong>Author:</strong> Amirhossein Heydari ‚Äî \n",
    "        üìß <a href=\"mailto:amirhosseinheydari78@gmail.com\">amirhosseinheydari78@gmail.com</a> ‚Äî \n",
    "        üêô <a href=\"https://github.com/mr-pylin/pytorch-workshop\" target=\"_blank\" rel=\"noopener\">github.com/mr-pylin</a>\n",
    "    </div>\n",
    "    <div style=\"text-align: right; flex: 1;\">\n",
    "        <a href=\"https://pytorch.org/\" target=\"_blank\" rel=\"noopener noreferrer\">\n",
    "            <img src=\"../assets/images/pytorch/logo/pytorch-logo-dark.svg\" \n",
    "                 alt=\"PyTorch Logo\"\n",
    "                 style=\"max-height: 48px; width: auto; background-color: #ffffff; border-radius: 8px;\">\n",
    "        </a>\n",
    "    </div>\n",
    "</div>\n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Dependencies](#toc1_)    \n",
    "- [Pre-Processin Dataset](#toc2_)    \n",
    "  - [Create Artificial Dataset](#toc2_1_)    \n",
    "  - [Split dataset into trainset & testset](#toc2_2_)    \n",
    "  - [Normalization](#toc2_3_)    \n",
    "  - [Dataset](#toc2_4_)    \n",
    "  - [Dataloader](#toc2_5_)    \n",
    "- [Radial Basis Function Networks](#toc3_)    \n",
    "  - [Common Radial Basis Functions](#toc3_1_)    \n",
    "    - [Gaussian](#toc3_1_1_)    \n",
    "    - [Multiquadric](#toc3_1_2_)    \n",
    "    - [Inverse Multiquadric](#toc3_1_3_)    \n",
    "    - [Inverse Quadratic](#toc3_1_4_)    \n",
    "    - [Thin-Plate Spline](#toc3_1_5_)    \n",
    "    - [RBF Feature Mapping Visualization](#toc3_1_6_)    \n",
    "  - [RBF Networks](#toc3_2_)    \n",
    "    - [Single Layer Architecture](#toc3_2_1_)    \n",
    "    - [Multi Layers Architecture](#toc3_2_2_)    \n",
    "  - [Model Training Pipeline](#toc3_3_)    \n",
    "    - [Set up model and Hyperparameters](#toc3_3_1_)    \n",
    "    - [Train & Validation Loop](#toc3_3_2_)    \n",
    "    - [Test Loop](#toc3_3_3_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[Dependencies](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from IPython.display import HTML\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchinfo import summary\n",
    "from torchmetrics.classification import MulticlassAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# disable automatic figure display (plt.show() required)  \n",
    "# this ensures consistency with .py scripts and gives full control over when plots appear\n",
    "plt.ioff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose animation display method\n",
    "display_backend = FuncAnimation.to_html5_video if shutil.which(\"ffmpeg\") else FuncAnimation.to_jshtml\n",
    "display_backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set a seed for deterministic results\n",
    "seed = 0\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if cuda is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# log\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc2_'></a>[Pre-Processin Dataset](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_1_'></a>[Create Artificial Dataset](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a 2D classification dataset\n",
    "n_samples = 250\n",
    "n_classes = 3\n",
    "\n",
    "X, y = make_classification(\n",
    "    n_samples=n_samples,\n",
    "    n_features=2,\n",
    "    n_informative=2,\n",
    "    n_redundant=0,\n",
    "    n_classes=n_classes,\n",
    "    n_clusters_per_class=1,\n",
    "    random_state=seed,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_2_'></a>[Split dataset into trainset & testset](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_3_'></a>[Normalization](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# log\n",
    "print(f\"min of trainset: {X_train.min(axis=0)}\")\n",
    "print(f\"max of trainset: {X_train.max(axis=0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "plt.scatter(X_train[:, 0], X_train[:, 1], marker=\"o\", c=y_train, s=25, edgecolor=\"k\", label=\"trainset\")\n",
    "plt.scatter(X_test[:, 0], X_test[:, 1], marker=\",\", c=y_test, s=25, edgecolor=\"k\", label=\"testset\")\n",
    "plt.legend()\n",
    "plt.title(f\"2D dataset with {n_samples} samples\")\n",
    "plt.xlabel(\"feature 1\")\n",
    "plt.ylabel(\"feature 2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_4_'></a>[Dataset](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.int64)\n",
    "y_test = torch.tensor(y_test, dtype=torch.int64)\n",
    "\n",
    "trainset = TensorDataset(X_train, y_train)\n",
    "testset = TensorDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_5_'></a>[Dataloader](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "\n",
    "trainloader = DataLoader(dataset=trainset, batch_size=batch_size, shuffle=True)\n",
    "testloader = DataLoader(dataset=testset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc3_'></a>[Radial Basis Function Networks](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc3_1_'></a>[Common Radial Basis Functions](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc3_1_1_'></a>[Gaussian](#toc0_)\n",
    "\n",
    "$$\n",
    "\\phi(x) = e^{- \\frac{\\|x - c\\|^2}{2\\sigma^2}}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rbf_gaussian_multi(x: torch.Tensor, centers: torch.Tensor, sigma: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    x       : [num_samples, features]\n",
    "    centers : [num_centers, features]\n",
    "    sigma   : [num_centers] or scalar\n",
    "    returns : [num_samples, num_centers] RBF activations\n",
    "    \"\"\"\n",
    "\n",
    "    # compute pairwise distances [num_samples, num_centers]\n",
    "    dists = torch.cdist(x, centers)  # shape: [num_samples, num_centers]\n",
    "\n",
    "    # same as above code\n",
    "    # x_exp = x.unsqueeze(1)                             # [num_samples, 1, features]\n",
    "    # c_exp = centers.unsqueeze(0)                       # [1, num_centers, features]\n",
    "    # dists = ((x_exp - c_exp) ** 2).sum(dim=-1).sqrt()  # [num_samples, num_centers]\n",
    "\n",
    "    # make sigma broadcastable if it's a 1D tensor\n",
    "    if sigma.ndim == 1:\n",
    "        sigma = sigma.unsqueeze(0)  # shape [1, num_centers]\n",
    "\n",
    "    return torch.exp(-(dists**2) / (2 * sigma**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc3_1_2_'></a>[Multiquadric](#toc0_)\n",
    "\n",
    "$$\n",
    "\\phi(x) = \\sqrt{1 + (\\|x - c\\|/\\sigma)^2}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rbf_multiquadric_multi(x: torch.Tensor, centers: torch.Tensor, sigma: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    x       : [num_samples, features]\n",
    "    centers : [num_centers, features]\n",
    "    sigma   : [num_centers] or scalar\n",
    "    returns : [num_samples, num_centers] RBF activations\n",
    "    \"\"\"\n",
    "    dists = torch.cdist(x, centers)\n",
    "    if sigma.ndim == 1:\n",
    "        sigma = sigma.unsqueeze(0)\n",
    "    return torch.sqrt(1 + (dists / sigma) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc3_1_3_'></a>[Inverse Multiquadric](#toc0_)\n",
    "\n",
    "$$\n",
    "\\phi(x) = \\frac{1}{\\sqrt{1 + (\\|x - c\\|/\\sigma)^2}}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rbf_inverse_multiquadric_multi(x: torch.Tensor, centers: torch.Tensor, sigma: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    x       : [num_samples, features]\n",
    "    centers : [num_centers, features]\n",
    "    sigma   : [num_centers] or scalar\n",
    "    returns : [num_samples, num_centers] RBF activations\n",
    "    \"\"\"\n",
    "    dists = torch.cdist(x, centers)\n",
    "    if sigma.ndim == 1:\n",
    "        sigma = sigma.unsqueeze(0)\n",
    "    return 1.0 / torch.sqrt(1 + (dists / sigma) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc3_1_4_'></a>[Inverse Quadratic](#toc0_)\n",
    "\n",
    "$$\n",
    "\\phi(x) = \\frac{1}{1 + (\\|x - c\\|/\\sigma)^2}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rbf_inverse_quadratic_multi(x: torch.Tensor, centers: torch.Tensor, sigma: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    x       : [num_samples, features]\n",
    "    centers : [num_centers, features]\n",
    "    sigma   : [num_centers] or scalar\n",
    "    returns : [num_samples, num_centers] RBF activations\n",
    "    \"\"\"\n",
    "    dists = torch.cdist(x, centers)\n",
    "    if sigma.ndim == 1:\n",
    "        sigma = sigma.unsqueeze(0)\n",
    "    return 1.0 / (1 + (dists / sigma) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc3_1_5_'></a>[Thin-Plate Spline](#toc0_)\n",
    "\n",
    "$$\n",
    "\\phi(x) = \\|x - c\\|^2 \\log(\\|x - c\\|)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rbf_thin_plate_spline_multi(x: torch.Tensor, centers: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    x       : [num_samples, features]\n",
    "    centers : [num_centers, features]\n",
    "    returns : [num_samples, num_centers] RBF activations\n",
    "    \"\"\"\n",
    "    dists = torch.cdist(x, centers)\n",
    "    dists = torch.clamp(dists, min=1e-10)  # avoid log(0)\n",
    "    return dists**2 * torch.log(dists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc3_1_6_'></a>[RBF Feature Mapping Visualization](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define 2 centers for visualization\n",
    "centers = torch.tensor([[-0.5, 0.0], [0.5, 0.0]])\n",
    "sigma = torch.tensor([0.3, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of kernels and their corresponding multi-center functions\n",
    "kernels = [\n",
    "    (\"Gaussian\", rbf_gaussian_multi),\n",
    "    (\"Multiquadric\", rbf_multiquadric_multi),\n",
    "    (\"Inverse Multiquadric\", rbf_inverse_multiquadric_multi),\n",
    "    (\"Inverse Quadratic\", rbf_inverse_quadratic_multi),\n",
    "    (\"Thin-Plate Spline\", rbf_thin_plate_spline_multi),\n",
    "]\n",
    "\n",
    "n_cols = 1 + len(kernels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create figure with n_kernels columns\n",
    "fig, axes = plt.subplots(1, n_cols, figsize=(5 * n_cols, 4))\n",
    "\n",
    "# original input features\n",
    "axes[0].scatter(X_train[:, 0], X_train[:, 1], marker=\"o\", c=y_train, s=25, edgecolor=\"k\")\n",
    "axes[0].set_title(\"Original features\")\n",
    "axes[0].set_xlabel(\"x1\")\n",
    "axes[0].set_ylabel(\"x2\")\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# RBF feature spaces\n",
    "for i, (name, func) in enumerate(kernels, start=1):\n",
    "    if name == \"Thin-Plate Spline\":\n",
    "        phi = func(X_train, centers)\n",
    "    else:\n",
    "        phi = func(X_train, centers, sigma)\n",
    "    phi1, phi2 = phi[:, 0], phi[:, 1]\n",
    "    axes[i].scatter(phi1, phi2, marker=\"o\", c=y_train, s=25, edgecolor=\"k\")\n",
    "    axes[i].set_title(name)\n",
    "    axes[i].set_xlabel(\"phi1\")\n",
    "    axes[i].set_ylabel(\"phi2\")\n",
    "    axes[i].grid(alpha=0.3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc3_2_'></a>[RBF Networks](#toc0_)\n",
    "\n",
    "- Radial Basis Function (RBF) networks are a family of feed-forward models used for nonlinear function approximation.\n",
    "- They transform inputs using localized, distance-based activation functions such as Gaussian kernels.\n",
    "- The network output is formed by combining these transformed responses, enabling smooth interpolation and efficient learning.\n",
    "\n",
    "<div style=\"text-align: center; padding-top: 10px;\">\n",
    "    <img src=\"../assets/images/original/rbf/radial-basis-function-networks.svg\" alt=\"radial-basis-function-networks.svg\" style=\"min-width: 256px; max-width: 80%; height: auto; border-radius: 16px;\">\n",
    "    <p><em>Figure 1: Single-layer Radial Basis Function Network</em></p>\n",
    "</div>\n",
    "\n",
    "**RBF Parameters**:\n",
    "- The centers $\\mu_j$ of the radial units are typically selected using clustering methods such as K-Means, sampled directly from training data, or defined as learnable parameters during training.\n",
    "- The spread $\\sigma_j$ of each unit controls the width of the radial basis function and may be fixed heuristically, derived from cluster statistics, or optimized during training.\n",
    "- A common rule for assigning spreads uses the maximum pairwise distance among centers:\n",
    "  $$\n",
    "  \\sigma = \\frac{d_{\\text{max}}}{\\sqrt{2k}}\n",
    "  $$\n",
    "  where\n",
    "  - $d_{\\text{max}}$ is the largest Euclidean distance between any two centers,\n",
    "  - $k$ is the total number of radial basis units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RBFLayer(nn.Module):\n",
    "    def __init__(self, in_features: int, out_features: int, kernel: str = \"gaussian\"):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.centers = nn.Parameter(torch.Tensor(out_features, in_features))\n",
    "        self.sigmas = nn.Parameter(torch.Tensor(out_features))\n",
    "        self.kernel = kernel\n",
    "        self.reset_parameters()\n",
    "\n",
    "        # mapping kernel names to functions\n",
    "        self.rbf_functions = {\n",
    "            \"gaussian\": rbf_gaussian_multi,\n",
    "            \"multiquadric\": rbf_multiquadric_multi,\n",
    "            \"inverse_multiquadric\": rbf_inverse_multiquadric_multi,\n",
    "            \"inverse_quadratic\": rbf_inverse_quadratic_multi,\n",
    "            \"thin_plate_spline\": rbf_thin_plate_spline_multi,\n",
    "        }\n",
    "\n",
    "    def reset_parameters(self) -> None:\n",
    "        nn.init.uniform_(self.centers, -1.0, 1.0)\n",
    "        nn.init.uniform_(self.sigmas, 0.1, 1.0)  # avoid zero sigma\n",
    "\n",
    "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
    "        if self.kernel not in self.rbf_functions:\n",
    "            raise ValueError(f\"Unknown kernel type {self.kernel}\")\n",
    "\n",
    "        rbf_fn = self.rbf_functions[self.kernel]\n",
    "        return rbf_fn(input, self.centers, self.sigmas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc3_2_1_'></a>[Single Layer Architecture](#toc0_)\n",
    "\n",
    "- An RBF network with a **single hidden layer** transforms inputs using **radial basis functions (RBFs)** centered at learned prototypes.\n",
    "- Each hidden unit computes a **localized activation** based on the distance between the input and its center, most commonly via a Gaussian kernel.\n",
    "- The output layer forms a **linear combination** of these localized responses, enabling efficient approximation of nonlinear mappings with simple optimization.\n",
    "\n",
    "**Calculating the number of parameters**:\n",
    "\n",
    "<table style=\"margin: 0 auto; text-align:center;\">\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th colspan=\"2\">Hidden layer parameters</th>\n",
    "      <th colspan=\"2\">Output (logits) parameters</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td>Centers (Œº)</td>\n",
    "      <td>Widths (œÉ)</td>\n",
    "      <td>Weights</td>\n",
    "      <td>Biases</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>A √ó B</td>\n",
    "      <td>B</td>\n",
    "      <td>B √ó C</td>\n",
    "      <td>C</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "  <tfoot>\n",
    "    <tr>\n",
    "      <td colspan=\"2\">A √ó B + B</td>\n",
    "      <td colspan=\"2\">B √ó C + C</td>\n",
    "    </tr>\n",
    "  </tfoot>\n",
    "</table>\n",
    "\n",
    "- $A$: input dimensionality  \n",
    "- $B$: number of RBF kernels (hidden neurons)  \n",
    "- $C$: number of output neurons  \n",
    "\n",
    "---\n",
    "\n",
    "**Input matrix**:\n",
    "\n",
    "$$\n",
    "X =\n",
    "\\begin{bmatrix}\n",
    "x_{1}^1 & x_{1}^2 & \\cdots & x_{1}^N \\\\\n",
    "x_{2}^1 & x_{2}^2 & \\cdots & x_{2}^N \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "x_{Q}^1 & x_{Q}^2 & \\cdots & x_{Q}^N\n",
    "\\end{bmatrix}_{Q \\times N}\n",
    "$$\n",
    "\n",
    "- $Q$: number of samples  \n",
    "- $N$: number of input features  \n",
    "\n",
    "---\n",
    "\n",
    "**Hidden layer (RBF activations)**:\n",
    "\n",
    "$$\n",
    "\\phi(X) =\n",
    "\\begin{bmatrix}\n",
    "1 & 1 & \\cdots & 1 \\\\\n",
    "\\phi_1(X_1) & \\phi_1(X_2) & \\cdots & \\phi_1(X_Q) \\\\\n",
    "\\phi_2(X_1) & \\phi_2(X_2) & \\cdots & \\phi_2(X_Q) \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "\\phi_B(X_1) & \\phi_B(X_2) & \\cdots & \\phi_B(X_Q)\n",
    "\\end{bmatrix}_{(B+1) \\times Q}\n",
    "$$\n",
    "\n",
    "with Gaussian RBFs:\n",
    "\n",
    "$$\n",
    "\\phi_j(X_i) =\n",
    "\\exp\\left(\n",
    "-\\frac{\\lVert \\mathbf{X}_i - \\boldsymbol{\\mu}_j \\rVert^2}{2\\sigma_j^2}\n",
    "\\right)\n",
    "$$\n",
    "\n",
    "- The first row corresponds to the **bias term**.\n",
    "- Each RBF neuron responds strongly only to inputs **near its center**, enforcing locality.\n",
    "\n",
    "---\n",
    "\n",
    "**Output layer weights**:\n",
    "\n",
    "$$\n",
    "W =\n",
    "\\begin{bmatrix}\n",
    "w_{0}^1 & w_{0}^2 & \\cdots & w_{0}^{C} \\\\\n",
    "w_{1}^1 & w_{1}^2 & \\cdots & w_{1}^{C} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "w_{B}^1 & w_{B}^2 & \\cdots & w_{B}^{C}\n",
    "\\end{bmatrix}_{(B+1) \\times C}\n",
    "$$\n",
    "\n",
    "- $C$: number of output neurons (classes or regression targets)\n",
    "\n",
    "---\n",
    "\n",
    "**Network output**:\n",
    "\n",
    "$$\n",
    "f(X) = \\phi(X)^{\\top} W\n",
    "$$\n",
    "\n",
    "- The model is **linear in the output weights** and **nonlinear in the input space**.\n",
    "- This structure allows efficient training of $W$ using closed-form or standard linear optimization methods.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RBFNet(nn.Module):\n",
    "    def __init__(self, in_features: int, hidden_features: int, out_features: int, kernel: str = \"gaussian\"):\n",
    "        super().__init__()\n",
    "        self.rbf = RBFLayer(in_features, hidden_features, kernel)\n",
    "        self.linear = nn.Linear(hidden_features, out_features)\n",
    "\n",
    "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
    "        return self.linear(self.rbf(input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc3_2_2_'></a>[Multi Layers Architecture](#toc0_)\n",
    " \n",
    " \n",
    "- A multi-layer RBF network extends the classical single-hidden-layer design by **stacking multiple RBF-based hidden layers**.\n",
    "- Each hidden layer performs a **nonlinear, localized transformation** of its input space, enabling hierarchical feature extraction.\n",
    "- Deeper RBF architectures can model **more complex decision boundaries** with fewer kernels per layer compared to a shallow RBF network.\n",
    "\n",
    "<!-- <div style=\"text-align: center; padding-top: 10px;\">\n",
    "    <img src=\"../assets/images/original/rbf/multi-layer-rbf-network.svg\" alt=\"multi-layer-rbf-network.svg\" style=\"min-width: 256px; max-width: 80%; height: auto; border-radius: 16px;\">\n",
    "    <p><em>Figure 2: Multi-layer Radial Basis Function Network</em></p>\n",
    "</div> -->\n",
    "\n",
    "**Key idea**:\n",
    "\n",
    "- Instead of directly mapping inputs to outputs using a single RBF layer, intermediate RBF layers learn **progressively abstract representations**.\n",
    "- Each layer applies RBF transformations to the activations of the previous layer, not directly to raw input data.\n",
    "\n",
    "---\n",
    "\n",
    "**Layer-wise structure** (for $L$ hidden RBF layers):\n",
    "\n",
    "- Input layer: raw feature space $\\mathbb{R}^{N}$\n",
    "- Hidden layer $l$: $B_l$ RBF kernels with centers $\\mu^{(l)}_j$ and widths $\\sigma^{(l)}_j$\n",
    "- Output layer: linear combination of the final hidden layer activations\n",
    "\n",
    "---\n",
    "\n",
    "**First hidden layer activations**:\n",
    "\n",
    "$$\n",
    "\\phi^{(1)}(X) =\n",
    "\\begin{bmatrix}\n",
    "1 \\\\\n",
    "\\phi^{(1)}_1(X) \\\\\n",
    "\\phi^{(1)}_2(X) \\\\\n",
    "\\vdots \\\\\n",
    "\\phi^{(1)}_{B_1}(X)\n",
    "\\end{bmatrix}\n",
    "\\quad \\text{with} \\quad\n",
    "\\phi^{(1)}_j(X_i) =\n",
    "\\exp\\left(\n",
    "-\\frac{\\lVert \\mathbf{X}_i - \\boldsymbol{\\mu}^{(1)}_j \\rVert^2}{2(\\sigma^{(1)}_j)^2}\n",
    "\\right)\n",
    "$$\n",
    "\n",
    "- This layer behaves identically to a standard single-layer RBF network.\n",
    "- The output dimensionality is $B_1$.\n",
    "\n",
    "---\n",
    "\n",
    "**Intermediate hidden layer $l$ ($l > 1$)**:\n",
    "\n",
    "$$\n",
    "\\phi^{(l)}(X) =\n",
    "\\begin{bmatrix}\n",
    "1 \\\\\n",
    "\\phi^{(l)}_1(\\phi^{(l-1)}(X)) \\\\\n",
    "\\phi^{(l)}_2(\\phi^{(l-1)}(X)) \\\\\n",
    "\\vdots \\\\\n",
    "\\phi^{(l)}_{B_l}(\\phi^{(l-1)}(X))\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "with:\n",
    "\n",
    "$$\n",
    "\\phi^{(l)}_j(Z_i) =\n",
    "\\exp\\left(\n",
    "-\\frac{\\lVert \\mathbf{Z}_i - \\boldsymbol{\\mu}^{(l)}_j \\rVert^2}{2(\\sigma^{(l)}_j)^2}\n",
    "\\right),\n",
    "\\quad\n",
    "\\mathbf{Z}_i = \\phi^{(l-1)}(X_i)\n",
    "$$\n",
    "\n",
    "- Each layer measures distances **in the transformed feature space** produced by the previous layer.\n",
    "- Locality is preserved, but defined over increasingly abstract representations.\n",
    "\n",
    "---\n",
    "\n",
    "**Output layer**:\n",
    "\n",
    "$$\n",
    "f(X) = \\left(\\phi^{(L)}(X)\\right)^{\\top} W\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "- $\\phi^{(L)}(X) \\in \\mathbb{R}^{(B_L+1)}$\n",
    "- $W \\in \\mathbb{R}^{(B_L+1) \\times C}$\n",
    "\n",
    "---\n",
    "\n",
    "**Parameter count (overview)**:\n",
    "\n",
    "- Hidden layer $l$:\n",
    "  - Centers: $B_{l-1} \\times B_l$\n",
    "  - Widths: $B_l$\n",
    "- Output layer:\n",
    "  - Weights: $B_L \\times C$\n",
    "  - Biases: $C$\n",
    "\n",
    "Total parameters grow **linearly with depth** and **quadratically with layer widths**, making careful layer-size selection important.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLayerRBFNet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_features: int,\n",
    "        hidden_features: list[int],\n",
    "        out_features: int,\n",
    "        kernels: list[str] | None = None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        in_features     : number of input features\n",
    "        hidden_features : list of hidden neurons per RBF layer, e.g., [64, 32]\n",
    "        out_features    : number of output neurons\n",
    "        kernels         : list of kernel names per layer, default all \"gaussian\"\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.num_layers = len(hidden_features)\n",
    "        if kernels is None:\n",
    "            kernels = [\"gaussian\"] * self.num_layers\n",
    "        assert len(kernels) == self.num_layers, \"kernels list must match hidden_features length\"\n",
    "\n",
    "        # create list of RBF layers\n",
    "        layers = []\n",
    "        prev_features = in_features\n",
    "        for size, kernel in zip(hidden_features, kernels):\n",
    "            layers.append(RBFLayer(prev_features, size, kernel))\n",
    "            prev_features = size\n",
    "        self.rbf_layers = nn.ModuleList(layers)\n",
    "\n",
    "        # final linear layer\n",
    "        self.linear = nn.Linear(prev_features, out_features)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        for layer in self.rbf_layers:\n",
    "            x = layer(x)\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc3_3_'></a>[Model Training Pipeline](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc3_3_1_'></a>[Set up model and Hyperparameters](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input/output sizes\n",
    "in_features = trainset[0][0].shape[0]  # automatically from dataset\n",
    "hidden_features = 3                    # number of RBF kernels\n",
    "out_features = n_classes               # number of output classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the model\n",
    "model = RBFNet(in_features, hidden_features, out_features).to(device)\n",
    "\n",
    "# log\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model, input_size=(batch_size, in_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training hyperparameters\n",
    "lr = 0.01\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(params=model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc3_3_2_'></a>[Train & Validation Loop](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store accuracy and loss at each epoch\n",
    "train_acc_per_epoch = []\n",
    "train_loss_per_epoch = []\n",
    "train_acc = MulticlassAccuracy(num_classes=n_classes, top_k=1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store RBF layer parameters at each epoch\n",
    "centers_history = []\n",
    "sigmas_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "\n",
    "    for x, y in trainloader:\n",
    "        x, y_true = x.to(device), y.to(device)\n",
    "\n",
    "        # forward + loss\n",
    "        y_pred = model(x)\n",
    "        loss = criterion(y_pred, y_true)\n",
    "\n",
    "        # backward\n",
    "        loss.backward()\n",
    "\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # store loss and accuracy per iteration\n",
    "        train_loss += loss.item() * len(x)\n",
    "        train_acc.update(y_pred, y_true)\n",
    "\n",
    "    # store metrics per epoch\n",
    "    train_loss_per_epoch.append(train_loss / len(trainset))\n",
    "    train_acc_per_epoch.append(train_acc.compute().item())\n",
    "    train_acc.reset()\n",
    "\n",
    "    # store current centers and sigmas per epoch\n",
    "    centers_history.append(model.rbf.centers.detach().cpu().clone())\n",
    "    sigmas_history.append(model.rbf.sigmas.detach().cpu().clone())\n",
    "\n",
    "    # log\n",
    "    print(\n",
    "        f\"epoch {epoch+1:0{len(str(num_epochs))}}/{num_epochs} -> \"\n",
    "        f\"train[loss: {train_loss_per_epoch[-1]:7.5f} - acc: {train_acc_per_epoch[-1]*100:5.2f}%]\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_frame(epoch_idx, centers_history, sigmas_history, X_train, y_train, X_test, y_test):\n",
    "    plt.clf()\n",
    "    centers = centers_history[epoch_idx].numpy()\n",
    "    sigmas = sigmas_history[epoch_idx].numpy()\n",
    "\n",
    "    plt.scatter(X_train[:, 0], X_train[:, 1], marker=\"o\", c=y_train, s=25, edgecolor=\"k\", label=\"trainset\")\n",
    "    plt.scatter(X_test[:, 0], X_test[:, 1], marker=\",\", c=y_test, s=25, edgecolor=\"k\", label=\"testset\")\n",
    "\n",
    "    for center, radius in zip(centers, sigmas):\n",
    "        circle = plt.Circle(center, radius, color=\"b\", fill=False)\n",
    "        plt.gca().add_artist(circle)\n",
    "\n",
    "    plt.title(f\"Epoch {epoch_idx + 1}\")\n",
    "    plt.xlabel(\"feature 1\")\n",
    "    plt.ylabel(\"feature 2\")\n",
    "    plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6,6))\n",
    "\n",
    "anim = FuncAnimation(\n",
    "    fig,\n",
    "    lambda i: plot_frame(i, centers_history, sigmas_history, X_train, y_train, X_test, y_test),\n",
    "    frames=len(centers_history),\n",
    "    interval=500\n",
    ")\n",
    "\n",
    "# choose backend depending on ffmpeg availability\n",
    "HTML(display_backend(anim))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc3_3_3_'></a>[Test Loop](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = MulticlassAccuracy(num_classes=n_classes, top_k=1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test loop\n",
    "model.eval()\n",
    "test_loss = 0\n",
    "predictions = []\n",
    "targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y in testloader:\n",
    "\n",
    "        # send data to GPU\n",
    "        x, y_true = x.to(device), y.to(device)\n",
    "\n",
    "        # forward\n",
    "        y_pred = model(x)\n",
    "        loss = criterion(y_pred, y_true)\n",
    "\n",
    "        # store loss and accuracy per iteration\n",
    "        test_loss += loss.item() * len(x)\n",
    "        test_acc.update(y_pred, y_true)\n",
    "\n",
    "        predictions.extend(y_pred.argmax(dim=1).cpu())\n",
    "        targets.extend(y_true.cpu())\n",
    "\n",
    "# log\n",
    "print(f\"test[loss: {test_loss / len(testset):.5f} - acc: {test_acc.compute().item()*100:5.2f}%]\")"
   ]
  }
 ],
 "metadata": {
  "author_email": "AmirhosseinHeydari78@gmail.com",
  "author_github": "https://github.com/mr-pylin",
  "author_name": "Amirhossein Heydari",
  "kernelspec": {
   "display_name": "pytorch-workshop (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  },
  "origin_repo": "https://github.com/mr-pylin/pytorch-workshop"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
