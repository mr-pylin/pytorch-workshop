{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìù **Author:** Amirhossein Heydari - üìß **Email:** <amirhosseinheydari78@gmail.com> - üìç **Origin:** [mr-pylin/pytorch-workshop](https://github.com/mr-pylin/pytorch-workshop)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Dependencies](#toc1_)    \n",
    "- [Metric](#toc2_)    \n",
    "  - [Built-in Metrics](#toc2_1_)    \n",
    "    - [Classification Tasks](#toc2_1_1_)    \n",
    "    - [Regression Tasks](#toc2_1_2_)    \n",
    "  - [Custom Metrics](#toc2_2_)    \n",
    "    - [Example 1: Custom Accuracy](#toc2_2_1_)    \n",
    "    - [Example 2: Attack Success Rate](#toc2_2_2_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[Dependencies](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchmetrics import Metric\n",
    "from torchmetrics.classification import (\n",
    "    MulticlassAccuracy,\n",
    "    MulticlassAUROC,\n",
    "    MulticlassConfusionMatrix,\n",
    "    MulticlassF1Score,\n",
    "    MulticlassPrecision,\n",
    "    MulticlassRecall,\n",
    "    MulticlassROC,\n",
    ")\n",
    "from torchmetrics.regression import (\n",
    "    CosineSimilarity,\n",
    "    MeanAbsoluteError,\n",
    "    MeanAbsolutePercentageError,\n",
    "    MeanSquaredError,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set a seed for deterministic results\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc2_'></a>[Metric](#toc0_)\n",
    "\n",
    "- **Metrics** evaluate model performance by computing key statistics such as **accuracy**, **precision**, **recall**, and **loss**.  \n",
    "- `torchmetrics` provides a **modular** and **efficient** way to compute metrics for **PyTorch** models.  \n",
    "- It supports both **batch-wise computation** and **distributed training** (e.g., multi-GPU).  \n",
    "\n",
    "üõ† **Using Metrics**:\n",
    "\n",
    "- Metrics in `torchmetrics` are subclasses of `torch.nn.Module` and can be used just like any other PyTorch module.  \n",
    "- They should be updated with each batch and `compute()` should be called at the end of an epoch.  \n",
    "\n",
    "üìù **Docs**:\n",
    "\n",
    "- Welcome to TorchMetrics: [lightning.ai/docs/torchmetrics/stable/](https://lightning.ai/docs/torchmetrics/stable/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_1_'></a>[Built-in Metrics](#toc0_)\n",
    "\n",
    "- `torchmetrics` provides several built-in metrics for tasks like **classification**, **regression**, **clustering**, **detection**, **segmentation**, ... .  \n",
    "- These metrics are optimized for **PyTorch** and support **GPU acceleration** and **distributed training**.\n",
    "\n",
    "üõ† **Common Built-in Metrics**:\n",
    "\n",
    "<table style=\"width: 48%; float: left; margin-right: 2%;\">\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th>Task</th>\n",
    "      <th>Metric</th>\n",
    "      <th>Description</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td rowspan=\"7\">Classification</td>\n",
    "      <td style=\"font-family: monospace;\">Accuracy()</td>\n",
    "      <td>Correct predictions ratio</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td style=\"font-family: monospace;\">Precision()</td>\n",
    "      <td>TP / (TP + FP)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td style=\"font-family: monospace;\">Recall()</td>\n",
    "      <td>TP / (TP + FN)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td style=\"font-family: monospace;\">F1Score()</td>\n",
    "      <td>Harmonic mean of precision & recall</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td style=\"font-family: monospace;\">AUROC()</td>\n",
    "      <td>ROC curve AUC</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td style=\"font-family: monospace;\">ROC()</td>\n",
    "      <td>Receiver Operating Characteristic curve</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td style=\"font-family: monospace;\">ConfusionMatrix()</td>\n",
    "      <td>Tabular summary of predictions</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "    <tr>\n",
    "      <td rowspan=\"2\">Detection</td>\n",
    "      <td style=\"font-family: monospace;\">MeanAveragePrecision()</td>\n",
    "      <td>mAP for object detection</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td style=\"font-family: monospace;\">IntersectionOverUnion()</td>\n",
    "      <td>IoU metric for object detection</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "<table style=\"width: 48%; float: left;\">\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th>Task</th>\n",
    "      <th>Metric</th>\n",
    "      <th>Description</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td rowspan=\"4\">Regression</td>\n",
    "      <td style=\"font-family: monospace;\">MeanSquaredError()</td>\n",
    "      <td>Avg. squared error</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td style=\"font-family: monospace;\">MeanAbsoluteError()</td>\n",
    "      <td>Avg. absolute error</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td style=\"font-family: monospace;\">CosineSimilarity()</td>\n",
    "      <td>Measure of angle similarity</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td style=\"font-family: monospace;\">MeanAbsolutePercentageError()</td>\n",
    "      <td>Mean absolute percentage error</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td rowspan=\"3\">Clustering</td>\n",
    "      <td style=\"font-family: monospace;\">AdjustedRandScore()</td>\n",
    "      <td>Similarity of clusters</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td style=\"font-family: monospace;\">RandScore()</td>\n",
    "      <td>Random clustering similarity</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td style=\"font-family: monospace;\">FowlkesMallowsIndex()</td>\n",
    "      <td>Precision-recall similarity</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td rowspan=\"2\">Segmentation</td>\n",
    "      <td style=\"font-family: monospace;\">Dice()</td>\n",
    "      <td>Dice coefficient (F1 score)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td style=\"font-family: monospace;\">MeanIoU()</td>\n",
    "      <td>Avg. IoU across classes</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "üìù **Docs**:\n",
    "\n",
    "- All TorchMetrics: [lightning.ai/docs/torchmetrics/stable/all-metrics.html](https://lightning.ai/docs/torchmetrics/stable/all-metrics.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc2_1_1_'></a>[Classification Tasks](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load iris dataset\n",
    "iris_df = pd.read_csv(\n",
    "    r\"https://raw.githubusercontent.com/mr-pylin/datasets/refs/heads/main/data/tabular-data/iris/dataset.csv\",\n",
    "    encoding=\"utf-8\",\n",
    ")\n",
    "\n",
    "# meta-data\n",
    "classes = iris_df[\"class\"].unique()\n",
    "class_to_idx = {l: i for i, l in enumerate(classes)}\n",
    "\n",
    "# split dataset into features & labels\n",
    "X, y = iris_df.iloc[:, :4].values, iris_df.iloc[:, 4].values\n",
    "y = np.array([class_to_idx[l] for l in y])\n",
    "\n",
    "# convert numpy.ndarray to torch.Tensor\n",
    "X = torch.from_numpy(X.astype(np.float32))\n",
    "y = torch.from_numpy(y.astype(np.int64))\n",
    "\n",
    "# create DataLoader\n",
    "dataset = TensorDataset(X, y)\n",
    "dataloader = DataLoader(dataset, batch_size=15, shuffle=True)\n",
    "\n",
    "# log\n",
    "print(f\"X.shape             : {X.shape}\")\n",
    "print(f\"X.dtype             : {X.dtype}\")\n",
    "print(f\"y.shape             : {y.shape}\")\n",
    "print(f\"y.dtype             : {y.dtype}\")\n",
    "print(f\"len(dataset)        : {len(dataset)}\")\n",
    "print(f\"dataset[0][0].shape : {dataset[0][0].shape}\")\n",
    "print(f\"dataset[0][1].shape : {dataset[0][1].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a simple model\n",
    "model = nn.Linear(X.shape[1], len(classes))\n",
    "\n",
    "# criterion and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.1)\n",
    "\n",
    "# log\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize metrics\n",
    "accuracy = MulticlassAccuracy(len(classes), top_k=1)\n",
    "recall = MulticlassRecall(len(classes), top_k=1, average=None)\n",
    "precision = MulticlassPrecision(len(classes), top_k=1, average=None)\n",
    "f1_score = MulticlassF1Score(len(classes), top_k=1, average=None)\n",
    "roc = MulticlassROC(len(classes), average=None)\n",
    "auroc = MulticlassAUROC(len(classes), average=None)\n",
    "confusion_matrix = MulticlassConfusionMatrix(len(classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop\n",
    "epochs = 1\n",
    "for epoch in range(epochs):\n",
    "    for batch_idx, (x, y_true) in enumerate(dataloader):\n",
    "\n",
    "        y_pred = model(x)\n",
    "\n",
    "        loss = criterion(y_pred, y_true)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # update metrics\n",
    "        accuracy.update(y_pred, y_true)\n",
    "        recall.update(y_pred, y_true)\n",
    "        precision.update(y_pred, y_true)\n",
    "        f1_score.update(y_pred, y_true)\n",
    "        roc.update(y_pred, y_true)\n",
    "        auroc.update(y_pred, y_true)\n",
    "        confusion_matrix.update(y_pred, y_true)\n",
    "\n",
    "    # log\n",
    "    print(f\"epoch {epoch+1}/{epochs}\")\n",
    "    print(f\"  -> accuracy  : {accuracy.compute():.4f}\")\n",
    "    print(f\"  -> recall    : {recall.compute()}\")\n",
    "    print(f\"  -> precision : {precision.compute()}\")\n",
    "    print(f\"  -> f1 score  : {f1_score.compute()}\")\n",
    "    print(f\"  -> auroc     : {auroc.compute()}\")\n",
    "    print(f\"  -> confusion matrix:\\n{confusion_matrix.compute()}\")\n",
    "\n",
    "    # plot ROC curve [for each class]\n",
    "    fpr, tpr, _ = roc.compute()\n",
    "    fig, axs = plt.subplots(nrows=1, ncols=len(classes), figsize=(len(classes) * 4, len(classes)), layout=\"compressed\")\n",
    "    fig.suptitle(\"Area Under ROC (One-vs-Rest Approach)\")\n",
    "    for i in range(len(classes)):\n",
    "        axs[i].plot(fpr[i], tpr[i], color=\"blue\")\n",
    "        axs[i].set(xlabel=\"FPR\", ylabel=\"TPR\", title=f\"Class {i}\")\n",
    "    plt.show()\n",
    "\n",
    "    # reset metrics for next epoch\n",
    "    accuracy.reset()\n",
    "    recall.reset()\n",
    "    precision.reset()\n",
    "    f1_score.reset()\n",
    "    roc.reset()\n",
    "    auroc.reset()\n",
    "    confusion_matrix.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc2_1_2_'></a>[Regression Tasks](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load boston dataset\n",
    "boston_df = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/mr-pylin/datasets/refs/heads/main/data/tabular-data/boston-housing/dataset.csv\",\n",
    "    encoding=\"utf-8\",\n",
    ")\n",
    "\n",
    "X = torch.tensor(boston_df.drop(columns=[\"MEDV\"]).values, dtype=torch.float32)\n",
    "y = torch.tensor(boston_df[\"MEDV\"].values, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# create DataLoader\n",
    "dataset = TensorDataset(X, y)\n",
    "dataloader = DataLoader(dataset, batch_size=15, shuffle=True)\n",
    "\n",
    "# log\n",
    "print(f\"X.shape             : {X.shape}\")\n",
    "print(f\"X.dtype             : {X.dtype}\")\n",
    "print(f\"y.shape             : {y.shape}\")\n",
    "print(f\"y.dtype             : {y.dtype}\")\n",
    "print(f\"len(dataset)        : {len(dataset)}\")\n",
    "print(f\"dataset[0][0].shape : {dataset[0][0].shape}\")\n",
    "print(f\"dataset[0][1].shape : {dataset[0][1].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a simple model\n",
    "num_output = 1\n",
    "model = nn.Linear(X.shape[1], num_output)\n",
    "\n",
    "# criterion and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.1)\n",
    "\n",
    "# log\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize metrics\n",
    "mae = MeanAbsoluteError()\n",
    "mse = MeanSquaredError()\n",
    "cs = CosineSimilarity()\n",
    "mape = MeanAbsolutePercentageError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop\n",
    "epochs = 1\n",
    "for epoch in range(epochs):\n",
    "    for batch_idx, (x, y_true) in enumerate(dataloader):\n",
    "\n",
    "        y_pred = model(x)\n",
    "\n",
    "        loss = criterion(y_pred, y_true)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # update metrics\n",
    "        mae.update(y_pred, y_true)\n",
    "        mse.update(y_pred, y_true)\n",
    "        cs.update(y_pred, y_true)\n",
    "        mape.update(y_pred, y_true)\n",
    "\n",
    "    # log\n",
    "    print(f\"epoch {epoch+1}/{epochs}\")\n",
    "    print(f\"  -> mae  : {mae.compute():.4f}\")\n",
    "    print(f\"  -> mse  : {mse.compute():.4f}\")\n",
    "    print(f\"  -> cs   : {cs.compute():.4f}\")\n",
    "    print(f\"  -> mape : {mape.compute():.4f}\")\n",
    "\n",
    "    # reset metrics for next epoch\n",
    "    mae.reset()\n",
    "    mse.reset()\n",
    "    cs.reset()\n",
    "    mape.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_2_'></a>[Custom Metrics](#toc0_)\n",
    "\n",
    "- `torchmetrics` allows defining **custom metrics** by subclassing `torchmetrics.Metric`.  \n",
    "- Custom metrics provide flexibility to compute **task-specific** evaluation criteria.  \n",
    "- They support **automatic accumulation** across batches and **distributed computation**.\n",
    "\n",
    "üõ† **Creating a Custom Metric**:\n",
    "\n",
    "- **Inherit** from `torchmetrics.Metric`.  \n",
    "- **Define internal states** using `self.add_state()`.  \n",
    "- **Implement `update()`** to process batch-level data.  \n",
    "- **Implement `compute()`** to aggregate results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc2_2_1_'></a>[Example 1: Custom Accuracy](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomAccuracy(Metric):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # add state variables to track the number of correct predictions and total predictions\n",
    "        self.add_state(\"correct\", default=torch.tensor(0), dist_reduce_fx=\"sum\")\n",
    "        self.add_state(\"total\", default=torch.tensor(0), dist_reduce_fx=\"sum\")\n",
    "\n",
    "    def update(self, preds: torch.Tensor, target: torch.Tensor):\n",
    "        # assuming preds are logits or probabilities, apply argmax for predicted classes\n",
    "        preds = preds.argmax(dim=1)\n",
    "\n",
    "        # update the correct and total counters\n",
    "        self.correct += (preds == target).sum()\n",
    "        self.total += target.size(0)\n",
    "\n",
    "    def compute(self):\n",
    "        return self.correct.float() / self.total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc2_2_2_'></a>[Example 2: Attack Success Rate](#toc0_)\n",
    "\n",
    "‚ÑπÔ∏è **Learn more**:\n",
    "\n",
    "- BadNets: Identifying Vulnerabilities in the Machine Learning Model Supply Chain [[ **pdf** ](https://arxiv.org/pdf/1708.06733)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttackSuccessRate(Metric):\n",
    "    def __init__(self, target_index: int):\n",
    "        super().__init__()\n",
    "        self.target_class = target_index\n",
    "        self.add_state(\"success\", default=torch.tensor(0), dist_reduce_fx=\"sum\")\n",
    "        self.add_state(\"total\", default=torch.tensor(0), dist_reduce_fx=\"sum\")\n",
    "\n",
    "    def update(self, preds: torch.Tensor, poison_mask: torch.Tensor | None) -> None:\n",
    "\n",
    "        if poison_mask is not None:\n",
    "            preds = preds[poison_mask]\n",
    "\n",
    "        preds = preds.argmax(dim=-1)\n",
    "\n",
    "        self.success += (preds == self.target_class).sum()\n",
    "        self.total += len(preds)\n",
    "\n",
    "    def compute(self) -> torch.Tensor:\n",
    "        return self.success.float() / self.total"
   ]
  }
 ],
 "metadata": {
  "author_email": "AmirhosseinHeydari78@gmail.com",
  "author_github": "https://github.com/mr-pylin",
  "author_name": "Amirhossein Heydari",
  "kernelspec": {
   "display_name": "pytorch-workshop (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  },
  "origin_repo": "https://github.com/mr-pylin/pytorch-workshop"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}