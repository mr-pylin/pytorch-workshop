{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìù **Author:** Amirhossein Heydari - üìß **Email:** <amirhosseinheydari78@gmail.com> - üìç **Origin:** [mr-pylin/pytorch-workshop](https://github.com/mr-pylin/pytorch-workshop)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Dependencies](#toc1_)    \n",
    "- [Dataset](#toc2_)    \n",
    "  - [Load Iris Dataset](#toc2_1_)    \n",
    "- [Torch Dataset](#toc3_)    \n",
    "- [Torch DataLoader](#toc4_)    \n",
    "  - [Strategies for updating weights](#toc4_1_)    \n",
    "    - [Batch Gradient Descent](#toc4_1_1_)    \n",
    "    - [Stochastic Gradient Descent](#toc4_1_2_)    \n",
    "    - [Mini-Batch Gradient Descent](#toc4_1_3_)    \n",
    "- [Available Datasets in PyTorch](#toc5_)    \n",
    "  - [Torchvision Built-in Datasets](#toc5_1_)    \n",
    "  - [Torchaudio Built-in Datasets](#toc5_2_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[Dependencies](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchaudio.datasets import YESNO\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms.v2 import ToImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update paths as needed based on your project structure\n",
    "MNIST_DIR = r\"../../datasets\"\n",
    "YESNO_DIR = r\"../../datasets\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc2_'></a>[Dataset](#toc0_)\n",
    "\n",
    "$\n",
    "X = \\begin{bmatrix}\n",
    "        x_{1}^1 & x_{1}^2 & \\cdots & x_{1}^n \\\\\n",
    "        x_{2}^1 & x_{2}^2 & \\cdots & x_{2}^n \\\\\n",
    "        \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "        x_{m}^1 & x_{m}^2 & \\cdots & x_{m}^n \\\\\n",
    "    \\end{bmatrix}_{m \\times n} \\quad \\text{(m: number of samples, n: number of features)}\n",
    "$\n",
    "\n",
    "$\n",
    "Y = \\begin{bmatrix}\n",
    "        y_{1} \\\\\n",
    "        y_{2} \\\\\n",
    "        \\vdots \\\\\n",
    "        y_{m} \\\\\n",
    "    \\end{bmatrix}_{m \\times 1} \\quad \\text{(m: number of samples)}\n",
    "$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_1_'></a>[Load Iris Dataset](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_dataset_url = r\"https://raw.githubusercontent.com/mr-pylin/datasets/refs/heads/main/data/tabular-data/iris/dataset.csv\"\n",
    "\n",
    "# pandas data-frame\n",
    "df = pd.read_csv(iris_dataset_url, encoding=\"utf-8\")\n",
    "\n",
    "# log\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = df[\"class\"].unique()\n",
    "class_to_idx = {l: i for i, l in enumerate(classes)}\n",
    "\n",
    "# split dataset into features and labels\n",
    "X, y = df.iloc[:, :4].values, df.iloc[:, 4].values\n",
    "\n",
    "# convert categorical labels into indices\n",
    "y = np.array([class_to_idx[l] for l in y])\n",
    "\n",
    "# properties of the dataset\n",
    "num_samples, num_features = X.shape\n",
    "classes, samples_per_class = np.unique(y, return_counts=True)\n",
    "\n",
    "# log\n",
    "print(f\"X.shape: {X.shape}\")\n",
    "print(f\"X.dtype: {X.dtype}\")\n",
    "print(f\"y.shape: {y.shape}\")\n",
    "print(f\"y.dtype: {y.dtype}\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"classes          : {classes}\")\n",
    "print(f\"samples per class: {samples_per_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert numpy.ndarray to torch.Tensor\n",
    "X = torch.from_numpy(X.astype(np.float32))\n",
    "y = torch.from_numpy(y.astype(np.float32)).view(-1, 1)\n",
    "\n",
    "# log\n",
    "print(f\"x.shape: {X.shape}\")\n",
    "print(f\"x.dtype: {X.dtype}\")\n",
    "print(f\"x.ndim : {X.ndim}\\n\")\n",
    "print(f\"y.shape: {y.shape}\")\n",
    "print(f\"y.dtype: {y.dtype}\")\n",
    "print(f\"y.ndim : {y.ndim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc3_'></a>[Torch Dataset](#toc0_)\n",
    "\n",
    "- It's designed to store and manage tensor-based datasets.\n",
    "- DataLoaders in PyTorch specifically require a tensor-based Dataset.\n",
    "- `torch.utils.data.TensorDataset` is indeed a subclass of the `torch.utils.data.Dataset` class in PyTorch.\n",
    "- To build highly customizable and versatile datasets, refer to [**custom-classes.ipynb**](./custom-classes.ipynb) notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a torch dataset\n",
    "dataset = TensorDataset(X, y)\n",
    "\n",
    "# log\n",
    "print(f\"dataset.tensors[0].shape : {dataset.tensors[0].shape}\")\n",
    "print(f\"dataset.tensors[1].shape : {dataset.tensors[1].shape}\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"first sample:\")\n",
    "print(f\"    -> X: {dataset[0][0]}\")\n",
    "print(f\"    -> y: {dataset[0][1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc4_'></a>[Torch DataLoader](#toc0_)\n",
    "\n",
    "- A DataLoader(`torch.utils.data.DataLoader`) is a utility for training and evaluation in deep learning tasks that enables:\n",
    "  - efficient loading datasets\n",
    "  - handling batching\n",
    "  - shuffling\n",
    "  - parallel data loading\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc4_1_'></a>[Strategies for updating weights](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc4_1_1_'></a>[Batch Gradient Descent](#toc0_)\n",
    "\n",
    "- Uses the **entire** dataset to compute the **gradient** of the loss function and **update** the **weights**.\n",
    "- **Pros**: Provides a stable convergence.\n",
    "- **Cons**: Can be very slow and computationally expensive for large datasets.\n",
    "\n",
    "üåü **Example**:\n",
    "\n",
    "| #Epoch | batch size | #batch per epoch                    | #iteration per epoch                |\n",
    "|:------:|:----------:|:-----------------------------------:|:-----------------------------------:|\n",
    "| $ 2 $  | $ 150 $    | $ \\lceil\\frac{150}{150}\\rceil = 1 $ | $ \\lceil\\frac{150}{150}\\rceil = 1 $ |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2\n",
    "batch_size = dataset.tensors[0].shape[0]\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "# log\n",
    "for epoch in range(epochs):\n",
    "    print(f\"epoch {epoch+1:0{len(str(epochs))}}/{epochs}\")\n",
    "    for i, (x, y) in enumerate(dataloader):\n",
    "        print(f\"    iteration {i}\")\n",
    "        print(f\"        x.shape: {x.shape}\")\n",
    "        print(f\"        y.shape: {y.shape}\")\n",
    "        print(\"    weights are updated.\")\n",
    "    print(f\"model saw the entire dataset.\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc4_1_2_'></a>[Stochastic Gradient Descent](#toc0_)\n",
    "\n",
    "- the model **updates** the **weights** using only **one data point** at a time.\n",
    "- **Pros**: Faster updates and can escape local minima.\n",
    "- **Cons**: Can be noisy and may not converge as smoothly as batch gradient descent.\n",
    "\n",
    "üåü **Example**:\n",
    "\n",
    "| #Epoch | batch size | #batch per epoch                    | #iteration per epoch                |\n",
    "|:------:|:----------:|:-----------------------------------:|:-----------------------------------:|\n",
    "| $ 2 $  | $ 1 $      | $ \\lceil\\frac{150}{1}\\rceil = 150 $ | $ \\lceil\\frac{150}{1}\\rceil = 150 $ |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2\n",
    "batch_size = 1\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "# log\n",
    "for epoch in range(epochs):\n",
    "    print(f\"epoch {epoch+1:0{len(str(epochs))}}/{epochs}\")\n",
    "    for i, (x, y) in enumerate(dataloader):\n",
    "        if i % 25 == 0 or i == len(X) - 1:\n",
    "            print(f\"    iteration {i}\")\n",
    "            print(f\"        x.shape: {x.shape}\")\n",
    "            print(f\"        y.shape: {y.shape}\")\n",
    "            print(\"    weights are updated.\")\n",
    "    print(f\"model saw the entire dataset.\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc4_1_3_'></a>[Mini-Batch Gradient Descent](#toc0_)\n",
    "\n",
    "- the model updates its weights after processing a small batch of 'm' samples from the training dataset.\n",
    "- this method combines the advantages of both SGD and Batch Gradient Descent by providing a balance between efficiency and stability during training.\n",
    "\n",
    "üåü **Example**:\n",
    "\n",
    "| #Epoch | batch size | #batch                             | #iteration per epoch               |\n",
    "|:------:|:----------:|:----------------------------------:|:----------------------------------:|\n",
    "| $ 2 $  | $ 32 $     | $ \\lceil\\frac{150}{32}\\rceil = 5 $ | #batch                             |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2\n",
    "batch_size = 32\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "# log\n",
    "for epoch in range(epochs):\n",
    "    print(f\"epoch {epoch+1:0{len(str(epochs))}}/{epochs}\")\n",
    "    for i, (x, y) in enumerate(dataloader):\n",
    "        print(f\"    iteration {i}\")\n",
    "        print(f\"        x.shape: {x.shape}\")\n",
    "        print(f\"        y.shape: {y.shape}\")\n",
    "        print(\"    weights are updated.\")\n",
    "    print(f\"model saw the entire dataset.\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc5_'></a>[Available Datasets in PyTorch](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc5_1_'></a>[Torchvision Built-in Datasets](#toc0_)\n",
    "\n",
    "- Torchvision provides many built-in datasets in the `torchvision.datasets` module, as well as utility classes for building your own datasets.\n",
    "- **Categories of built-in datasets**:\n",
    "  - Image classification\n",
    "  - Image Detection or Segmentation\n",
    "  - Optical Flow\n",
    "  - Stereo Matching\n",
    "  - Image pairs\n",
    "  - Image captioning\n",
    "  - Video classification\n",
    "  - Video prediction\n",
    "\n",
    "üìù **Docs**:\n",
    "\n",
    "- Datasets: [pytorch.org/vision/stable/datasets.html](https://pytorch.org/vision/stable/datasets.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_dataset = MNIST(MNIST_DIR, train=True, transform=ToImage(), download=False)\n",
    "\n",
    "# log\n",
    "print(f\"len(mnist_dataset)        : {len(mnist_dataset)}\")\n",
    "print(f\"mnist_dataset[0][0].shape : {mnist_dataset[0][0].shape}\")\n",
    "print(f\"mnist_dataset[0][0].dtype : {mnist_dataset[0][0].dtype}\")\n",
    "print(f\"classes                   : {mnist_dataset.classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_loader = DataLoader(mnist_dataset, batch_size=64, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc5_2_'></a>[Torchaudio Built-in Datasets](#toc0_)\n",
    "\n",
    "- Torchaudio provides several built-in datasets in the `torchaudio.datasets` module.\n",
    "\n",
    "\n",
    "üìù **Docs**:\n",
    "\n",
    "- Datasets: [pytorch.org/audio/stable/datasets.html](https://pytorch.org/audio/stable/datasets.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yesno_dataset = YESNO(YESNO_DIR, download=False)\n",
    "\n",
    "# log\n",
    "print(f\"len(yesno_dataset)        : {len(yesno_dataset)}\")\n",
    "print(f\"yesno_dataset[0][0].shape : {yesno_dataset[0][0].shape}\")\n",
    "print(f\"yesno_dataset[0][0].dtype : {yesno_dataset[0][0].dtype}\")\n",
    "print(f\"sample_rate               : {yesno_dataset[0][1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "yesno_loader = DataLoader(yesno_dataset, batch_size=4, shuffle=True, num_workers=2)"
   ]
  }
 ],
 "metadata": {
  "author_email": "AmirhosseinHeydari78@gmail.com",
  "author_github": "https://github.com/mr-pylin",
  "author_name": "Amirhossein Heydari",
  "kernelspec": {
   "display_name": "pytorch-workshop-U_zYfVTd-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "origin_repo": "https://github.com/mr-pylin/pytorch-workshop"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
