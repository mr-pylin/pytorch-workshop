{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìù **Author:** Amirhossein Heydari - üìß **Email:** <amirhosseinheydari78@gmail.com> - üìç **Origin:** [mr-pylin/pytorch-workshop](https://github.com/mr-pylin/pytorch-workshop)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Dependencies](#toc1_)    \n",
    "- [Consider An Initialized Model As Trained](#toc2_)    \n",
    "- [Save & Load](#toc3_)    \n",
    "    - [Save and Load ONLY Parameters](#toc3_1_1_)    \n",
    "    - [Save & Load the ENTIRE Model](#toc3_1_2_)    \n",
    "    - [Saving & Loading a General Checkpoint for Inference and/or Resuming Training](#toc3_1_3_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[Dependencies](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set a seed for deterministic results\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_DIR = Path(\"../../assets/checkpoints/models\")\n",
    "CHECKPOINT_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc2_'></a>[Consider An Initialized Model As Trained](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = nn.Sequential(\n",
    "    nn.Linear(4, 2),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(2, 1),\n",
    "    nn.Sigmoid(),\n",
    ")\n",
    "\n",
    "# log\n",
    "print(trained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(trained_model, input_size=(16, 4), device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights and biases per layer (using model.parameters())\n",
    "for i, param in enumerate(trained_model.parameters()):\n",
    "    if i % 2 == 0:  # weights of the model\n",
    "        print(str(param).replace(\"Parameter containing:\", f\"weights (layer {i // 2 + 1}):\"), end=\"\\n\\n\")\n",
    "    else:  # biases of the model\n",
    "        print(str(param).replace(\"Parameter containing:\", f\"biases (layer {(i-1) // 2 + 1}):\"), end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights and biases per layer (using model.state_dict())\n",
    "for param in trained_model.state_dict().items():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc3_'></a>[Save & Load](#toc0_)\n",
    "\n",
    "- The extension `.pth` has no specific meaning to PyTorch internally.\n",
    "- `.pth` (or sometimes `.pt`) is used conventionally to indicate the file contains a PyTorch model or parameters.\n",
    "\n",
    "üìù **Docs & Tutorials** üìö:\n",
    "\n",
    "- torch.save: [docs.pytorch.org/docs/stable/generated/torch.save.html](https://docs.pytorch.org/docs/stable/generated/torch.save.html)\n",
    "- torch.load: [docs.pytorch.org/docs/stable/generated/torch.load.html](https://docs.pytorch.org/docs/stable/generated/torch.load.html)\n",
    "- Saving and Loading Models: [pytorch.org/tutorials/beginner/saving_loading_models.html](https://pytorch.org/tutorials/beginner/saving_loading_models.html)\n",
    "- Save and Load the Model: [pytorch.org/tutorials/beginner/basics/saveloadrun_tutorial.html](https://pytorch.org/tutorials/beginner/basics/saveloadrun_tutorial.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc3_1_1_'></a>[Save and Load ONLY Parameters](#toc0_)\n",
    "\n",
    "- This is the recommended approach.\n",
    "- Model architecture can be defined separately and changed without issues\n",
    "- Efficient for saving memory and storage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get model parameters\n",
    "trained_model_parameters = trained_model.state_dict()\n",
    "\n",
    "# save\n",
    "torch.save(obj=trained_model_parameters, f=f\"{CHECKPOINT_DIR}/model_1.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load\n",
    "weights = torch.load(f=f\"{CHECKPOINT_DIR}/model_1.pth\", weights_only=True)\n",
    "\n",
    "# log\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert weights to the model\n",
    "model_1 = nn.Sequential(nn.Linear(4, 2), nn.Sigmoid(), nn.Linear(2, 1), nn.Sigmoid())\n",
    "\n",
    "model_1.load_state_dict(weights)\n",
    "\n",
    "# log\n",
    "for param in model_1.state_dict().items():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc3_1_2_'></a>[Save & Load the ENTIRE Model](#toc0_)\n",
    "\n",
    "- ‚úÖ Easier to use since you don‚Äôt need to redefine the model architecture.\n",
    "- ‚ö†Ô∏è Not portable across different PyTorch versions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "torch.save(obj=trained_model, f=f\"{CHECKPOINT_DIR}/model_2.pth\")\n",
    "\n",
    "# load\n",
    "model_2 = torch.load(f=f\"{CHECKPOINT_DIR}/model_2.pth\", weights_only=False)\n",
    "\n",
    "# log\n",
    "model_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log\n",
    "for param in model_2.state_dict().items():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc3_1_3_'></a>[Saving & Loading a General Checkpoint for Inference and/or Resuming Training](#toc0_)\n",
    "\n",
    "- you can save a checkpoint whenever you are training the model at each epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 10\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(params=trained_model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save both model and optimizer state_dict for resuming training\n",
    "torch.save(\n",
    "    obj={\n",
    "        \"model_state_dict\": trained_model.state_dict(),\n",
    "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "        \"epoch\": epoch,  # Save the epoch to resume training\n",
    "        \"criterion\": criterion,  # Optional, save the last loss\n",
    "    },\n",
    "    f=f\"{CHECKPOINT_DIR}/model_3.pth\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the checkpoint\n",
    "checkpoint = torch.load(f\"{CHECKPOINT_DIR}/model_3.pth\", weights_only=False)\n",
    "\n",
    "# model\n",
    "model_3 = nn.Sequential(nn.Linear(4, 2), nn.Sigmoid(), nn.Linear(2, 1), nn.Sigmoid())\n",
    "\n",
    "# optimizer\n",
    "optimizer = optim.SGD(model_3.parameters(), lr=0.01)\n",
    "\n",
    "# insert values\n",
    "model_3.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "criterion = checkpoint[\"criterion\"]\n",
    "epoch = checkpoint[\"epoch\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log\n",
    "for param in model_3.state_dict().items():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log\n",
    "print(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log\n",
    "print(f\"epoch : {epoch}\")"
   ]
  }
 ],
 "metadata": {
  "author_email": "AmirhosseinHeydari78@gmail.com",
  "author_github": "https://github.com/mr-pylin",
  "author_name": "Amirhossein Heydari",
  "kernelspec": {
   "display_name": "pytorch-workshop (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  },
  "origin_repo": "https://github.com/mr-pylin/pytorch-workshop"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}