{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "üìù **Author:** Amirhossein Heydari - üìß **Email:** <amirhosseinheydari78@gmail.com> - üìç **Origin:** [mr-pylin/media-processing-workshop](https://github.com/mr-pylin/media-processing-workshop)\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Table of contents**<a id='toc0_'></a>    \n",
        "- [Dependencies](#toc1_)    \n",
        "- [Signals and Systems](#toc2_)    \n",
        "  - [Linear Time-Invariant (LTI) Systems](#toc2_1_)    \n",
        "    - [Convolution](#toc2_1_1_)    \n",
        "      - [Circular Convolution](#toc2_1_1_1_)    \n",
        "      - [Separable Convolution](#toc2_1_1_2_)    \n",
        "  - [Cross-Correlation](#toc2_2_)    \n",
        "  - [Examples](#toc2_3_)    \n",
        "    - [1D Convolution](#toc2_3_1_)    \n",
        "      - [Manual](#toc2_3_1_1_)    \n",
        "      - [Using NumPy](#toc2_3_1_2_)    \n",
        "      - [Using SciPy](#toc2_3_1_3_)    \n",
        "    - [2D Convolution](#toc2_3_2_)    \n",
        "      - [Manual](#toc2_3_2_1_)    \n",
        "      - [Using OpenCV](#toc2_3_2_2_)    \n",
        "      - [Using SciPy](#toc2_3_2_3_)    \n",
        "    - [Separable Convolution](#toc2_3_3_)    \n",
        "      - [Manual](#toc2_3_3_1_)    \n",
        "      - [Using OpenCV](#toc2_3_3_2_)    \n",
        "    - [2D Cross-Correlation](#toc2_3_4_)    \n",
        "      - [Using SciPy](#toc2_3_4_1_)    \n",
        "\n",
        "<!-- vscode-jupyter-toc-config\n",
        "\tnumbering=false\n",
        "\tanchor=true\n",
        "\tflat=false\n",
        "\tminLevel=1\n",
        "\tmaxLevel=6\n",
        "\t/vscode-jupyter-toc-config -->\n",
        "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# <a id='toc1_'></a>[Dependencies](#toc0_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "from numpy.typing import NDArray"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# <a id='toc2_'></a>[Signals and Systems](#toc0_)\n",
        "\n",
        "- A **signal** is a function that conveys information about the behavior or attributes of a **physical phenomenon**.\n",
        "  - **Continuous-time**: $x(t)$, defined for every instant of time.\n",
        "  - **Discrete-time**: $x[n]$, defined only at specific instants of time.\n",
        "- A **system** is an entity that processes an input signal to produce an output signal.\n",
        "  - **Continuous-time**:\n",
        "    $$y(t) = T\\{x(t)\\}$$\n",
        "  - **Discrete-time**:\n",
        "    $$y[n] = T\\{x[n]\\}$$\n",
        "\n",
        "<figure style=\"text-align:center; margin:0;\">\n",
        "  <img src=\"../../assets/images/original/vector/lti/signal-and-system.svg\" alt=\"signal-and-system.svg\" style=\"max-width:80%; height:auto;\">\n",
        "  <figcaption>Signals and Systems</figcaption>\n",
        "</figure>\n",
        "\n",
        "üìã **Properties of Systems:**\n",
        "\n",
        "1. **Linearity**: A system is linear if it satisfies the **superposition principle**:\n",
        "   $$T\\{a x_1(t) + b x_2(t)\\} = a T\\{x_1(t)\\} + b T\\{x_2(t)\\}$$\n",
        "1. **Time-Invariance**: A system is time-invariant if a time shift in the **input** results in the same time shift in the **output**:\n",
        "   $$y(t - t_0) = T\\{x(t - t_0)\\}$$\n",
        "1. **Causality**: A system is causal if the **output** at any time $\\mathbf{t}$ depends only on the input at the **present** and **past** times, **not future** times.\n",
        "1. **Stability**: A system is stable if bounded inputs produce bounded outputs (**BIBO stability**).\n",
        "1. **Memory**: A system is **memoryless** if the output at any time $\\mathbf{t}$ depends only on the input at the same time $\\mathbf{t}$.\n",
        "\n",
        "üìù **Docs**:\n",
        "\n",
        "- Signal processing: [en.wikipedia.org/wiki/Signal_processing](https://en.wikipedia.org/wiki/Signal_processing)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## <a id='toc2_1_'></a>[Linear Time-Invariant (LTI) Systems](#toc0_)\n",
        "\n",
        "- An **LTI** system is a system that is both **linear** and **time-invariant**.\n",
        "- The **impulse response** of an LTI system is the output of the system when the input is an **impulse**:\n",
        "  - For **continuous-time systems**:\n",
        "    $$h(t) = T\\{\\delta(t)\\}$$\n",
        "  - For **discrete-time systems**:\n",
        "    $$h[n] = T\\{\\delta[n]\\}$$\n",
        "\n",
        "<figure style=\"text-align:center; margin:0;\">\n",
        "  <img src=\"../../assets/images/original/vector/lti/impulse.svg\" alt=\"impulse.svg\" style=\"max-width:80%; height:auto;\">\n",
        "  <figcaption>Impulse Signal</figcaption>\n",
        "</figure>\n",
        "\n",
        "- The impulse response $\\mathbf{h(t)}$ or $\\mathbf{h[n]}$ completely characterizes an LTI system.\n",
        "- Once the **impulse response** is known, the **output** for **any input** can be computed using **Convolution**.\n",
        "\n",
        "<figure style=\"text-align:center; margin:0;\">\n",
        "  <img src=\"../../assets/images/original/vector/lti/lti-system.svg\" alt=\"lti-system.svg\" style=\"max-width:80%; height:auto;\">\n",
        "  <figcaption>Linear Time-Invariant Systems</figcaption>\n",
        "</figure>\n",
        "\n",
        "‚ùì **Example:**\n",
        "\n",
        "- $h[n] = \\{1, 2, 1\\}$\n",
        "- $x[n] = \\{1, 2\\}$\n",
        "- $y[n] = ?$\n",
        "\n",
        "<figure style=\"text-align:center; margin:0;\">\n",
        "  <img src=\"../../assets/images/original/vector/lti/lti-example.svg\" alt=\"lti-example.svg\" style=\"max-width:100%; height:auto;\">\n",
        "  <figcaption>Linear Time-Invariant Systems Example</figcaption>\n",
        "</figure>\n",
        "\n",
        "üìù **Docs**:\n",
        "\n",
        "- Linear time-invariant system: [en.wikipedia.org/wiki/Linear_time-invariant_system](https://en.wikipedia.org/wiki/Linear_time-invariant_system)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <a id='toc2_1_1_'></a>[Convolution](#toc0_)\n",
        "\n",
        "- Convolution is a mathematical operation that **combines** two functions to produce a third function.\n",
        "- For **LTI** systems, convolution is used to compute the **output** of the system given the **input** and the **impulse response**.\n",
        "- **Continuous-Time Convolution**\n",
        "  - For continuous-time LTI systems, the output $\\mathbf{y(t)}$ is the convolution of the input $\\mathbf{x(t)}$ and the impulse response $\\mathbf{h(t)}$:\n",
        "  $$y(t) = x(t) * h(t) = \\int_{-\\infty}^{\\infty} x(\\tau) h(t - \\tau) \\, d\\tau$$\n",
        "  - This **integral** represents the superposition of **scaled** and **shifted** versions of the **impulse response**.\n",
        "- **Discrete-Time Convolution**\n",
        "  - For discrete-time LTI systems, the output $\\mathbf{y[n]}$ is the convolution of the input $\\mathbf{x[n]}$ and the impulse response $\\mathbf{h[n]}$:\n",
        "  $$y[n] = x[n] * h[n] = \\sum_{k=-\\infty}^{\\infty} x[k] h[n - k]$$\n",
        "  - This **sum** represents the weighted **sum** of **shifted** versions of the **impulse response**.\n",
        "\n",
        "‚ùì **Example:**\n",
        "\n",
        "- $h[n] = \\{1, 2, 1\\}$\n",
        "- $x[n] = \\{1, 2\\}$\n",
        "- $y[n] = ?$\n",
        "\n",
        "<figure style=\"text-align:center; margin:0;\">\n",
        "  <img src=\"../../assets/images/original/vector/lti/convolution-kernel-flip.svg\" alt=\"convolution-kernel-flip.svg\" style=\"max-width:100%; height:auto;\">\n",
        "  <figcaption>Convolution (flipped kernel)</figcaption>\n",
        "</figure>\n",
        "\n",
        "üìã **Properties of Convolution:**\n",
        "\n",
        "1. **Commutativity**:\n",
        "    $$x[n] * h[n] = h[n] * x[n]$$\n",
        "1. **Associativity**:\n",
        "    $$(x(t) * h_1(t)) * h_2(t) = x(t) * (h_1(t) * h_2(t))$$\n",
        "1. **Distributivity**:\n",
        "    $$x(t) * (h_1(t) + h_2(t)) = x(t) * h_1(t) + x(t) * h_2(t)$$\n",
        "1. **Identity**:\n",
        "    $$x(t) * \\delta(t) = x(t)$$\n",
        "\n",
        "üìù **Docs**:\n",
        "\n",
        "- Convolution: [en.wikipedia.org/wiki/Convolution](https://en.wikipedia.org/wiki/Convolution)\n",
        "- `numpy.convolve`: [numpy.org/doc/2.1/reference/generated/numpy.convolve.html](https://numpy.org/doc/2.1/reference/generated/numpy.convolve.html)\n",
        "- `scipy.signal`: [docs.scipy.org/doc/scipy/reference/signal.html](https://docs.scipy.org/doc/scipy/reference/signal.html)\n",
        "- `cv2.filter2D`: [docs.opencv.org/master/d4/d86/group__imgproc__filter.html#ga27c049795ce870216ddfb366086b5a04](https://docs.opencv.org/master/d4/d86/group__imgproc__filter.html#ga27c049795ce870216ddfb366086b5a04)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### <a id='toc2_1_1_1_'></a>[Circular Convolution](#toc0_)\n",
        "\n",
        "- Circular convolution is a special type of convolution where the input signals are assumed to be **periodic**.\n",
        "- For two discrete signals $\\mathbf{x[n]}$ and $\\mathbf{h[n]}$ of length $\\mathbf{N}$, the circular convolution is defined as:\n",
        "\n",
        "$$y[n] = \\sum_{m=0}^{N-1} x[m] h[(n - m) \\mod N]$$\n",
        "\n",
        "- The result is another **finite-length** sequence of the **same length** as the **inputs**.\n",
        "\n",
        "<figure style=\"text-align:center; margin:0;\">\n",
        "  <img src=\"../../assets/images/original/vector/lti/circular-convolution.svg\" alt=\"circular-convolution.svg\" style=\"max-width:100%; height:auto;\">\n",
        "  <figcaption>Circular Convolution</figcaption>\n",
        "</figure>\n",
        "\n",
        "- It is particularly important in the context of **Fourier transforms**, as **convolution** in the **time domain** corresponds to **multiplication** in the **frequency domain**:\n",
        "\n",
        "$$\\mathcal{F}\\{x[n] * h[n]\\} = X(\\omega) \\cdot H(\\omega)$$\n",
        "$$\\mathcal{F}\\{x[n] \\cdot h[n]\\} = X(\\omega) * H(\\omega)$$\n",
        "\n",
        "üÜö **Circular vs. Linear Convolution**:\n",
        "\n",
        "- **Linear Convolution**: Used for finite non-periodic signals. $\\text{length} = N+M‚àí1$.\n",
        "- **Circular Convolution**: Assumes periodicity. $\\text{length} = max(N,M)$.\n",
        "- **Key Insight**: Circular convolution **wraps around overlapping parts**, while linear convolution **zero-pads**.\n",
        "\n",
        "ü§ö **Avoiding Wrap-Around Artifacts**:\n",
        "\n",
        "- To compute **linear convolution** using **DFT**:\n",
        "  - Zero-pad both sequences to length $N+M‚àí1$.\n",
        "  - Perform circular convolution on the padded sequences.\n",
        "\n",
        "<figure style=\"text-align:center; margin:0;\">\n",
        "  <img src=\"../../assets/images/original/vector/lti/linear-vs-circular-convolution.svg\" alt=\"linear-vs-circular-convolution.svg\" style=\"max-width:90%; height:auto;\">\n",
        "  <figcaption>Linear vs. Circular Convolution</figcaption>\n",
        "</figure>\n",
        "\n",
        "üî¢ **Matrix Representation (Circulant Matrix)**:\n",
        "\n",
        "- Circular convolution can be represented as multiplication by a **circulant matrix**.\n",
        "- For $h=[h_0‚Äã,h_1‚Äã,h_2‚Äã]$:\n",
        "\n",
        "$$\n",
        "\\begin{bmatrix}\n",
        "h_0 & h_2 & h_1 \\\\\n",
        "h_1 & h_0 & h_2 \\\\\n",
        "h_2 & h_1 & h_0 \\\\\n",
        "\\end{bmatrix}\n",
        "\\begin{bmatrix}\n",
        "x_1 \\\\\n",
        "x_2 \\\\\n",
        "x_3 \\\\\n",
        "\\end{bmatrix}\n",
        "=\n",
        "\\begin{bmatrix}\n",
        "y_1 \\\\\n",
        "y_2 \\\\\n",
        "y_3 \\\\\n",
        "\\end{bmatrix}\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### <a id='toc2_1_1_2_'></a>[Separable Convolution](#toc0_)\n",
        "\n",
        "- Separable convolution is a technique used to **reduce computation** when applying **2D** convolution filters.\n",
        "- A convolution kernel $\\mathbf{K}$ is **separable** if it can be **decomposed** into the **outer product** of two **1D kernels** (its matrix has **Rank 1**):\n",
        "- This is closely related to Singular Value Decomposition (SVD), as discussed in [**linalg-basics**](./02-linalg-basics.ipynb) notebook.\n",
        "\n",
        "\\begin{aligned}\n",
        "K &= k_c \\otimes k_r \\\\\n",
        "&\\text{where } k_r \\text{ is a 1D row filter and } k_c \\text{ is a 1D column filter.}\n",
        "\\end{aligned}\n",
        "\n",
        "- Instead of performing a full 2D convolution, we can apply a **row-wise** convolution first, followed by a **column-wise** convolution.\n",
        "\n",
        "$$\n",
        "(I * K)_{m,n} = \\sum_{i,j} I_{m-i, n-j} K_{i,j} \n",
        "= \\sum_i k_c[i] \\sum_j k_r[j] I_{m-i, n-j} \n",
        "= \\big((I * k_r) * k_c \\big)_{m,n}\n",
        "$$\n",
        "\n",
        "- Here, **1D convolutions** are applied sequentially:  \n",
        "   1. **Row-wise:**  \n",
        "   $$\n",
        "   (I * k_r)_{m,n} = \\sum_j k_r[j] I_{m,n-j}\n",
        "   $$\n",
        "\n",
        "   2. **Column-wise:**  \n",
        "   $$\n",
        "   ((I * k_r) * k_c)_{m,n} = \\sum_i k_c[i] (I * k_r)_{m-i,n}\n",
        "   $$\n",
        "\n",
        "- This reduces complexity from $\\mathcal{O}(n^2 k^2)$ to $\\mathcal{O}(n^2 k) + \\mathcal{O}(n^2 k) = \\mathcal{O}(2n^2 k)$ per dimension.\n",
        "\n",
        "‚úçÔ∏è **Example**:\n",
        "\n",
        "$$\n",
        "S_x = \n",
        "\\begin{bmatrix}\n",
        "1 & 0 & -1 \\\\\n",
        "2 & 0 & -2 \\\\\n",
        "1 & 0 & -1\n",
        "\\end{bmatrix} \n",
        "= \n",
        "\\underbrace{\\begin{bmatrix} 1 \\\\ 2 \\\\ 1 \\end{bmatrix}}_{k_c} \n",
        "\\cdot \n",
        "\\underbrace{\\begin{bmatrix} 1 & 0 & -1 \\end{bmatrix}}_{k_r}\n",
        "$$\n",
        "\n",
        "For $k = 3$:\n",
        "\n",
        "$$\n",
        "1 - \\frac{2}{3} \\approx 33.3\\% \\text{ reduction in operations.}\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## <a id='toc2_2_'></a>[Cross-Correlation](#toc0_)\n",
        "\n",
        "- It measures the **similarity** between two signals.\n",
        "- It is closely related to convolution, but unlike convolution, cross-correlation **DOES NOT** flip the kernel.\n",
        "- This makes cross-correlation particularly useful in applications like **template matching**, **signal alignment**, and **feature detection**.\n",
        "\n",
        "$$y[n] = \\sum_{k} x[k] \\cdot h[k + n]$$\n",
        "$$y[i, j] = \\sum_{m} \\sum_{n} x[m, n] \\cdot h[m + i, n + j]$$\n",
        "\n",
        "<figure style=\"text-align:center; margin:0;\">\n",
        "  <img src=\"../../assets/images/original/vector/lti/convolution-vs-correlation.svg\" alt=\"convolution-vs-correlation.svg\" style=\"max-width:80%; height:auto;\">\n",
        "  <figcaption>Convolution vs. Cross-Correlation</figcaption>\n",
        "</figure>\n",
        "\n",
        "üìù **Docs**:\n",
        "\n",
        "- Cross-correlation: [en.wikipedia.org/wiki/Cross-correlation](https://en.wikipedia.org/wiki/Cross-correlation)\n",
        "- `scipy.signal`: [docs.scipy.org/doc/scipy/reference/signal.html](https://docs.scipy.org/doc/scipy/reference/signal.html)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## <a id='toc2_3_'></a>[Examples](#toc0_)\n",
        "\n",
        "‚úçÔ∏è **Note on Padding in Convolutions:**  \n",
        "\n",
        "- In convolution operations, we often apply different types of padding:  \n",
        "  - **Padding modes:** e.g., `constant`, `reflect`, `replicate`, etc.  \n",
        "  - **Padding strategies:** e.g., `same` (output same size as input), `valid` (no padding), `full` (output larger than input).  \n",
        "- These affect how the convolution handles image borders and can influence the results of filtering operations.  \n",
        "- For a detailed explanation and examples of these padding types, refer to the [**padding**](../utils/padding.ipynb) notebook.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <a id='toc2_3_1_'></a>[1D Convolution](#toc0_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "signal_1d = np.array([0, 1, 2, 3, 4, 5, 4, 3, 2, 1, 0], dtype=np.float32)\n",
        "filter_1d = np.array([1, 0, -1], dtype=np.float32)\n",
        "\n",
        "# log\n",
        "print(f\"signal_1d:\\n{signal_1d}\\n\")\n",
        "print(f\"filter_1d:\\n{filter_1d}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### <a id='toc2_3_1_1_'></a>[Manual](#toc0_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def conv1d(signal: NDArray, kernel: NDArray) -> NDArray:\n",
        "    signal_len = len(signal)\n",
        "    kernel_len = len(kernel)\n",
        "    output_len = signal_len + kernel_len - 1  # full convolution length\n",
        "\n",
        "    kernel = kernel[::-1]\n",
        "    padded_signal = np.pad(signal, (kernel_len - 1, kernel_len - 1), mode=\"constant\")\n",
        "    result = np.array([np.sum(padded_signal[i : i + kernel_len] * kernel) for i in range(output_len)])\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "signal_1d_conv_1 = conv1d(signal_1d, filter_1d)\n",
        "\n",
        "# plot\n",
        "titles = [\"Input\", \"Filter\", \"Full\"]\n",
        "signals = [signal_1d, filter_1d, signal_1d_conv_1]\n",
        "fig, axes = plt.subplots(1, 3, figsize=(12, 3), layout=\"compressed\", sharex=True, sharey=True)\n",
        "for col, (ax, title, data) in enumerate(zip(axes, titles, signals)):\n",
        "    ax.stem(data, basefmt=\" \")\n",
        "    ax.set_title(title)\n",
        "    ax.grid(True, linewidth=0.5, linestyle=\"--\", color=\"gray\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### <a id='toc2_3_1_2_'></a>[Using NumPy](#toc0_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "signal_1d_conv_2 = np.convolve(signal_1d, filter_1d, mode=\"valid\")\n",
        "signal_1d_conv_3 = np.convolve(signal_1d, filter_1d, mode=\"same\")\n",
        "signal_1d_conv_4 = np.convolve(signal_1d, filter_1d, mode=\"full\")\n",
        "\n",
        "# plot\n",
        "titles = [\"Input\", \"Filter\", \"Valid\", \"Same\", \"Full\"]\n",
        "signals = [signal_1d, filter_1d, signal_1d_conv_2, signal_1d_conv_3, signal_1d_conv_4]\n",
        "fig, axes = plt.subplots(1, 5, figsize=(24, 3), layout=\"compressed\", sharex=True, sharey=True)\n",
        "for col, (ax, title, data) in enumerate(zip(axes, titles, signals)):\n",
        "    ax.stem(data, basefmt=\" \")\n",
        "    ax.set_title(title)\n",
        "    ax.grid(True, linewidth=0.5, linestyle=\"--\", color=\"gray\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### <a id='toc2_3_1_3_'></a>[Using SciPy](#toc0_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "signal_1d_conv_5 = sp.signal.convolve(signal_1d, filter_1d, mode=\"valid\")\n",
        "signal_1d_conv_6 = sp.signal.convolve(signal_1d, filter_1d, mode=\"same\")\n",
        "signal_1d_conv_7 = sp.signal.convolve(signal_1d, filter_1d, mode=\"full\")\n",
        "\n",
        "# plot\n",
        "titles = [\"Input\", \"Filter\", \"Valid\", \"Same\", \"Full\"]\n",
        "signals = [signal_1d, filter_1d, signal_1d_conv_5, signal_1d_conv_6, signal_1d_conv_7]\n",
        "fig, axes = plt.subplots(1, 5, figsize=(20, 3), layout=\"compressed\", sharex=True, sharey=True)\n",
        "for col, (ax, title, data) in enumerate(zip(axes, titles, signals)):\n",
        "    ax.stem(data, basefmt=\" \")\n",
        "    ax.set_title(title)\n",
        "    ax.grid(True, linewidth=0.5, linestyle=\"--\", color=\"gray\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <a id='toc2_3_2_'></a>[2D Convolution](#toc0_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "signal_2d = np.array([[1, 2, 3], [2, 1, 1], [3, 1, 2]], dtype=np.float32)\n",
        "filter_2d = np.array([[3, 1, 2], [1, 2, 1], [3, 1, 1]], dtype=np.float32)\n",
        "\n",
        "# log\n",
        "print(f\"signal_2d:\\n{signal_2d}\\n\")\n",
        "print(f\"filter_2d:\\n{filter_2d}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### <a id='toc2_3_2_1_'></a>[Manual](#toc0_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def conv2d(image: NDArray, kernel: NDArray) -> NDArray:\n",
        "    image_h, image_w = image.shape\n",
        "    kernel_h, kernel_w = kernel.shape\n",
        "    output_h = image_h + kernel_h - 1  # full convolution height\n",
        "    output_w = image_w + kernel_w - 1  # full convolution width\n",
        "    kernel = np.flipud(np.fliplr(kernel))\n",
        "\n",
        "    # pad the image with zeros\n",
        "    pad_h, pad_w = kernel_h - 1, kernel_w - 1\n",
        "    padded_image = np.pad(image, ((pad_h, pad_h), (pad_w, pad_w)), mode=\"constant\", constant_values=0)\n",
        "\n",
        "    # compute convolution\n",
        "    result = np.zeros((output_h, output_w))\n",
        "    for i in range(output_h):\n",
        "        for j in range(output_w):\n",
        "            result[i, j] = np.sum(padded_image[i : i + kernel_h, j : j + kernel_w] * kernel)\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "signal_2d_conv_1 = conv2d(signal_2d, filter_2d)\n",
        "\n",
        "# plot\n",
        "signals = [signal_2d, filter_2d, signal_2d_conv_1]\n",
        "titles = [\"signal_2d\", \"filter_2d\", \"signal_2d_conv_1\"]\n",
        "fig, axes = plt.subplots(1, 3, figsize=(9, 3), layout=\"compressed\")\n",
        "for ax, signal, title in zip(axes, signals, titles):\n",
        "    ax.imshow(signal, cmap=\"gray\")\n",
        "    ax.set(title=title, xticks=range(signal.shape[1]), yticks=range(signal.shape[0]))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### <a id='toc2_3_2_2_'></a>[Using OpenCV](#toc0_)\n",
        "\n",
        "- It performs convolution operations using the **same** mode by default.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "kernel_h, kernel_w = filter_2d.shape\n",
        "pad_h, pad_w = kernel_h - 1 - 1, kernel_w - 1 - 1\n",
        "signal_2d_padded = cv2.copyMakeBorder(signal_2d, pad_h, pad_h, pad_w, pad_w, borderType=cv2.BORDER_CONSTANT, value=0)\n",
        "filter_2d_flip = np.flipud(np.fliplr(filter_2d))\n",
        "signal_2d_conv_2 = cv2.filter2D(signal_2d_padded, ddepth=-1, kernel=filter_2d_flip, borderType=cv2.BORDER_CONSTANT)\n",
        "\n",
        "# plot\n",
        "signals = [signal_2d, filter_2d, signal_2d_conv_2]\n",
        "titles = [\"signal_2d\", \"filter_2d\", \"signal_2d_conv_2\"]\n",
        "fig, axes = plt.subplots(1, 3, figsize=(9, 3), layout=\"compressed\")\n",
        "for ax, signal, title in zip(axes, signals, titles):\n",
        "    ax.imshow(signal, cmap=\"gray\")\n",
        "    ax.set(title=title, xticks=range(signal.shape[1]), yticks=range(signal.shape[0]))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### <a id='toc2_3_2_3_'></a>[Using SciPy](#toc0_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "signal_2d_conv_3 = sp.signal.convolve2d(signal_2d, filter_2d, mode=\"full\", boundary=\"fill\", fillvalue=0)\n",
        "\n",
        "# plot\n",
        "signals = [signal_2d, filter_2d, signal_2d_conv_3]\n",
        "titles = [\"signal_2d\", \"filter_2d\", \"signal_2d_conv_3\"]\n",
        "fig, axes = plt.subplots(1, 3, figsize=(9, 3), layout=\"compressed\")\n",
        "for ax, signal, title in zip(axes, signals, titles):\n",
        "    ax.imshow(signal, cmap=\"gray\")\n",
        "    ax.set(title=title, xticks=range(signal.shape[1]), yticks=range(signal.shape[0]))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <a id='toc2_3_3_'></a>[Separable Convolution](#toc0_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "signal_2d = np.array([[1, 2, 3], [2, 1, 1], [3, 1, 2]], dtype=np.float32)\n",
        "filter_2d = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]], dtype=np.float32)\n",
        "\n",
        "# log\n",
        "print(f\"signal_2d:\\n{signal_2d}\\n\")\n",
        "print(f\"filter_2d:\\n{filter_2d}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def decompose_kernel(kernel_2d: NDArray) -> tuple[NDArray, NDArray]:\n",
        "\n",
        "    if np.linalg.matrix_rank(kernel_2d) > 1:\n",
        "        raise ValueError(\"Kernel is not separable (rank > 1).\")\n",
        "\n",
        "    U, S, Vt = np.linalg.svd(kernel_2d)\n",
        "\n",
        "    s0 = np.sqrt(S[0])\n",
        "    k_c = U[:, 0] * s0\n",
        "    k_r = Vt[0, :] * s0\n",
        "\n",
        "    return k_c, k_r\n",
        "\n",
        "\n",
        "# decompose 2d kernel\n",
        "k_c, k_r = decompose_kernel(filter_2d)\n",
        "\n",
        "# log\n",
        "print(f\"k_r                : {k_r}\")\n",
        "print(f\"k_c                : {k_c}\")\n",
        "print(f\"np.outer(k_c, k_r) :\\n{np.outer(k_c, k_r)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# apply 2D convolution for comparison\n",
        "signal_2d_conv_4 = conv2d(signal_2d, filter_2d)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### <a id='toc2_3_3_1_'></a>[Manual](#toc0_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def conv2d_separable(image: NDArray, k_r: NDArray, k_c: NDArray) -> NDArray:\n",
        "    image_h, image_w = image.shape\n",
        "    k_r = np.flip(k_r)\n",
        "    k_c = np.flip(k_c)\n",
        "    pad_r = len(k_r) - 1\n",
        "    pad_c = len(k_c) - 1\n",
        "\n",
        "    padded_image = np.pad(image, ((0, 0), (pad_r, pad_r)), mode=\"constant\", constant_values=0)\n",
        "    intermediate = np.zeros((image_h, image_w + pad_r))\n",
        "    for i in range(image_h):\n",
        "        for j in range(image_w + pad_r):\n",
        "            intermediate[i, j] = np.sum(padded_image[i, j : j + len(k_r)] * k_r)\n",
        "\n",
        "    padded_intermediate = np.pad(intermediate, ((pad_c, pad_c), (0, 0)), mode=\"constant\", constant_values=0)\n",
        "    output_h, output_w = image_h + pad_c, image_w + pad_r\n",
        "    output = np.zeros((output_h, output_w))\n",
        "    for i in range(output_h):\n",
        "        for j in range(output_w):\n",
        "            output[i, j] = np.sum(padded_intermediate[i : i + len(k_c), j] * k_c)\n",
        "\n",
        "    return output\n",
        "\n",
        "\n",
        "# apply convolution separately\n",
        "signal_2d_conv_5 = conv2d_separable(signal_2d, k_r, k_c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# plot\n",
        "signals = [signal_2d, signal_2d_conv_4, signal_2d_conv_5]\n",
        "titles = [\"signal_2d\", \"2D Convolution\", \"Separable Convolution\"]\n",
        "fig, axes = plt.subplots(1, 3, figsize=(9, 3), layout=\"compressed\")\n",
        "for ax, signal, title in zip(axes, signals, titles):\n",
        "    ax.imshow(signal, cmap=\"gray\")\n",
        "    ax.set(title=title, xticks=range(signal.shape[1]), yticks=range(signal.shape[0]))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### <a id='toc2_3_3_2_'></a>[Using OpenCV](#toc0_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# proper padding to apply full convolution\n",
        "pad_r = k_r.shape[0] // 2\n",
        "pad_c = k_c.shape[0] // 2\n",
        "signal_2d_padded = cv2.copyMakeBorder(signal_2d, pad_r, pad_r, pad_c, pad_c, borderType=cv2.BORDER_CONSTANT, value=0)\n",
        "\n",
        "# apply convolution separately\n",
        "signal_2d_conv_6 = cv2.sepFilter2D(signal_2d_padded, -1, k_r[::-1], k_c[::-1], borderType=cv2.BORDER_CONSTANT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# plot\n",
        "signals = [signal_2d, signal_2d_conv_4, signal_2d_conv_6]\n",
        "titles = [\"signal_2d\", \"2D Convolution\", \"Separable Convolution\"]\n",
        "fig, axes = plt.subplots(1, 3, figsize=(9, 3), layout=\"compressed\")\n",
        "for ax, signal, title in zip(axes, signals, titles):\n",
        "    ax.imshow(signal, cmap=\"gray\")\n",
        "    ax.set(title=title, xticks=range(signal.shape[1]), yticks=range(signal.shape[0]))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <a id='toc2_3_4_'></a>[2D Cross-Correlation](#toc0_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "signal_2d = np.array([[1, 2, 3], [2, 1, 1], [3, 1, 2]], dtype=np.float32)\n",
        "filter_2d = np.array([[3, 1, 2], [1, 2, 1], [3, 1, 1]], dtype=np.float32)\n",
        "\n",
        "# log\n",
        "print(f\"signal_2d:\\n{signal_2d}\\n\")\n",
        "print(f\"filter_2d:\\n{filter_2d}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### <a id='toc2_3_4_1_'></a>[Using SciPy](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "signal_2d_corr_1 = sp.signal.correlate2d(signal_2d, filter_2d, mode=\"full\", boundary=\"fill\", fillvalue=0)\n",
        "\n",
        "# plot\n",
        "signals = [signal_2d, filter_2d, signal_2d_corr_1]\n",
        "titles = [\"signal_2d\", \"filter_2d\", \"signal_2d_corr_1\"]\n",
        "fig, axes = plt.subplots(1, 3, figsize=(9, 3), layout=\"compressed\")\n",
        "for ax, signal, title in zip(axes, signals, titles):\n",
        "    ax.imshow(signal, cmap=\"gray\")\n",
        "    ax.set(title=title, xticks=range(signal.shape[1]), yticks=range(signal.shape[0]))\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "author_email": "AmirhosseinHeydari78@gmail.com",
    "author_github": "https://github.com/mr-pylin",
    "author_name": "Amirhossein Heydari",
    "kernelspec": {
      "display_name": "media-processing-workshop-py3.13 (3.13.1)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    },
    "origin_repo": "https://github.com/mr-pylin/pytorch-workshop"
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
