{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìù **Author:** Amirhossein Heydari - üìß **Email:** <amirhosseinheydari78@gmail.com> - üìç **Origin:** [mr-pylin/pytorch-workshop](https://github.com/mr-pylin/pytorch-workshop)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Dependencies](#toc1_)    \n",
    "- [Linear Regression](#toc2_)    \n",
    "  - [Load Boston Housing Dataset](#toc2_1_)    \n",
    "  - [Implementation 1](#toc2_2_)    \n",
    "  - [Implementation 2](#toc2_3_)    \n",
    "  - [Implementation 3](#toc2_4_)    \n",
    "  - [Implementation 4](#toc2_5_)    \n",
    "- [Logistic Regression](#toc3_)    \n",
    "  - [Load Breast Cancer Dataset](#toc3_1_)    \n",
    "  - [Implementation](#toc3_2_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[Dependencies](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn, optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set a seed for deterministic results\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc2_'></a>[Linear Regression](#toc0_)\n",
    "\n",
    "- **Linear Regression** is a **supervised** machine learning algorithm.\n",
    "- It's used to model the **relationship** between a dependent variable (**target**) and one or more independent variables (**features**).\n",
    "- It predicts a **continuous** output.\n",
    "\n",
    "<figure style=\"text-align:center; margin:0;\">\n",
    "  <img src=\"../assets/images/original/perceptron/linear-regression.svg\" alt=\"linear-regression.svg\" style=\"max-width:80%; height:auto;\">\n",
    "  <figcaption style=\"text-align:center;\">Linear Regression Model</figcaption>\n",
    "</figure>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_1_'></a>[Load Boston Housing Dataset](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boston dataset as a pandas data-frame\n",
    "boston_df = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/mr-pylin/datasets/refs/heads/main/data/tabular-data/boston-housing/dataset.csv\",\n",
    "    encoding=\"utf-8\",\n",
    ")\n",
    "\n",
    "# log\n",
    "print(boston_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate features and target\n",
    "X = torch.tensor(boston_df.drop(columns=[\"MEDV\"]).values, dtype=torch.float32)\n",
    "y = torch.tensor(boston_df[\"MEDV\"].values, dtype=torch.float32)\n",
    "\n",
    "# split dataset into train and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=seed)\n",
    "\n",
    "# standardize features\n",
    "x_train_mean = x_train.mean(dim=0)\n",
    "x_train_std = x_train.std(dim=0)\n",
    "x_train = (x_train - x_train_mean) / x_train_std\n",
    "x_test = (x_test - x_train_mean) / x_train_std\n",
    "\n",
    "# reshape targets to add `batch` dimension\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "y_test = y_test.reshape(-1, 1)\n",
    "\n",
    "# log\n",
    "print(f\"x_train[0]: {x_train[0]}\\n\")\n",
    "print(f\"y_train[0]: {y_train[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_2_'></a>[Implementation 1](#toc0_)\n",
    "\n",
    "<table style=\"text-align: center; border-collapse: collapse;\">\n",
    "  <tr>\n",
    "    <th style=\"width: 25%;\">Feedforward</th>\n",
    "    <th style=\"width: 25%;\">Gradient Computation</th>\n",
    "    <th style=\"width: 25%;\">Loss Computation</th>\n",
    "    <th style=\"width: 25%;\">Parameter Update</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Manual ‚ùå</td>\n",
    "    <td>Manual ‚ùå</td>\n",
    "    <td>Manual ‚ùå</td>\n",
    "    <td>Manual ‚ùå</td>\n",
    "  </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize weights and bias\n",
    "torch.manual_seed(seed)\n",
    "w = torch.randn((1, x_train.shape[1]), dtype=torch.float32)\n",
    "b = torch.zeros((1), dtype=torch.float32)\n",
    "\n",
    "# hyperparameters\n",
    "lr = 0.02\n",
    "epochs = 100\n",
    "\n",
    "\n",
    "# feed-forward\n",
    "def model_1(x: torch.Tensor) -> torch.Tensor:\n",
    "    return x @ w.T + b\n",
    "\n",
    "\n",
    "# MSE loss\n",
    "def loss(y_pred: torch.Tensor, y_train: torch.Tensor) -> torch.Tensor:\n",
    "    return ((y_pred - y_train) ** 2).mean()\n",
    "\n",
    "\n",
    "# gradients for weights and bias\n",
    "def gradient(x: torch.Tensor, y_pred: torch.Tensor, y_train: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    dw = (2 * ((y_pred - y_train).T @ x)) / x.shape[0]\n",
    "    db = (2 * (y_pred - y_train)).mean()\n",
    "    return dw, db\n",
    "\n",
    "\n",
    "# training loop\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # feed-forward\n",
    "    y_pred = model_1(x_train)\n",
    "\n",
    "    # loss\n",
    "    l = loss(y_pred, y_train)\n",
    "\n",
    "    # backward\n",
    "    dw, db = gradient(x_train, y_pred, y_train)\n",
    "\n",
    "    # update parameters\n",
    "    w -= lr * dw\n",
    "    b -= lr * db\n",
    "\n",
    "    # log\n",
    "    if epoch % 10 == 0 or (epoch + 1) == epochs:\n",
    "        print(f\"epoch {epoch+1:0{len(str(epochs))}}/{epochs} -> loss: {l:9.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict test set targets\n",
    "with torch.no_grad():\n",
    "    y_pred = model_1(x_test)\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    print(f\"[y_true: {y_test[i].squeeze():8.5f} | y_pred: {y_pred[i].squeeze():8.5f}]\", end=\"\")\n",
    "    if (i + 1) % 4 == 0:\n",
    "        print(\"\")\n",
    "    else:\n",
    "        print(\" , \", end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_3_'></a>[Implementation 2](#toc0_)\n",
    "\n",
    "<table style=\"text-align: center; border-collapse: collapse;\">\n",
    "  <tr>\n",
    "    <th style=\"width: 25%;\">Feedforward</th>\n",
    "    <th style=\"width: 25%;\">Gradient Computation</th>\n",
    "    <th style=\"width: 25%;\">Loss Computation</th>\n",
    "    <th style=\"width: 25%;\">Parameter Update</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Manual ‚ùå</td>\n",
    "    <td>Auto ‚úÖ</td>\n",
    "    <td>Manual ‚ùå</td>\n",
    "    <td>Manual ‚ùå</td>\n",
    "  </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize weights and bias\n",
    "torch.manual_seed(seed)\n",
    "w = torch.randn((1, x_train.shape[1]), dtype=torch.float32, requires_grad=True)\n",
    "b = torch.zeros((1), dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "# hyperparameters\n",
    "lr = 0.02\n",
    "epochs = 100\n",
    "\n",
    "\n",
    "# feed-forward\n",
    "def model_2(x: torch.Tensor) -> torch.Tensor:\n",
    "    return x @ w.T + b\n",
    "\n",
    "\n",
    "# MSE loss\n",
    "def loss(y_pred: torch.Tensor, y_train: torch.Tensor) -> torch.Tensor:\n",
    "    return ((y_pred - y_train) ** 2).mean()\n",
    "\n",
    "\n",
    "# training loop\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # feed-forward\n",
    "    y_pred = model_2(x_train)\n",
    "\n",
    "    # loss\n",
    "    l = loss(y_pred, y_train)\n",
    "\n",
    "    # backward\n",
    "    l.backward()\n",
    "\n",
    "    # update parameters\n",
    "    with torch.no_grad():\n",
    "        w -= lr * w.grad\n",
    "        b -= lr * b.grad\n",
    "\n",
    "        # zero the gradients to prevent accumulating\n",
    "        w.grad.zero_()\n",
    "        b.grad.zero_()\n",
    "\n",
    "    # log\n",
    "    if epoch % 10 == 0 or (epoch + 1) == epochs:\n",
    "        print(f\"epoch {epoch+1:0{len(str(epochs))}}/{epochs} -> loss: {l:9.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict test set targets\n",
    "with torch.no_grad():\n",
    "    y_pred = model_2(x_test)\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    print(f\"[y_true: {y_test[i].squeeze():8.5f} | y_pred: {y_pred[i].squeeze():8.5f}]\", end=\"\")\n",
    "    if (i + 1) % 4 == 0:\n",
    "        print(\"\")\n",
    "    else:\n",
    "        print(\" , \", end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_4_'></a>[Implementation 3](#toc0_)\n",
    "\n",
    "<table style=\"text-align: center; border-collapse: collapse;\">\n",
    "  <tr>\n",
    "    <th style=\"width: 25%;\">Feedforward</th>\n",
    "    <th style=\"width: 25%;\">Gradient Computation</th>\n",
    "    <th style=\"width: 25%;\">Loss Computation</th>\n",
    "    <th style=\"width: 25%;\">Parameter Update</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Manual ‚ùå</td>\n",
    "    <td>Auto ‚úÖ</td>\n",
    "    <td>Auto ‚úÖ</td>\n",
    "    <td>Auto ‚úÖ</td>\n",
    "  </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize weights and bias\n",
    "torch.manual_seed(seed)\n",
    "w = torch.randn((1, x_train.shape[1]), dtype=torch.float32, requires_grad=True)\n",
    "b = torch.zeros((1), dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "# hyperparameters\n",
    "lr = 0.02\n",
    "epochs = 100\n",
    "\n",
    "# initialize criterion and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD([w, b], lr=lr)\n",
    "\n",
    "\n",
    "# feed-forward\n",
    "def model_3(x: torch.Tensor) -> torch.Tensor:\n",
    "    return x @ w.T + b\n",
    "\n",
    "\n",
    "# training loop\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # feed-forward\n",
    "    y_pred = model_3(x_train)\n",
    "\n",
    "    # loss\n",
    "    l = criterion(y_pred, y_train)\n",
    "\n",
    "    # backward\n",
    "    l.backward()\n",
    "\n",
    "    # update parameters\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # log\n",
    "    if epoch % 10 == 0 or (epoch + 1) == epochs:\n",
    "        print(f\"epoch {epoch+1:0{len(str(epochs))}}/{epochs} -> loss: {l:9.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict test set targets\n",
    "with torch.no_grad():\n",
    "    y_pred = model_3(x_test)\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    print(f\"[y_true: {y_test[i].squeeze():8.5f} | y_pred: {y_pred[i].squeeze():8.5f}]\", end=\"\")\n",
    "    if (i + 1) % 4 == 0:\n",
    "        print(\"\")\n",
    "    else:\n",
    "        print(\" , \", end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_5_'></a>[Implementation 4](#toc0_)\n",
    "\n",
    "<table style=\"text-align: center; border-collapse: collapse;\">\n",
    "  <tr>\n",
    "    <th style=\"width: 25%;\">Feedforward</th>\n",
    "    <th style=\"width: 25%;\">Gradient Computation</th>\n",
    "    <th style=\"width: 25%;\">Loss Computation</th>\n",
    "    <th style=\"width: 25%;\">Parameter Update</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Auto ‚úÖ</td>\n",
    "    <td>Auto ‚úÖ</td>\n",
    "    <td>Auto ‚úÖ</td>\n",
    "    <td>Auto ‚úÖ</td>\n",
    "  </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a linear transformation\n",
    "model_4 = nn.Linear(in_features=x_train.shape[1], out_features=1)\n",
    "\n",
    "# initialize weights and bias [to start from the point of above implementations]\n",
    "torch.manual_seed(seed)\n",
    "with torch.no_grad():\n",
    "    model_4.weight = nn.init.normal_(model_4.weight, mean=0, std=1)\n",
    "    model_4.bias = nn.init.zeros_(model_4.bias)\n",
    "\n",
    "# hyperparameters\n",
    "lr = 0.02\n",
    "epochs = 100\n",
    "\n",
    "# initialize criterion and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model_4.parameters(), lr=lr)\n",
    "\n",
    "# training loop\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # feed-forward\n",
    "    y_pred = model_4(x_train)\n",
    "\n",
    "    # loss\n",
    "    l = criterion(y_pred, y_train)\n",
    "\n",
    "    # backward\n",
    "    l.backward()\n",
    "\n",
    "    # update parameters\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # log\n",
    "    if epoch % 10 == 0 or (epoch + 1) == epochs:\n",
    "        print(f\"epoch {epoch+1:0{len(str(epochs))}}/{epochs} -> loss: {l:9.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict test set targets\n",
    "with torch.no_grad():\n",
    "    y_pred = model_4(x_test)\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    print(f\"[y_true: {y_test[i].squeeze():8.5f} | y_pred: {y_pred[i].squeeze():8.5f}]\", end=\"\")\n",
    "    if (i + 1) % 4 == 0:\n",
    "        print(\"\")\n",
    "    else:\n",
    "        print(\" , \", end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc3_'></a>[Logistic Regression](#toc0_)\n",
    "\n",
    "- **Logistic Regression** is a **supervised** machine learning algorithm.\n",
    "- It models the **relationship** between a dependent variable (**target**) and one or more independent variables (**features**).\n",
    "- Unlike **linear regression**, it predicts a **categorical outcome**, typically for **binary classification** (0 or 1).\n",
    "- It uses the **logistic** function (**sigmoid**) to map predicted values to **probabilities**.\n",
    "\n",
    "<figure style=\"text-align:center; margin:0;\">\n",
    "  <img src=\"../assets/images/original/perceptron/logistic-regression.svg\" alt=\"logistic-regression.svg\" style=\"max-width:80%; height:auto;\">\n",
    "  <figcaption style=\"text-align:center;\">Logistic Regression Model</figcaption>\n",
    "</figure>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc3_1_'></a>[Load Breast Cancer Dataset](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# breast cancer as a pandas data-frame\n",
    "breast_df = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/mr-pylin/datasets/refs/heads/main/data/tabular-data/breast-cancer-wisconsin-diagnostic/dataset.csv\",\n",
    "    encoding=\"utf-8\",\n",
    ")\n",
    "\n",
    "# encode labels to numbers\n",
    "breast_df[\"Diagnosis\"] = breast_df[\"Diagnosis\"].map({\"B\": 0, \"M\": 1})\n",
    "\n",
    "# log\n",
    "print(breast_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate features and target\n",
    "X = torch.tensor(breast_df.iloc[:, 2:].values, dtype=torch.float32)\n",
    "y = torch.tensor(breast_df[\"Diagnosis\"].values, dtype=torch.float32)\n",
    "\n",
    "# split dataset into train and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=seed)\n",
    "\n",
    "# standardize features\n",
    "x_train_mean = x_train.mean(dim=0)\n",
    "x_train_std = x_train.std(dim=0)\n",
    "x_train = (x_train - x_train_mean) / x_train_std\n",
    "x_test = (x_test - x_train_mean) / x_train_std\n",
    "\n",
    "# reshape targets to add `batch` dimension\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "y_test = y_test.reshape(-1, 1)\n",
    "\n",
    "# log\n",
    "print(f\"x_train[0]: {x_train[0]}\\n\")\n",
    "print(f\"y_train[0]: {y_train[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc3_2_'></a>[Implementation](#toc0_)\n",
    "\n",
    "<table style=\"text-align: center; border-collapse: collapse;\">\n",
    "  <tr>\n",
    "    <th style=\"width: 25%;\">Feedforward</th>\n",
    "    <th style=\"width: 25%;\">Gradient Computation</th>\n",
    "    <th style=\"width: 25%;\">Loss Computation</th>\n",
    "    <th style=\"width: 25%;\">Parameter Update</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Auto ‚úÖ</td>\n",
    "    <td>Auto ‚úÖ</td>\n",
    "    <td>Auto ‚úÖ</td>\n",
    "    <td>Auto ‚úÖ</td>\n",
    "  </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a linear transformation\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(in_features=x_train.shape[1], out_features=1),\n",
    "    nn.Sigmoid(),\n",
    ")\n",
    "\n",
    "# log\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "lr = 0.02\n",
    "epochs = 100\n",
    "\n",
    "# initialize criterion and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "# training loop\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # feed-forward\n",
    "    y_pred = model(x_train)\n",
    "\n",
    "    # loss\n",
    "    l = criterion(y_pred, y_train)\n",
    "\n",
    "    # backward\n",
    "    l.backward()\n",
    "\n",
    "    # update parameters\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # compute accuracy\n",
    "    acc = ((y_pred >= 0.5).float() == y_train).float().mean().item()\n",
    "\n",
    "    # log\n",
    "    if epoch % 10 == 0 or (epoch + 1) == epochs:\n",
    "        print(f\"epoch {epoch+1:0{len(str(epochs))}}/{epochs} -> loss: {l:7.5f} | acc: {acc*100:5.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "with torch.no_grad():\n",
    "\n",
    "    # feed-forward\n",
    "    y_pred = model(x_test)\n",
    "\n",
    "    # loss\n",
    "    l = criterion(y_pred, y_test)\n",
    "\n",
    "    # compute accuracy\n",
    "    acc = ((y_pred >= 0.5).float() == y_test).float().mean().item()\n",
    "\n",
    "    # log\n",
    "    if epoch % 10 == 0 or (epoch + 1) == epochs:\n",
    "        print(f\"loss: {l:9.5f} | acc: {acc*100:5.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "author_email": "AmirhosseinHeydari78@gmail.com",
  "author_github": "https://github.com/mr-pylin",
  "author_name": "Amirhossein Heydari",
  "kernelspec": {
   "display_name": "pytorch-workshop-U_zYfVTd-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "origin_repo": "https://github.com/mr-pylin/pytorch-workshop"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
