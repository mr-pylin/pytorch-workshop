{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: space-between; align-items: center;\">\n",
    "    <div style=\"text-align: left; flex: 4\">\n",
    "        <strong>Author:</strong> Amirhossein Heydari ‚Äî \n",
    "        üìß <a href=\"mailto:amirhosseinheydari78@gmail.com\">amirhosseinheydari78@gmail.com</a> ‚Äî \n",
    "        üêô <a href=\"https://github.com/mr-pylin/pytorch-workshop\" target=\"_blank\" rel=\"noopener\">github.com/mr-pylin</a>\n",
    "    </div>\n",
    "    <div style=\"text-align: right; flex: 1;\">\n",
    "        <a href=\"https://pytorch.org/\" target=\"_blank\" rel=\"noopener noreferrer\">\n",
    "            <img src=\"../assets/images/pytorch/logo/pytorch-logo-dark.svg\" \n",
    "                 alt=\"PyTorch Logo\"\n",
    "                 style=\"max-height: 48px; width: auto; background-color: #ffffff; border-radius: 8px;\">\n",
    "        </a>\n",
    "    </div>\n",
    "</div>\n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Dependencies](#toc1_)    \n",
    "- [Prepare a Dataset](#toc2_)    \n",
    "- [Model Reuse](#toc3_)    \n",
    "  - [Transfer Learning](#toc3_1_)    \n",
    "    - [Transfer Learning via Feature Extraction](#toc3_1_1_)    \n",
    "      - [Load a Pre-trained Model](#toc3_1_1_1_)    \n",
    "      - [Create a Feature Extractor](#toc3_1_1_2_)    \n",
    "      - [Define a Custom Classifier](#toc3_1_1_3_)    \n",
    "      - [Training Loop (Demo)](#toc3_1_1_4_)    \n",
    "    - [End-to-End Transfer Learning](#toc3_1_2_)    \n",
    "      - [Load a Pre-trained Model](#toc3_1_2_1_)    \n",
    "      - [Define End-to-End Model](#toc3_1_2_2_)    \n",
    "      - [Check Gradients](#toc3_1_2_3_)    \n",
    "      - [Training Loop (Demo)](#toc3_1_2_4_)    \n",
    "  - [Fine-tuning](#toc3_2_)    \n",
    "    - [Fine-tuning Strategies](#toc3_2_1_)    \n",
    "      - [Full Fine-Tuning](#toc3_2_1_1_)    \n",
    "        - [Load a Pre-trained Model](#toc3_2_1_1_1_)    \n",
    "        - [Unfreeze All Parameters](#toc3_2_1_1_2_)    \n",
    "        - [Training Loop (Demo)](#toc3_2_1_1_3_)    \n",
    "      - [Partial Fine-Tuning](#toc3_2_1_2_)    \n",
    "        - [Load a Pre-trained Model](#toc3_2_1_2_1_)    \n",
    "        - [Partially Unfreeze Parameters](#toc3_2_1_2_2_)    \n",
    "        - [Training Loop (Demo)](#toc3_2_1_2_3_)    \n",
    "      - [Progressive Fine-Tuning](#toc3_2_1_3_)    \n",
    "        - [Load a Pre-trained Model](#toc3_2_1_3_1_)    \n",
    "        - [Stage 1: Train classifier only](#toc3_2_1_3_2_)    \n",
    "        - [Stage 2: Unfreeze Last Block](#toc3_2_1_3_3_)    \n",
    "        - [Stage 3: Fine-tune Entire Network](#toc3_2_1_3_4_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[Dependencies](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from torchinfo import summary\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.models import MobileNet_V3_Small_Weights, mobilenet_v3_small\n",
    "from torchvision.models.feature_extraction import create_feature_extractor\n",
    "from torchvision.transforms import v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# disable automatic figure display (plt.show() required)\n",
    "# this ensures consistency with .py scripts and gives full control over when plots appear\n",
    "plt.ioff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set a seed for deterministic results\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if cuda is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# log\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update paths as needed based on your project structure\n",
    "DATASET_DIR = Path(\"../datasets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc2_'></a>[Prepare a Dataset](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = v2.Compose(\n",
    "    [\n",
    "        v2.ToImage(),\n",
    "        v2.Resize((224, 224)),\n",
    "        v2.ToDtype(torch.float32, scale=True),\n",
    "        v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # ImageNet normalization\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = CIFAR10(root=DATASET_DIR, train=True, download=False, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log\n",
    "print(\"trainset:\")\n",
    "print(f\"    -> trainset.data.shape    : {trainset.data.shape}\")\n",
    "print(f\"    -> trainset.data.dtype    : {trainset.data.dtype}\")\n",
    "print(f\"    -> type(trainset.data)    : {type(trainset.data)}\")\n",
    "print(f\"    -> type(trainset.targets) : {type(trainset.targets)}\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"classes : {trainset.classes}\")\n",
    "print(f\"trainset distribution : {torch.unique(torch.tensor(trainset.targets), return_counts=True)[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "fig, axs = plt.subplots(nrows=4, ncols=8, figsize=(12, 6), layout=\"compressed\")\n",
    "for i in range(4):\n",
    "    for j in range(8):\n",
    "        axs[i, j].imshow(trainset.data[i * 8 + j], cmap=\"gray\")\n",
    "        axs[i, j].set_title(trainset.classes[trainset.targets[i * 8 + j]])\n",
    "        axs[i, j].axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc3_'></a>[Model Reuse](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc3_1_'></a>[Transfer Learning](#toc0_)\n",
    "\n",
    "- Transfer learning is the practice of **reusing knowledge** from a p**retrained model** to solve a new but **related task**.\n",
    "- Early layers of neural networks learn **general features** like edges, textures, or shapes that are often useful across tasks.\n",
    "\n",
    "üìà **Motivation**:\n",
    "\n",
    "- Reduces training time and data requirements.\n",
    "- Leverages knowledge from large datasets (e.g., ImageNet) for smaller or domain-specific tasks.\n",
    "\n",
    "üìâ **Common Pitfalls**:\n",
    "\n",
    "- **Mismatched input size or channels:** Pretrained models expect specific input shapes (e.g., 224√ó224√ó3).\n",
    "- **Overfitting downstream model:** Use regularization if downstream data is small.\n",
    "- **Feature collapse:** Some extracted features may not be informative for new tasks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc3_1_1_'></a>[Transfer Learning via Feature Extraction](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc3_1_1_1_'></a>[Load a Pre-trained Model](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model = mobilenet_v3_small(weights=MobileNet_V3_Small_Weights.IMAGENET1K_V1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set to evaluation mode\n",
    "pretrained_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze backbone parameters\n",
    "for param in pretrained_model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc3_1_1_2_'></a>[Create a Feature Extractor](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract features from the last layer before classifier\n",
    "return_nodes = {\"avgpool\": \"embedding\"}\n",
    "feature_extractor = create_feature_extractor(pretrained_model, return_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc3_1_1_3_'></a>[Define a Custom Classifier](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, embedding_size: int = 576, num_classes: int = 10):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(embedding_size, num_classes)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # flatten from (B, C, 1, 1) ‚Üí (B, C)\n",
    "        x = torch.flatten(x, 1)\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Classifier(embedding_size=576, num_classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc3_1_1_4_'></a>[Training Loop (Demo)](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor.to(device)\n",
    "classifier.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(classifier.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(2):\n",
    "    for x, y_true in train_loader:\n",
    "        x, y_true = x.to(device), y_true.to(device)\n",
    "\n",
    "        # extract features from frozen backbone\n",
    "        with torch.no_grad():\n",
    "            features = feature_extractor(x)[\"embedding\"]\n",
    "\n",
    "        # forward through new classifier\n",
    "        y_pred = classifier(features)\n",
    "        loss = criterion(y_pred, y_true)\n",
    "\n",
    "        # backpropagate only through classifier\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    # log\n",
    "    print(f\"Epoch {epoch+1}: Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc3_1_2_'></a>[End-to-End Transfer Learning](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc3_1_2_1_'></a>[Load a Pre-trained Model](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model = mobilenet_v3_small(weights=MobileNet_V3_Small_Weights.IMAGENET1K_V1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set to evaluation mode\n",
    "pretrained_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze backbone parameters\n",
    "for param in pretrained_model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc3_1_2_2_'></a>[Define End-to-End Model](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTransferModel(nn.Module):\n",
    "    def __init__(self, backbone: nn.Module, num_classes: int = 10):\n",
    "        super().__init__()\n",
    "\n",
    "        # remove original classifier (fc layer)\n",
    "        self.backbone = backbone.features\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.classifier = nn.Linear(576, num_classes)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.backbone(x)\n",
    "        x = self.pool(x)\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate model\n",
    "custom_model = CustomTransferModel(backbone=pretrained_model, num_classes=10)\n",
    "custom_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(custom_model, input_size=(1, 3, 224, 224), device=\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc3_1_2_3_'></a>[Check Gradients](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in custom_model.named_parameters():\n",
    "    print(f\"{name:<30s} -> requires_grad: {param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc3_1_2_4_'></a>[Training Loop (Demo)](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(custom_model.classifier.parameters(), lr=1e-3)  # only train classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(2):\n",
    "    for x, y_true in train_loader:\n",
    "        x, y_true = x.to(device), y_true.to(device)\n",
    "\n",
    "        # forward\n",
    "        y_pred = custom_model(x)\n",
    "        loss = criterion(y_pred, y_true)\n",
    "\n",
    "        # backward\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    # log\n",
    "    print(f\"Epoch {epoch+1}: Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc3_2_'></a>[Fine-tuning](#toc0_)\n",
    "\n",
    "- Fine-tuning is the practice of **starting from a pretrained model** and **updating some or all of its weights** on a new dataset.\n",
    "- Instead of keeping the backbone frozen, the model is allowed to **adapt its learned representations** to better fit the target task.\n",
    "\n",
    "üìà **Motivation**:\n",
    "\n",
    "- Improves performance when the target dataset differs from the source dataset.\n",
    "- Allows higher-level features to specialize for the new task.\n",
    "- Particularly useful when the target dataset is moderately sized.\n",
    "\n",
    "üìâ **Common Pitfalls**:\n",
    "\n",
    "- **Overfitting:** Updating too many parameters with limited data can harm generalization.\n",
    "- **Catastrophic forgetting:** The model may lose useful pretrained knowledge.\n",
    "- **Learning rate misconfiguration:** Using too large a learning rate can destroy pretrained features; typically a smaller learning rate is used for pretrained layers.\n",
    "- **Unstable training:** Fine-tuning without proper normalization or scheduling may cause training divergence.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc3_2_1_'></a>[Fine-tuning Strategies](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc3_2_1_1_'></a>[Full Fine-Tuning](#toc0_)\n",
    "\n",
    "- All pretrained layers are **unfrozen and learnable**.\n",
    "- The entire network adapts to the new dataset.\n",
    "- Provides maximum flexibility and adaptation.\n",
    "- Requires a **small learning rate** to preserve useful pretrained knowledge.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <a id='toc3_2_1_1_1_'></a>[Load a Pre-trained Model](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model = mobilenet_v3_small(weights=MobileNet_V3_Small_Weights.IMAGENET1K_V1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace classifier for CIFAR-10\n",
    "in_features = pretrained_model.classifier[3].in_features\n",
    "pretrained_model.classifier[3] = nn.Linear(in_features, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <a id='toc3_2_1_1_2_'></a>[Unfreeze All Parameters](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in pretrained_model.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <a id='toc3_2_1_1_3_'></a>[Training Loop (Demo)](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model = pretrained_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(\n",
    "    pretrained_model.parameters(),\n",
    "    lr=1e-5,   # critical: small learning rate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(2):\n",
    "\n",
    "    pretrained_model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for x, y_true in train_loader:\n",
    "        x, y_true = x.to(device), y_true.to(device)\n",
    "\n",
    "        # forward\n",
    "        y_pred = pretrained_model(x)\n",
    "        loss = criterion(y_pred, y_true)\n",
    "\n",
    "        # backward\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # calculate loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "\n",
    "    # log\n",
    "    print(f\"Epoch {epoch+1}: Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc3_2_1_2_'></a>[Partial Fine-Tuning](#toc0_)\n",
    "\n",
    "- Only **some layers** (usually higher layers) are unfrozen.\n",
    "- Early layers remain frozen because they contain general features.\n",
    "- Later layers adapt to task-specific features.\n",
    "- Provides a balance between stability and adaptability.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <a id='toc3_2_1_2_1_'></a>[Load a Pre-trained Model](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model = mobilenet_v3_small(weights=MobileNet_V3_Small_Weights.IMAGENET1K_V1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace classifier for CIFAR-10\n",
    "in_features = pretrained_model.classifier[3].in_features\n",
    "pretrained_model.classifier[3] = nn.Linear(in_features, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <a id='toc3_2_1_2_2_'></a>[Partially Unfreeze Parameters](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model.features[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze entire backbone\n",
    "for param in pretrained_model.features.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unfreeze last block of geatures\n",
    "for param in pretrained_model.features[-1].parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier should be learnable\n",
    "for param in pretrained_model.classifier.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check parameters\n",
    "for name, param in pretrained_model.named_parameters():\n",
    "    print(f\"{name:<30s} -> requires_grad: {param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <a id='toc3_2_1_2_3_'></a>[Training Loop (Demo)](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model = pretrained_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# if you include frozen params, memory and computation are wasted on params that never update.\n",
    "optimizer = torch.optim.Adam(\n",
    "    filter(lambda p: p.requires_grad, pretrained_model.parameters()),\n",
    "    lr=1e-4,   # higher than full fine-tuning since fewer params update\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(2):\n",
    "\n",
    "    pretrained_model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for x, y_true in train_loader:\n",
    "        x, y_true = x.to(device), y_true.to(device)\n",
    "\n",
    "        # forward\n",
    "        y_pred = pretrained_model(x)\n",
    "        loss = criterion(y_pred, y_true)\n",
    "\n",
    "        # backward\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # calculate loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "\n",
    "    # log\n",
    "    print(f\"Epoch {epoch+1}: Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc3_2_1_3_'></a>[Progressive Fine-Tuning](#toc0_)\n",
    "\n",
    "- Layers are **gradually unfrozen during training**.\n",
    "- Training starts with fewer learnable layers and increases over time.\n",
    "- Improves stability and reduces risk of damaging pretrained representations.\n",
    "- Common in research and professional workflows.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <a id='toc3_2_1_3_1_'></a>[Load a Pre-trained Model](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model = mobilenet_v3_small(weights=MobileNet_V3_Small_Weights.IMAGENET1K_V1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace classifier for CIFAR-10\n",
    "in_features = pretrained_model.classifier[3].in_features\n",
    "pretrained_model.classifier[3] = nn.Linear(in_features, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model = pretrained_model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <a id='toc3_2_1_3_2_'></a>[Stage 1: Train classifier only](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze all backbone\n",
    "for param in pretrained_model.features.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(\n",
    "    filter(lambda p: p.requires_grad, pretrained_model.parameters()),\n",
    "    lr=1e-3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(2):\n",
    "    for x, y_true in train_loader:\n",
    "        x, y_true = x.to(device), y_true.to(device)\n",
    "\n",
    "        # forward\n",
    "        y_pred = pretrained_model(x)\n",
    "        loss = criterion(y_pred, y_true)\n",
    "\n",
    "        # backward\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    # log\n",
    "    print(f\"Epoch {epoch+1}: Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <a id='toc3_2_1_3_3_'></a>[Stage 2: Unfreeze Last Block](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unfreeze last block\n",
    "for param in pretrained_model.features[-1].parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(\n",
    "    filter(lambda p: p.requires_grad, pretrained_model.parameters()),\n",
    "    lr=1e-4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(2):\n",
    "    for x, y_true in train_loader:\n",
    "        x, y_true = x.to(device), y_true.to(device)\n",
    "\n",
    "        # forward\n",
    "        y_pred = pretrained_model(x)\n",
    "        loss = criterion(y_pred, y_true)\n",
    "\n",
    "        # backward\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    # log\n",
    "    print(f\"Epoch {epoch+1}: Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <a id='toc3_2_1_3_4_'></a>[Stage 3: Fine-tune Entire Network](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unfreeze all parameters\n",
    "for param in pretrained_model.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(\n",
    "    pretrained_model.parameters(),\n",
    "    lr=1e-5,  # very small LR for stability\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(2):\n",
    "    for x, y_true in train_loader:\n",
    "        x, y_true = x.to(device), y_true.to(device)\n",
    "\n",
    "        # forward\n",
    "        y_pred = pretrained_model(x)\n",
    "        loss = criterion(y_pred, y_true)\n",
    "\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # log\n",
    "    print(f\"Epoch {epoch+1}: Loss: {loss.item():.4f}\")"
   ]
  }
 ],
 "metadata": {
  "author_email": "AmirhosseinHeydari78@gmail.com",
  "author_github": "https://github.com/mr-pylin",
  "author_name": "Amirhossein Heydari",
  "kernelspec": {
   "display_name": "pytorch-workshop (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  },
  "origin_repo": "https://github.com/mr-pylin/pytorch-workshop"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
