{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìù **Author:** Amirhossein Heydari - üìß **Email:** <amirhosseinheydari78@gmail.com> - üìç **Origin:** [mr-pylin/pytorch-workshop](https://github.com/mr-pylin/pytorch-workshop)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Dependencies](#toc1_)    \n",
    "- [Classification of MNIST Dataset](#toc2_)    \n",
    "  - [Utility Function to Store Metrics](#toc2_1_)    \n",
    "  - [Hyperparameters](#toc2_2_)    \n",
    "  - [Pre-Processing](#toc2_3_)    \n",
    "    - [Load MNIST Dataset](#toc2_3_1_)    \n",
    "    - [Split Train Set into Train and Validation Subsets](#toc2_3_2_)    \n",
    "    - [Normalization](#toc2_3_3_)    \n",
    "      - [Append Normalization to the Transforms](#toc2_3_3_1_)    \n",
    "    - [Create DataLoaders](#toc2_3_4_)    \n",
    "  - [Custom MLP Model](#toc2_4_)    \n",
    "  - [Train and Validation Loop](#toc2_5_)    \n",
    "    - [Analyze Loss and Accuracy over Epochs](#toc2_5_1_)    \n",
    "  - [Test Loop](#toc2_6_)    \n",
    "    - [Plot Top_1 Confusion Matrix](#toc2_6_1_)    \n",
    "    - [Classification Report](#toc2_6_2_)    \n",
    "  - [Prediction](#toc2_7_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[Dependencies](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from sklearn.metrics import classification_report\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchinfo import summary\n",
    "from torchmetrics.classification import MulticlassAccuracy, MulticlassConfusionMatrix\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set a seed for deterministic results\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if cuda is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# log\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update paths as needed based on your project structure\n",
    "DATASET_DIR = Path(\"../../../../datasets/\")\n",
    "LOG_DIR = Path(\"./results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc2_'></a>[Classification of MNIST Dataset](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_1_'></a>[Utility Function to Store Metrics](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricsLogger:\n",
    "    def __init__(\n",
    "        self,\n",
    "        train_val_file: str | Path = LOG_DIR / \"train_val_metrics.csv\",\n",
    "        test_file: str | Path = LOG_DIR / \"test_metrics.csv\",\n",
    "        confusion_matrix_file: str | Path = LOG_DIR / \"test_top_1_confusion_matrix.csv\",\n",
    "        test_top_k_acc: int = 5,\n",
    "        lr_precision: str = \".6f\",\n",
    "        loss_precision: str = \"7.5f\",\n",
    "        acc_precision: str = \".3f\",\n",
    "    ):\n",
    "        self.train_val_file = train_val_file\n",
    "        self.test_file = test_file\n",
    "        self.confusion_matrix_file = confusion_matrix_file\n",
    "        self.test_top_k_acc = test_top_k_acc\n",
    "        self.lr_precision = lr_precision\n",
    "        self.loss_precision = loss_precision\n",
    "        self.acc_precision = acc_precision\n",
    "\n",
    "        # initialize csv files with headers\n",
    "        self._initialize_file(\n",
    "            self.train_val_file,\n",
    "            \"epoch,lr,train_loss,train_acc,val_loss,val_acc\\n\",\n",
    "        )\n",
    "        self._initialize_file(\n",
    "            self.test_file,\n",
    "            f\"test_loss,{','.join(f'test_top_{i+1}_acc' for i in range(test_top_k_acc))}\\n\",\n",
    "        )\n",
    "\n",
    "    def _initialize_file(self, file_path: str | Path, header: str) -> None:\n",
    "\n",
    "        # create directory if doesn't exist\n",
    "        Path(file_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        with open(file_path, mode=\"w\") as file:\n",
    "            file.write(header)\n",
    "\n",
    "    def log_train_val(\n",
    "        self, epoch: str, lr: float, train_loss: float, train_acc: float, val_loss: float, val_acc: float\n",
    "    ) -> None:\n",
    "        with open(self.train_val_file, mode=\"a\") as file:\n",
    "            file.write(\n",
    "                f\"{epoch},{lr:{self.lr_precision}},{train_loss:{self.loss_precision}},{train_acc:{self.acc_precision}},{val_loss:{self.loss_precision}},{val_acc:{self.acc_precision}}\\n\"\n",
    "            )\n",
    "\n",
    "    def log_test(self, test_loss: float, *test_top_k_acc: float) -> None:\n",
    "\n",
    "        if len(test_top_k_acc) != self.test_top_k_acc:\n",
    "            raise ValueError(f\"expected {self.test_top_k_acc} test accuracies, but got {len(test_top_k_acc)}.\")\n",
    "\n",
    "        with open(self.test_file, mode=\"a\") as file:\n",
    "            file.write(\n",
    "                f\"{test_loss:{self.loss_precision}},{','.join(f'{x:{self.acc_precision}}' for x in test_top_k_acc)}\\n\"\n",
    "            )\n",
    "\n",
    "    def log_confusion_matrix(self, cm: torch.Tensor, labels: list[str]) -> None:\n",
    "\n",
    "        if cm.dim() != 2:\n",
    "            raise ValueError(\"confusion matrix must be a 2D tensor.\")\n",
    "\n",
    "        self._initialize_file(\n",
    "            self.confusion_matrix_file,\n",
    "            f\",{\",\".join([f'pred_{label}' for label in labels])}\\n\",\n",
    "        )\n",
    "\n",
    "        max_length_label = max(map(len, labels))\n",
    "\n",
    "        with open(self.confusion_matrix_file, mode=\"a\") as file:\n",
    "            for true_label_idx, true_label in enumerate(labels):\n",
    "                row = [f\"true_{true_label:<{max_length_label}}\"] + [\n",
    "                    f\"{cm[true_label_idx, pred_idx]}\" for pred_idx in range(cm.shape[1])\n",
    "                ]\n",
    "                file.write(\",\".join(row) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_top_k_acc = 3\n",
    "logger = MetricsLogger(test_top_k_acc=test_top_k_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_2_'></a>[Hyperparameters](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_BATCH_SIZE = 64\n",
    "VALIDATION_BATCH_SIZE = 128\n",
    "TEST_BATCH_SIZE = 128\n",
    "LEARNING_RATE = 0.01\n",
    "EPOCHS = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_3_'></a>[Pre-Processing](#toc0_)\n",
    "\n",
    "üìö **Tutorials**:\n",
    "\n",
    "- **Transformations**\n",
    "  - Learn about common image transformations and how to apply them for data augmentation and normalization.\n",
    "  - check [vision-transforms.ipynb](../../../utils/vision-transforms.ipynb)\n",
    "- **Dataset & DataLoader**\n",
    "  - Understand how to load datasets and efficiently manage batching with DataLoader.\n",
    "  - check [dataset-dataloader.ipynb](../../../utils/dataset-dataloader.ipynb)\n",
    "- **Normalizations**\n",
    "  - Explore techniques for normalizing image data to improve model performance and convergence.\n",
    "  - check [normalizations.ipynb](../../../utils/normalizations.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc2_3_1_'></a>[Load MNIST Dataset](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial transforms\n",
    "transforms = v2.Compose(\n",
    "    [\n",
    "        v2.ToImage(),\n",
    "        v2.ToDtype(torch.float32, scale=True),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the MNIST dataset\n",
    "trainset = MNIST(DATASET_DIR, train=True, transform=transforms, download=False)\n",
    "testset = MNIST(DATASET_DIR, train=False, transform=transforms, download=False)\n",
    "\n",
    "classes = trainset.classes\n",
    "num_classes = len(classes)\n",
    "\n",
    "# log\n",
    "print(\"trainset:\")\n",
    "print(f\"    -> trainset.data.shape    : {trainset.data.shape}\")\n",
    "print(f\"    -> trainset.data.dtype    : {trainset.data.dtype}\")\n",
    "print(f\"    -> type(trainset.data)    : {type(trainset.data)}\")\n",
    "print(f\"    -> type(trainset.targets) : {type(trainset.targets)}\")\n",
    "print(f\"    -> trainset[0][0].shape   : {trainset[0][0].shape}\")\n",
    "print(f\"    -> trainset[0][0].dtype   : {trainset[0][0].dtype}\")\n",
    "print(\"-\" * 50)\n",
    "print(\"testset:\")\n",
    "print(f\"    -> testset.data.shape    : {testset.data.shape}\")\n",
    "print(f\"    -> testset.data.dtype    : {testset.data.dtype}\")\n",
    "print(f\"    -> type(testset.data)    : {type(testset.data)}\")\n",
    "print(f\"    -> type(testset.targets) : {type(testset.targets)}\")\n",
    "print(f\"    -> testset[0][0].shape   : {testset[0][0].shape}\")\n",
    "print(f\"    -> testset[0][0].dtype   : {testset[0][0].dtype}\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"classes               : {classes}\")\n",
    "print(f\"class_to_idx          : {trainset.class_to_idx}\")\n",
    "print(f\"trainset distribution : {torch.unique(trainset.targets, return_counts=True)[1]}\")\n",
    "print(f\"testset  distribution : {torch.unique(testset.targets, return_counts=True)[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc2_3_2_'></a>[Split Train Set into Train and Validation Subsets](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random split (returns List[Subset])\n",
    "trainset, validationset = random_split(trainset, [0.9, 0.1])\n",
    "\n",
    "# log\n",
    "print(\"trainset:\")\n",
    "print(f\"    -> len(trainset)         : {len(trainset)}\")\n",
    "print(f\"    -> trainset[0][0]        : {trainset[0][0].shape}\")\n",
    "print(f\"    -> trainset[0][1]        : {trainset[0][1]}\")\n",
    "print(f\"    -> type(trainset)        : {type(trainset)}\")\n",
    "print(\n",
    "    f\"    -> trainset distribution : {torch.unique(trainset.dataset.targets[trainset.indices], return_counts=True)[1]}\\n\"\n",
    ")\n",
    "print(\"validationset:\")\n",
    "print(f\"    -> len(validationset)          : {len(validationset)}\")\n",
    "print(f\"    -> validationset[0][0]         : {validationset[0][0].shape}\")\n",
    "print(f\"    -> validationset[0][1]         : {validationset[0][1]}\")\n",
    "print(f\"    -> type(validationset)         : {type(validationset)}\")\n",
    "print(\n",
    "    f\"    -> validationset distribution : {torch.unique(validationset.dataset.targets[validationset.indices], return_counts=True)[1]}\\n\"\n",
    ")\n",
    "print(\"testset:\")\n",
    "print(f\"    -> len(testset)         : {len(testset)}\")\n",
    "print(f\"    -> testset[0][0]        : {testset[0][0].shape}\")\n",
    "print(f\"    -> testset[0][1]        : {testset[0][1]}\")\n",
    "print(f\"    -> type(testset)        : {type(testset)}\")\n",
    "print(f\"    -> testset distribution : {torch.unique(testset.targets, return_counts=True)[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc2_3_3_'></a>[Normalization](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a temporary DataLoader for the trainset\n",
    "temp_trainloader_x = next(iter(DataLoader(trainset, batch_size=len(trainset))))[0]\n",
    "\n",
    "# calculate the mean and standard deviation\n",
    "train_mean = temp_trainloader_x.mean().item()  # 0.1307\n",
    "train_std = temp_trainloader_x.std().item()  # 0.3081\n",
    "\n",
    "del temp_trainloader_x\n",
    "\n",
    "# log\n",
    "print(f\"mean of train set per channel : {train_mean}\")\n",
    "print(f\"std  of train set per channel : {train_std}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc2_3_3_1_'></a>[Append Normalization to the Transforms](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms.transforms.append(v2.Normalize(mean=(train_mean,), std=(train_std,)))\n",
    "\n",
    "# log\n",
    "print(f\"trainset.dataset.transforms:\\n{trainset.dataset.transforms}\\n\")\n",
    "print(f\"validationset.dataset.transforms:\\n{validationset.dataset.transforms}\\n\")\n",
    "print(f\"testset.transforms:\\n{testset.transforms}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "nrows, ncols = 4, 16\n",
    "fig, axs = plt.subplots(nrows, ncols, figsize=(ncols, nrows + 1), layout=\"compressed\")\n",
    "plt.suptitle(\"Transformed First 64 MNIST Test Set Samples\")\n",
    "for i in range(nrows):\n",
    "    for j in range(ncols):\n",
    "        axs[i, j].imshow(testset[i * ncols + j][0].squeeze(), cmap=\"gray\")\n",
    "        axs[i, j].set_title(testset.targets[i * ncols + j].item())\n",
    "        axs[i, j].axis(\"off\")\n",
    "plt.savefig(f\"{LOG_DIR}/transformed_testset_demo.png\", format=\"png\", bbox_inches=\"tight\", dpi=72)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc2_3_4_'></a>[Create DataLoaders](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(dataset=trainset, batch_size=TRAIN_BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "validationloader = DataLoader(dataset=validationset, batch_size=VALIDATION_BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "testloader = DataLoader(dataset=testset, batch_size=TEST_BATCH_SIZE, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log\n",
    "first_train_batch = next(iter(trainloader))\n",
    "first_validation_batch = next(iter(validationloader))\n",
    "first_test_batch = next(iter(testloader))\n",
    "\n",
    "print(\"trainloader [first batch]:\")\n",
    "print(f\"    -> x.shape: {first_train_batch[0].shape}\")\n",
    "print(f\"    -> x.dtype: {first_train_batch[0].dtype}\")\n",
    "print(f\"    -> y.shape: {first_train_batch[1].shape}\")\n",
    "print(f\"    -> y.dtype: {first_train_batch[1].dtype}\\n\")\n",
    "print(\"validationloader [first batch]:\")\n",
    "print(f\"    -> x.shape: {first_validation_batch[0].shape}\")\n",
    "print(f\"    -> x.dtype: {first_validation_batch[0].dtype}\")\n",
    "print(f\"    -> y.shape: {first_validation_batch[1].shape}\")\n",
    "print(f\"    -> y.dtype: {first_validation_batch[1].dtype}\\n\")\n",
    "print(\"testloader [first batch]:\")\n",
    "print(f\"    -> x.shape: {first_test_batch[0].shape}\")\n",
    "print(f\"    -> x.dtype: {first_test_batch[0].dtype}\")\n",
    "print(f\"    -> y.shape: {first_test_batch[1].shape}\")\n",
    "print(f\"    -> y.dtype: {first_test_batch[1].dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_4_'></a>[Custom MLP Model](#toc0_)\n",
    "\n",
    "üìö **Tutorials**:\n",
    "\n",
    "- **Gradient**\n",
    "  - Explore gradient calculations and backpropagation in neural networks\n",
    "  - check [vision-transforms.ipynb](../../../02-gradient.ipynb)\n",
    "- **Multi-Layer Perceptron**\n",
    "  - Learn how to build and train a custom MLP model for classification tasks\n",
    "  - check [multi-layer-perceptrons.ipynb](../../../05-multi-layer-perceptrons.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomMLP(nn.Module):\n",
    "    def __init__(self, input_dim: int, hidden_dims: list[int], output_dim: int):\n",
    "        super().__init__()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(start_dim=1),\n",
    "            nn.Linear(input_dim, hidden_dims[0]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dims[0], hidden_dims[1]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dims[1], output_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth, height, width = trainset[0][0].shape\n",
    "input_dim = depth * height * width\n",
    "hidden_dims = [64, 32]\n",
    "output_dim = num_classes\n",
    "\n",
    "# log\n",
    "print(f\"input  dim  : {input_dim}\")\n",
    "print(f\"hidden dims : {hidden_dims}\")\n",
    "print(f\"output dim  : {output_dim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the model\n",
    "model = CustomMLP(input_dim, hidden_dims, output_dim).to(device)\n",
    "\n",
    "# log\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model, input_size=(TRAIN_BATCH_SIZE, *trainset[0][0].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.5, patience=1, threshold=1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_5_'></a>[Train and Validation Loop](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc_per_epoch = []\n",
    "train_loss_per_epoch = []\n",
    "validation_acc_per_epoch = []\n",
    "validation_loss_per_epoch = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = MulticlassAccuracy(num_classes, top_k=1).to(device)\n",
    "val_acc = MulticlassAccuracy(num_classes, top_k=1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "\n",
    "    # train loop\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "\n",
    "    for x, y in trainloader:\n",
    "\n",
    "        # send data to GPU\n",
    "        x, y_true = x.to(device), y.to(device)\n",
    "\n",
    "        # forward\n",
    "        y_pred = model(x)\n",
    "        loss = criterion(y_pred, y_true)\n",
    "\n",
    "        # backward\n",
    "        loss.backward()\n",
    "\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # store loss and accuracy per iteration\n",
    "        train_loss += loss.item() * len(x)\n",
    "        train_acc.update(y_pred, y_true)\n",
    "\n",
    "    # store loss and accuracy per epoch\n",
    "    train_loss_per_epoch.append(train_loss / len(trainset))\n",
    "    train_acc_per_epoch.append(train_acc.compute().item())\n",
    "    train_acc.reset()\n",
    "\n",
    "    # validation loop\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in validationloader:\n",
    "\n",
    "            # send data to GPU\n",
    "            x, y_true = x.to(device), y.to(device)\n",
    "\n",
    "            # forward\n",
    "            y_pred = model(x)\n",
    "            loss = criterion(y_pred, y_true)\n",
    "\n",
    "            # store loss and accuracy per iteration\n",
    "            val_loss += loss.item() * len(x)\n",
    "            val_acc.update(y_pred, y_true)\n",
    "\n",
    "    # store loss and accuracy per epoch\n",
    "    validation_loss_per_epoch.append(val_loss / len(validationset))\n",
    "    validation_acc_per_epoch.append(val_acc.compute().item())\n",
    "    val_acc.reset()\n",
    "\n",
    "    # lr scheduler\n",
    "    scheduler.step(validation_loss_per_epoch[epoch])\n",
    "\n",
    "    # store train and validation metrics\n",
    "    logger.log_train_val(\n",
    "        epoch=f\"{epoch+1:0{len(str(EPOCHS))}}\",\n",
    "        lr=scheduler.get_last_lr()[0],\n",
    "        train_loss=train_loss_per_epoch[epoch],\n",
    "        train_acc=train_acc_per_epoch[epoch],\n",
    "        val_loss=validation_loss_per_epoch[epoch],\n",
    "        val_acc=validation_acc_per_epoch[epoch],\n",
    "    )\n",
    "\n",
    "    # log\n",
    "    print(\n",
    "        f\"epoch {epoch+1:0{len(str(EPOCHS))}}/{EPOCHS} -> lr: {scheduler.get_last_lr()[0]:.5f} | train[loss: {train_loss_per_epoch[epoch]:.5f} - acc: {train_acc_per_epoch[epoch]*100:5.2f}%] | validation[loss: {validation_loss_per_epoch[epoch]:.5f} - acc: {validation_acc_per_epoch[epoch]*100:5.2f}%]\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc2_5_1_'></a>[Analyze Loss and Accuracy over Epochs](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(14, 4), layout=\"compressed\")\n",
    "ax[0].plot(train_acc_per_epoch, label=\"Train Accuracy\", marker=\"o\", color=\"blue\")\n",
    "ax[0].plot(validation_acc_per_epoch, label=\"Validation Accuracy\", marker=\"o\", color=\"orange\")\n",
    "ax[0].set(\n",
    "    title=\"Accuracy Over Epochs\",\n",
    "    xlabel=\"Epoch\",\n",
    "    ylabel=\"Accuracy\",\n",
    "    xticks=range(EPOCHS),\n",
    ")\n",
    "ax[0].legend()\n",
    "ax[0].grid()\n",
    "ax[1].plot(train_loss_per_epoch, label=\"Train Loss\", marker=\"o\", color=\"blue\")\n",
    "ax[1].plot(validation_loss_per_epoch, label=\"Validation Loss\", marker=\"o\", color=\"orange\")\n",
    "ax[1].set(title=\"Loss Over Epochs\", xlabel=\"Epoch\", ylabel=\"Loss\", xticks=range(EPOCHS))\n",
    "ax[1].legend()\n",
    "ax[1].grid()\n",
    "plt.suptitle(\"Training and Validation Accuracy and Loss Over Epochs\")\n",
    "plt.savefig(f\"{LOG_DIR}/train_val_metrics.svg\", format=\"svg\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_6_'></a>[Test Loop](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k_acc = []\n",
    "true_labels = []\n",
    "predictions = []\n",
    "\n",
    "for k in range(test_top_k_acc):\n",
    "\n",
    "    model.eval()\n",
    "    test_acc = MulticlassAccuracy(num_classes, top_k=k + 1).to(device)\n",
    "    test_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y_true in testloader:\n",
    "\n",
    "            # move batch of features and labels to <device>\n",
    "            x, y_true = x.to(device), y_true.to(device)\n",
    "\n",
    "            # forward\n",
    "            y_pred = model(x)\n",
    "\n",
    "            # loss\n",
    "            loss = criterion(y_pred, y_true)\n",
    "\n",
    "            # store loss and accuracy per iteration\n",
    "            test_loss += loss.item() * len(x)\n",
    "            test_acc.update(y_pred, y_true)\n",
    "\n",
    "            # store predictions and true_labels\n",
    "            if k == 0:\n",
    "                predictions.extend(y_pred.argmax(dim=1).cpu())\n",
    "                true_labels.extend(y_true.cpu())\n",
    "\n",
    "    # store loss and accuracy per epoch\n",
    "    test_loss /= len(testset)\n",
    "    test_acc = test_acc.compute().item()\n",
    "    top_k_acc.append(test_acc)\n",
    "\n",
    "# log\n",
    "print(f\"test[loss: {test_loss:.5f} | {' - '.join(f'top_{i} acc: {a*100:5.2f}%' for i, a in enumerate(top_k_acc))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store test metrics\n",
    "logger.log_test(test_loss, *top_k_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = torch.tensor(predictions).to(\"cpu\")\n",
    "true_labels = torch.tensor(true_labels).to(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc2_6_1_'></a>[Plot Top_1 Confusion Matrix](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "confmat = MulticlassConfusionMatrix(num_classes)\n",
    "cm = confmat(predictions, true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store confusion matrix\n",
    "logger.log_confusion_matrix(cm, labels=[str(i) for i in testset.class_to_idx.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.set(title=\"Confusion Matrix based on top_1 accuracy\")\n",
    "confmat.plot(ax=ax, cmap=\"Blues\")\n",
    "cbar = plt.colorbar(ax.images[0], ax=ax)\n",
    "cbar.set_label(\"Count\", rotation=270, labelpad=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc2_6_2_'></a>[Classification Report](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_1 classification report\n",
    "print(classification_report(true_labels, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_7_'></a>[Prediction](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(\n",
    "    model: nn.Module, data: torch.Tensor, classes: list[str], transform: v2.Compose | None = None\n",
    ") -> torch.Tensor:\n",
    "\n",
    "    # add batch & channel dimension to a single data\n",
    "    if len(data.shape) == 2:\n",
    "        data = data[torch.newaxis, :, :, torch.newaxis]\n",
    "\n",
    "    # apply the transform\n",
    "    if transform:\n",
    "        data = torch.stack([transform(image) for image in data])\n",
    "\n",
    "    # predict\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "\n",
    "        # send data to GPU\n",
    "        data = data.to(device)\n",
    "\n",
    "        # forward\n",
    "        y_pred = model(data).argmax(dim=1).cpu()\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first 64 images of test set to demonstrate prediction section\n",
    "raw_data = MNIST(DATASET_DIR, train=False, transform=None, download=False).data[:64]\n",
    "y_pred = predict(model, data=raw_data, classes=classes, transform=transforms)\n",
    "\n",
    "# plot\n",
    "nrows, ncols = 4, 16\n",
    "fig, axs = plt.subplots(nrows, ncols, figsize=(ncols, nrows), layout=\"compressed\")\n",
    "for i in range(nrows):\n",
    "    for j in range(ncols):\n",
    "        axs[i, j].imshow(transforms(raw_data[i * ncols + j]).squeeze(), cmap=\"gray\")\n",
    "        axs[i, j].set_title(y_pred[i * ncols + j].item())\n",
    "        axs[i, j].axis(\"off\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "author_email": "AmirhosseinHeydari78@gmail.com",
  "author_github": "https://github.com/mr-pylin",
  "author_name": "Amirhossein Heydari",
  "kernelspec": {
   "display_name": "pytorch-workshop-U_zYfVTd-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "origin_repo": "https://github.com/mr-pylin/pytorch-workshop"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
