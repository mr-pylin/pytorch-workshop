{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ud83d\udcdd **Author:** Amirhossein Heydari - \ud83d\udce7 **Email:** amirhosseinheydari78@gmail.com - \ud83d\udccd **Linktree:** [linktr.ee/mr_pylin](https://linktr.ee/mr_pylin)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torchvision.transforms import v2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Normalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Base Normalization\n",
        "   - Min-Max normalization\n",
        "   - Z-score normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainset.data.shape : (50000, 32, 32, 3)\n",
            "trainset.data.dtype : uint8\n",
            "type(trainset.data) : <class 'numpy.ndarray'>\n"
          ]
        }
      ],
      "source": [
        "trainset = CIFAR10('./dataset', train=True, transform=None)\n",
        "\n",
        "# log\n",
        "print(f\"trainset.data.shape : {trainset.data.shape}\")\n",
        "print(f\"trainset.data.dtype : {trainset.data.dtype}\")\n",
        "print(f\"type(trainset.data) : {type(trainset.data)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.1. Min-Max\n",
        "   - there is no any built-in feature for this type of normalization in pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Minimum values per channel : [0 0 0]\n",
            "Maximum values per channel : [255 255 255]\n"
          ]
        }
      ],
      "source": [
        "min_value = trainset.data.min(axis=(0, 1, 2))\n",
        "max_value = trainset.data.max(axis=(0, 1, 2))\n",
        "\n",
        "# log\n",
        "print(f\"Minimum values per channel : {min_value}\")\n",
        "print(f\"Maximum values per channel : {max_value}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Minimum values for minmax_trainset_1 : [0. 0. 0.]\n",
            "Maximum values for minmax_trainset_1 : [1. 1. 1.]\n",
            "--------------------------------------------------\n",
            "Minimum values for minmax_trainset_2 : [-1. -1. -1.]\n",
            "Maximum values for minmax_trainset_2 : [1. 1. 1.]\n"
          ]
        }
      ],
      "source": [
        "# normalize to the range: (0, 1)\n",
        "minmax_trainset_1 = (trainset.data - min_value) / (max_value - min_value)\n",
        "\n",
        "# normalize to the range: (-1, 1)\n",
        "minmax_trainset_2 = minmax_trainset_1 * 2 - 1\n",
        "\n",
        "# log\n",
        "print(f\"Minimum values for minmax_trainset_1 : {minmax_trainset_1.min(axis=(0, 1, 2))}\")\n",
        "print(f\"Maximum values for minmax_trainset_1 : {minmax_trainset_1.max(axis=(0, 1, 2))}\")\n",
        "print('-' * 50)\n",
        "print(f\"Minimum values for minmax_trainset_2 : {minmax_trainset_2.min(axis=(0, 1, 2))}\")\n",
        "print(f\"Maximum values for minmax_trainset_2 : {minmax_trainset_2.max(axis=(0, 1, 2))}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.2. Z-score\n",
        "   - there is no any built-in feature for this type of normalization in pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean values per channel : [125.30691805 122.95039414 113.86538318]\n",
            "STD values per channel  : [62.99321928 62.08870764 66.70489964]\n"
          ]
        }
      ],
      "source": [
        "mean_value = trainset.data.mean(axis=(0, 1, 2))\n",
        "std_value  = trainset.data.std(axis=(0, 1, 2))\n",
        "\n",
        "# log\n",
        "print(f\"Mean values per channel : {mean_value}\")\n",
        "print(f\"STD values per channel  : {std_value}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean values for minmax_trainset_1 : [1.90680804e-17 9.16847154e-17 1.50768287e-17]\n",
            "STD values for minmax_trainset_1  : [1. 1. 1.]\n",
            "--------------------------------------------------\n",
            "Mean values for minmax_trainset_2 : [2. 2. 2.]\n",
            "STD values for minmax_trainset_2  : [5. 5. 5.]\n"
          ]
        }
      ],
      "source": [
        "# standardize with mean:0 and std:1\n",
        "zscore_trainset_1 = (trainset.data - mean_value) / std_value\n",
        "\n",
        "# standardize with mean:2 and std:5\n",
        "zscore_trainset_2 = zscore_trainset_1 * 5 + 2\n",
        "\n",
        "# log\n",
        "print(f\"Mean values for minmax_trainset_1 : {zscore_trainset_1.mean(axis=(0, 1, 2))}\")\n",
        "print(f\"STD values for minmax_trainset_1  : {zscore_trainset_1.std(axis=(0, 1, 2))}\")\n",
        "print('-' * 50)\n",
        "print(f\"Mean values for minmax_trainset_2 : {zscore_trainset_2.mean(axis=(0, 1, 2))}\")\n",
        "print(f\"STD values for minmax_trainset_2  : {zscore_trainset_2.std(axis=(0, 1, 2))}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Train Normalization\n",
        "   - Batch normalization\n",
        "   - Layer normalization\n",
        "   - Instance normalization\n",
        "   - group normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "transform = v2.Compose(\n",
        "    [\n",
        "        v2.ToImage(),\n",
        "        v2.ToDtype(torch.float32, scale=True),\n",
        "    ]\n",
        ")\n",
        "\n",
        "trainset = CIFAR10('./dataset', train=True, transform=transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "first_batch.shape : torch.Size([8, 3, 32, 32])\n",
            "first_batch.dtype : torch.float32\n",
            "type.first_batch) : <class 'torch.Tensor'>\n"
          ]
        }
      ],
      "source": [
        "batch_size = 8\n",
        "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "first_batch = next(iter(trainloader))[0]\n",
        "\n",
        "# log\n",
        "print(f\"first_batch.shape : {first_batch.shape}\")\n",
        "print(f\"first_batch.dtype : {first_batch.dtype}\")\n",
        "print(f\"type.first_batch) : {type(first_batch)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "features_maps.shape : torch.Size([8, 16, 30, 30])\n"
          ]
        }
      ],
      "source": [
        "in_channels = first_batch.shape[1]\n",
        "out_channels = 16\n",
        "\n",
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=3)\n",
        ")\n",
        "\n",
        "features_maps = model(first_batch)\n",
        "\n",
        "# log\n",
        "print(f\"features_maps.shape : {features_maps.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1. Batch Normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bn_mean.shape : torch.Size([1, 16, 1, 1])\n",
            "bn_std.shape  : torch.Size([1, 16, 1, 1])\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "bn_mean = features_maps.mean(dim=(0, 2, 3), keepdim=True)\n",
        "bn_std  = features_maps.std(dim=(0, 2, 3), keepdim=True)\n",
        "\n",
        "bn_result_1 = (features_maps - bn_mean) / bn_std\n",
        "bn_result_2 = torch.nn.BatchNorm2d(out_channels, affine=False, eps=0)(features_maps)\n",
        "\n",
        "# log\n",
        "print(f\"bn_mean.shape : {bn_mean.shape}\")\n",
        "print(f\"bn_std.shape  : {bn_std.shape}\")\n",
        "print(torch.allclose(bn_result_1, bn_result_2, atol=1e-03))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2. Layer Normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ln_mean.shape : torch.Size([8, 1, 1, 1])\n",
            "ln_std.shape  : torch.Size([8, 1, 1, 1])\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "ln_mean = features_maps.mean(dim=(1, 2, 3), keepdim=True)\n",
        "ln_std  = features_maps.std(dim=(1, 2, 3), keepdim=True)\n",
        "\n",
        "ln_result_1 = (features_maps - ln_mean) / ln_std\n",
        "ln_result_2 = torch.nn.LayerNorm(features_maps.shape[1:], elementwise_affine=False, eps=0)(features_maps)\n",
        "\n",
        "# log\n",
        "print(f\"ln_mean.shape : {ln_mean.shape}\")\n",
        "print(f\"ln_std.shape  : {ln_std.shape}\")\n",
        "print(torch.allclose(ln_result_1, ln_result_2, atol=1e-03))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.3. Instance Normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "in_mean.shape : torch.Size([8, 16, 1, 1])\n",
            "in_std.shape  : torch.Size([8, 16, 1, 1])\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "in_mean = features_maps.mean(dim=(2, 3), keepdim=True)\n",
        "in_std  = features_maps.std(dim=(2, 3), keepdim=True)\n",
        "\n",
        "in_result_1 = (features_maps - in_mean) / in_std\n",
        "in_result_2 = torch.nn.InstanceNorm2d(out_channels, affine=False, eps=0)(features_maps)\n",
        "\n",
        "# log\n",
        "print(f\"in_mean.shape : {in_mean.shape}\")\n",
        "print(f\"in_std.shape  : {in_std.shape}\")\n",
        "print(torch.allclose(in_result_1, in_result_2, atol=1e-02))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.4. Group Normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "gn_mean_1.shape : torch.Size([8, 1, 1, 1])\n",
            "gn_std_1.shape  : torch.Size([8, 1, 1, 1])\n",
            "gn_mean_2.shape : torch.Size([8, 1, 1, 1])\n",
            "gn_std_2.shape  : torch.Size([8, 1, 1, 1])\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "groups = [features_maps[:, :8, :, :], features_maps[:, 8:, :, :]]\n",
        "\n",
        "gn_mean_1 = groups[0].mean(dim=(1, 2, 3), keepdim=True)\n",
        "gn_std_1  = groups[0].std(dim=(1, 2, 3), keepdim=True)\n",
        "result_1  = (groups[0] - gn_mean_1) / gn_std_1\n",
        "\n",
        "gn_mean_2 = groups[1].mean(dim=(1, 2, 3), keepdim=True)\n",
        "gn_std_2  = groups[1].std(dim=(1, 2, 3), keepdim=True)\n",
        "result_2  = (groups[1] - gn_mean_2) / gn_std_2\n",
        "\n",
        "gn_result_1 = torch.concatenate([result_1, result_2], dim=1)\n",
        "gn_result_2 = torch.nn.GroupNorm(num_groups=2, num_channels=out_channels, affine=False)(features_maps)\n",
        "\n",
        "# log\n",
        "print(f\"gn_mean_1.shape : {gn_mean_1.shape}\")\n",
        "print(f\"gn_std_1.shape  : {gn_std_1.shape}\")\n",
        "print(f\"gn_mean_2.shape : {gn_mean_2.shape}\")\n",
        "print(f\"gn_std_2.shape  : {gn_std_2.shape}\")\n",
        "print(torch.allclose(gn_result_1, gn_result_2, atol=1e-03))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "author_name": "Amirhossein Heydari",
    "author_email": "AmirhosseinHeydari78@gmail.com",
    "author_github": "https://github.com/mr-pylin",
    "origin_repo": "https://github.com/mr-pylin/pytorch-workshop"
  },
  "nbformat": 4,
  "nbformat_minor": 2
}