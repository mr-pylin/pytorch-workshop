{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ud83d\udcdd **Author:** Amirhossein Heydari - \ud83d\udce7 **Email:** amirhosseinheydari78@gmail.com - \ud83d\udccd **Linktree:** [linktr.ee/mr_pylin](https://linktr.ee/mr_pylin)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.metrics import classification_report\n",
        "from torch import nn\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchinfo import summary\n",
        "from torchmetrics import Accuracy, ConfusionMatrix\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torchvision.transforms import v2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# set a seed for deterministic results\n",
        "random_state = 42\n",
        "torch.manual_seed(random_state)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'cuda'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# check if cuda is available\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Pre-Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "trainset:\n",
            "    -> trainset.data.shape    : (50000, 32, 32, 3)\n",
            "    -> trainset.data.dtype    : uint8\n",
            "    -> type(trainset.data)    : <class 'numpy.ndarray'>\n",
            "    -> type(trainset.targets) : <class 'list'>\n",
            "--------------------------------------------------\n",
            "testset:\n",
            "    -> testset.data.shape     : (10000, 32, 32, 3)\n",
            "    -> testset.data.dtype     : uint8\n",
            "    -> type(testset.data)     : <class 'numpy.ndarray'>\n",
            "    -> type(testset.targets)  : <class 'list'>\n",
            "--------------------------------------------------\n",
            "classes: {'airplane': 0, 'automobile': 1, 'bird': 2, 'cat': 3, 'deer': 4, 'dog': 5, 'frog': 6, 'horse': 7, 'ship': 8, 'truck': 9}\n",
            "trainset distribution: [5000 5000 5000 5000 5000 5000 5000 5000 5000 5000]\n",
            "testset  distribution: [1000 1000 1000 1000 1000 1000 1000 1000 1000 1000]\n"
          ]
        }
      ],
      "source": [
        "# initial transforms\n",
        "transforms = v2.Compose(\n",
        "    [\n",
        "        v2.ToImage(),\n",
        "        v2.ToDtype(torch.float32, scale=True)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# load the CIFAR-10 dataset\n",
        "trainset = CIFAR10(root='./dataset', train=True , download=True, transform=transforms)\n",
        "testset  = CIFAR10(root='./dataset', train=False, download=True, transform=transforms)\n",
        "\n",
        "# log\n",
        "print('trainset:')\n",
        "print(f\"    -> trainset.data.shape    : {trainset.data.shape}\")\n",
        "print(f\"    -> trainset.data.dtype    : {trainset.data.dtype}\")\n",
        "print(f\"    -> type(trainset.data)    : {type(trainset.data)}\")\n",
        "print(f\"    -> type(trainset.targets) : {type(trainset.targets)}\")\n",
        "print('-' * 50)\n",
        "print('testset:')\n",
        "print(f\"    -> testset.data.shape     : {testset.data.shape}\")\n",
        "print(f\"    -> testset.data.dtype     : {testset.data.dtype}\")\n",
        "print(f\"    -> type(testset.data)     : {type(testset.data)}\")\n",
        "print(f\"    -> type(testset.targets)  : {type(testset.targets)}\")\n",
        "print('-' * 50)\n",
        "print(f\"classes: {trainset.class_to_idx}\")\n",
        "print(f\"trainset distribution: {np.unique(trainset.targets, return_counts=True)[1]}\")\n",
        "print(f\"testset  distribution: {np.unique(testset.targets, return_counts=True)[1]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# plot\n",
        "fig, axs = plt.subplots(nrows=4, ncols=8, figsize=(12, 6), layout='compressed')\n",
        "for i in range(4):\n",
        "    for j in range(8):\n",
        "        axs[i, j].imshow(trainset.data[i * 8 + j], cmap='gray')\n",
        "        axs[i, j].set_title(trainset.classes[trainset.targets[i * 8 + j]])\n",
        "        axs[i, j].axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Split trainset into [trainset, validationset]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainset:\n",
            "    -> len(trainset)       : 45000\n",
            "    -> trainset[0][0]      : torch.Size([3, 32, 32])\n",
            "    -> trainset[0][1]      : 6\n",
            "\n",
            "validationset:\n",
            "    -> len(validationset)  : 5000\n",
            "    -> validationset[0][0] : torch.Size([3, 32, 32])\n",
            "    -> validationset[0][1] : 7\n",
            "\n",
            "testset:\n",
            "    -> len(testset)        : 10000\n",
            "    -> testset[0][0]       : torch.Size([3, 32, 32])\n",
            "    -> testset[0][1]       : 3\n"
          ]
        }
      ],
      "source": [
        "# random split\n",
        "trainset, validationset = random_split(trainset, [.9, .1])\n",
        "\n",
        "# log\n",
        "print('trainset:')\n",
        "print(f\"    -> len(trainset)       : {len(trainset)}\")\n",
        "print(f\"    -> trainset[0][0]      : {trainset[0][0].shape}\")\n",
        "print(f\"    -> trainset[0][1]      : {trainset[0][1]}\\n\")\n",
        "print('validationset:')\n",
        "print(f\"    -> len(validationset)  : {len(validationset)}\")\n",
        "print(f\"    -> validationset[0][0] : {validationset[0][0].shape}\")\n",
        "print(f\"    -> validationset[0][1] : {validationset[0][1]}\\n\")\n",
        "print('testset:')\n",
        "print(f\"    -> len(testset)        : {len(testset)}\")\n",
        "print(f\"    -> testset[0][0]       : {testset[0][0].shape}\")\n",
        "print(f\"    -> testset[0][1]       : {testset[0][1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train mean per channel : tensor([0.4917, 0.4823, 0.4467])\n",
            "train std  per channel : tensor([0.2471, 0.2435, 0.2616])\n"
          ]
        }
      ],
      "source": [
        "# create a temporary DataLoader for the trainset\n",
        "temp_trainloader = DataLoader(trainset, batch_size=len(trainset))\n",
        "\n",
        "# get the whole data\n",
        "temp_dataset = next(iter(temp_trainloader))\n",
        "\n",
        "# calculate the mean and standard deviation [PER CHANNEL]\n",
        "train_mean = temp_dataset[0].mean(axis=(0, 2, 3))  # [0.4917, 0.4823, 0.4467]\n",
        "train_std = temp_dataset[0].std(axis=(0, 2, 3))  # [0.2471, 0.2435, 0.2616]\n",
        "\n",
        "del temp_trainloader\n",
        "del temp_dataset\n",
        "\n",
        "# log\n",
        "print(f\"train mean per channel : {train_mean}\")\n",
        "print(f\"train std  per channel : {train_std}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Transform\n",
        "   - on-the-fly data augmentation\n",
        "   - Disadvantage:\n",
        "      - same transform applies to the same data in each epoch\n",
        "   - Advantage:\n",
        "      - Reduced Memory Usage, Regularization & Data Diversity [random transforms e.g. RancomCrop]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Compose(\n",
              "      ToImage()\n",
              "      ToDtype(scale=True)\n",
              ")"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainset.dataset.transforms:\n",
            "StandardTransform\n",
            "Transform: Compose(\n",
            "                 ToImage()\n",
            "                 ToDtype(scale=True)\n",
            "                 Normalize(mean=[tensor(0.4917), tensor(0.4823), tensor(0.4467)], std=[tensor(0.2471), tensor(0.2435), tensor(0.2616)], inplace=False)\n",
            "           )\n",
            "\n",
            "validationset.dataset.transforms:\n",
            "StandardTransform\n",
            "Transform: Compose(\n",
            "                 ToImage()\n",
            "                 ToDtype(scale=True)\n",
            "                 Normalize(mean=[tensor(0.4917), tensor(0.4823), tensor(0.4467)], std=[tensor(0.2471), tensor(0.2435), tensor(0.2616)], inplace=False)\n",
            "           )\n",
            "\n",
            "testset.transforms:\n",
            "StandardTransform\n",
            "Transform: Compose(\n",
            "                 ToImage()\n",
            "                 ToDtype(scale=True)\n",
            "                 Normalize(mean=[tensor(0.4917), tensor(0.4823), tensor(0.4467)], std=[tensor(0.2471), tensor(0.2435), tensor(0.2616)], inplace=False)\n",
            "           )\n"
          ]
        }
      ],
      "source": [
        "transforms.transforms.append(v2.Normalize(mean=train_mean, std=train_std))\n",
        "\n",
        "# log\n",
        "print(f\"trainset.dataset.transforms:\\n{trainset.dataset.transforms}\\n\")\n",
        "print(f\"validationset.dataset.transforms:\\n{validationset.dataset.transforms}\\n\")\n",
        "print(f\"testset.transforms:\\n{testset.transforms}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "before applying transform:\n",
            "    -> type(testset.data[0]) : <class 'numpy.ndarray'>\n",
            "    -> testset.data[0].dtype : uint8\n",
            "    -> testset.data[0].shape : (32, 32, 3)\n",
            "--------------------------------------------------\n",
            "after applying transform:\n",
            "    -> type(testset[0][0])   : <class 'torchvision.tv_tensors._image.Image'>\n",
            "    -> testset[0][0].dtype   : torch.float32\n",
            "    -> testset[0][0].shape   : torch.Size([3, 32, 32])\n"
          ]
        }
      ],
      "source": [
        "# log\n",
        "print(\"before applying transform:\")\n",
        "print(f\"    -> type(testset.data[0]) : {type(testset.data[0])}\")\n",
        "print(f\"    -> testset.data[0].dtype : {testset.data[0].dtype}\")\n",
        "print(f\"    -> testset.data[0].shape : {testset.data[0].shape}\")\n",
        "print('-' * 50)\n",
        "print(\"after applying transform:\")\n",
        "print(f\"    -> type(testset[0][0])   : {type(testset[0][0])}\")\n",
        "print(f\"    -> testset[0][0].dtype   : {testset[0][0].dtype}\")\n",
        "print(f\"    -> testset[0][0].shape   : {testset[0][0].shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "\n",
        "trainloader      = DataLoader(dataset=trainset     , batch_size=batch_size, shuffle=True , num_workers=2)\n",
        "validationloader = DataLoader(dataset=validationset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "testloader       = DataLoader(dataset=testset      , batch_size=batch_size, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainloader      first batch     -> x.shape: torch.Size([64, 3, 32, 32]) - y.shape: torch.Size([64]) - x.dtype: torch.float32 - y.dtype: torch.int64\n",
            "validationloader first batch     -> x.shape: torch.Size([64, 3, 32, 32]) - y.shape: torch.Size([64]) - x.dtype: torch.float32 - y.dtype: torch.int64\n",
            "testloader       first batch     -> x.shape: torch.Size([64, 3, 32, 32]) - y.shape: torch.Size([64]) - x.dtype: torch.float32 - y.dtype: torch.int64\n",
            "trainloader      last batch-size -> 8\n",
            "validationloader last batch-size -> 8\n",
            "testloader       last batch-size -> 16\n"
          ]
        }
      ],
      "source": [
        "first_train_batch = next(iter(trainloader))\n",
        "first_validation_batch = next(iter(validationloader))\n",
        "first_test_batch = next(iter(testloader))\n",
        "\n",
        "print(f\"trainloader      first batch     -> x.shape: {first_train_batch[0].shape} - y.shape: {first_train_batch[1].shape} - x.dtype: {first_train_batch[0].dtype} - y.dtype: {first_train_batch[1].dtype}\")\n",
        "print(f\"validationloader first batch     -> x.shape: {first_validation_batch[0].shape} - y.shape: {first_validation_batch[1].shape} - x.dtype: {first_validation_batch[0].dtype} - y.dtype: {first_validation_batch[1].dtype}\")\n",
        "print(f\"testloader       first batch     -> x.shape: {first_test_batch[0].shape} - y.shape: {first_test_batch[1].shape} - x.dtype: {first_test_batch[0].dtype} - y.dtype: {first_test_batch[1].dtype}\")\n",
        "print(f\"trainloader      last batch-size -> {len(trainset) % batch_size}\")\n",
        "print(f\"validationloader last batch-size -> {len(validationset) % batch_size}\")\n",
        "print(f\"testloader       last batch-size -> {len(testset) % batch_size}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Network Structure: Convolutional Neural Networks\n",
        "   - Sequential Model\n",
        "      - Use torch.nn.Sequential to create a sequence of layers or modules\n",
        "      - [pytorch.org/docs/stable/generated/torch.nn.Sequential.html](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html)\n",
        "   - Functional Model\n",
        "      - for stateless operations like activation functions, loss functions, and other operations within the forward method of custom modules or in custom functions\n",
        "      - [pytorch.org/docs/stable/nn.functional.html](https://pytorch.org/docs/stable/nn.functional.html)\n",
        "   - Mixed Model\n",
        "\n",
        "**Notes**:\n",
        "   - `torch.nn.Conv2d`\n",
        "      - loss function : \n",
        "         - multi-class classification : `torch.nn.CrossEntropyLoss` = `torch.nn.LogSoftmax` + `torch.nn.NLLLoss`\n",
        "         - [pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html)\n",
        "         - [pytorch.org/docs/stable/generated/torch.nn.NLLLoss.html](https://pytorch.org/docs/stable/generated/torch.nn.NLLLoss.html)\n",
        "      - activation function for the last layer:\n",
        "         - when using `torch.nn.CrossEntropyLoss` as a loss function, the output layer doesn't need an activation function\n",
        "         - `torch.nn.CrossEntropyLoss` calculates `torch.nn.LogSoftmax` and `torch.nn.NLLLoss` internally.\n",
        "         - [pytorch.org/docs/stable/generated/torch.nn.Softmax.html](https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html)\n",
        "         - [pytorch.org/docs/stable/generated/torch.nn.LogSoftmax.html](https://pytorch.org/docs/stable/generated/torch.nn.LogSoftmax.html)\n",
        "      - Weights\n",
        "         - Initialized based on a scheme similar to Kaiming/He initialization\n",
        "         - Uniform Distribution [default]: $W \\sim \\mathcal{U}\\left(-\\sqrt{\\frac{6}{n_{\\text{in}}}}, \\sqrt{\\frac{6}{n_{\\text{in}}}}\\right)$\n",
        "         - Normal Distribution: $W \\sim \\mathcal{N}\\left(0, \\frac{2}{n_{\\text{in}}}\\right)$\n",
        "      - Biases:\n",
        "         - Initialized to zero\n",
        "      - [pytorch.org/docs/stable/nn.init.html](https://pytorch.org/docs/stable/nn.init.html)\n",
        "      - Paper: [Delving deep into rectifiers: Surpassing human-level performance on ImageNet classification - He, K. et al. (2015).](https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/He_Delving_Deep_into_ICCV_2015_paper.pdf)\n",
        "\n",
        "**Playground**:\n",
        "   - [poloclub.github.io/cnn-explainer](https://poloclub.github.io/cnn-explainer/)\n",
        "   - [convnetplayground.fastforwardlabs.com](https://convnetplayground.fastforwardlabs.com/)\n",
        "   - [alexlenail.me/NN-SVG](https://alexlenail.me/NN-SVG/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<figure style=\"text-align: center;\">\n",
        "    <img src=\"../../assets/images/original/convolutional-neural-network.svg\" alt=\"convolutional-neural-network.svg\" style=\"width: 100%;\">\n",
        "    <figcaption>Convolutional Neural Networks Model</figcaption>\n",
        "</figure>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<table style=\"margin-left:auto;margin-right:auto;text-align:center;\">\n",
        "  <thead>\n",
        "    <tr>\n",
        "      <th colspan=\"4\" style=\"text-align:center;\">Feature Extraction</th>\n",
        "      <th colspan=\"4\" style=\"text-align:center;\">Classification</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th colspan=\"2\">Convolution_1 parameters</th>\n",
        "      <th colspan=\"2\">Convolution_2 parameters</th>\n",
        "      <th colspan=\"2\">hidden<sub>1</sub> parameters</th>\n",
        "      <th colspan=\"2\">logits parameters</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <td>Weights</td>\n",
        "      <td>Biases</td>\n",
        "      <td>Weights</td>\n",
        "      <td>Biases</td>\n",
        "      <td>Weights</td>\n",
        "      <td>Biases</td>\n",
        "      <td>Weights</td>\n",
        "      <td>Biases</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td>(1 x 3 \u00d7 3) \u00d7 A</td>\n",
        "      <td>A</td>\n",
        "      <td>(A x 3 \u00d7 3) \u00d7 B</td>\n",
        "      <td>B</td>\n",
        "      <td>C \u00d7 D</td>\n",
        "      <td>D</td>\n",
        "      <td>D \u00d7 E</td>\n",
        "      <td>E</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "  <tfoot>\n",
        "    <tr>\n",
        "      <td colspan=\"2\">(1 \u00d7 3 \u00d7 3 + 1) \u00d7 A</td>\n",
        "      <td colspan=\"2\">(A \u00d7 3 \u00d7 3 + 1) \u00d7 B</td>\n",
        "      <td colspan=\"2\">(C + 1) \u00d7 D</td>\n",
        "      <td colspan=\"2\">(D + 1) \u00d7 E</td>\n",
        "    </tr>\n",
        "  </tfoot>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CIFAR10Model(nn.Module):\n",
        "    def __init__(self, in_channels, output_dim):\n",
        "        super(CIFAR10Model, self).__init__()\n",
        "        self.feature_extractor = nn.Sequential(\n",
        "\n",
        "            # 3x32x32\n",
        "            nn.Conv2d(in_channels, out_channels=32, kernel_size=3),\n",
        "            nn.BatchNorm2d(32),  # StandardScaler along channel axis\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "            # 32x15x15\n",
        "\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "            # 64x6x6\n",
        "\n",
        "            nn.AdaptiveAvgPool2d(output_size=(1, 1))\n",
        "            # 64x1x1\n",
        "        )\n",
        "\n",
        "        self.flatten = nn.Flatten(start_dim=1)\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(64, output_dim),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.feature_extractor(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "CIFAR10Model(\n",
              "  (feature_extractor): Sequential(\n",
              "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (6): ReLU()\n",
              "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  )\n",
              "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=64, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "in_channels = trainset[0][0].shape[0]\n",
        "output_dim = len(trainset.dataset.classes)\n",
        "\n",
        "model = CIFAR10Model(in_channels, output_dim)\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "CIFAR10Model                             [64, 10]                  --\n",
              "\u251c\u2500Sequential: 1-1                        [64, 64, 1, 1]            --\n",
              "\u2502    \u2514\u2500Conv2d: 2-1                       [64, 32, 30, 30]          896\n",
              "\u2502    \u2514\u2500BatchNorm2d: 2-2                  [64, 32, 30, 30]          64\n",
              "\u2502    \u2514\u2500ReLU: 2-3                         [64, 32, 30, 30]          --\n",
              "\u2502    \u2514\u2500MaxPool2d: 2-4                    [64, 32, 15, 15]          --\n",
              "\u2502    \u2514\u2500Conv2d: 2-5                       [64, 64, 13, 13]          18,496\n",
              "\u2502    \u2514\u2500BatchNorm2d: 2-6                  [64, 64, 13, 13]          128\n",
              "\u2502    \u2514\u2500ReLU: 2-7                         [64, 64, 13, 13]          --\n",
              "\u2502    \u2514\u2500MaxPool2d: 2-8                    [64, 64, 6, 6]            --\n",
              "\u2502    \u2514\u2500AdaptiveAvgPool2d: 2-9            [64, 64, 1, 1]            --\n",
              "\u251c\u2500Flatten: 1-2                           [64, 64]                  --\n",
              "\u251c\u2500Sequential: 1-3                        [64, 10]                  --\n",
              "\u2502    \u2514\u2500Linear: 2-10                      [64, 10]                  650\n",
              "==========================================================================================\n",
              "Total params: 20,234\n",
              "Trainable params: 20,234\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (Units.MEGABYTES): 251.72\n",
              "==========================================================================================\n",
              "Input size (MB): 0.79\n",
              "Forward/backward pass size (MB): 40.57\n",
              "Params size (MB): 0.08\n",
              "Estimated Total Size (MB): 41.44\n",
              "=========================================================================================="
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "summary(model, input_size=(batch_size, *testset.data.transpose(0, 3, 1, 2).shape[1:]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Set up remaining Hyper-Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "lr = 0.01\n",
        "criterion = CrossEntropyLoss()\n",
        "optimizer = Adam(params=model.parameters(), lr=lr)\n",
        "num_epochs = 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Train & Validation Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_acc_per_epoch  = []\n",
        "train_loss_per_epoch = []\n",
        "val_acc_per_epoch    = []\n",
        "val_loss_per_epoch   = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_acc = Accuracy(task='multiclass', num_classes=len(testset.classes), top_k=1).to(device)\n",
        "val_acc   = Accuracy(task='multiclass', num_classes=len(testset.classes), top_k=1).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 0  ->  train[loss: 1.53168 - acc: 0.44] | validation[loss: 1.49292 - acc: 0.48]\n",
            "epoch 1  ->  train[loss: 1.28642 - acc: 0.54] | validation[loss: 1.23919 - acc: 0.57]\n",
            "epoch 2  ->  train[loss: 1.20031 - acc: 0.58] | validation[loss: 1.59825 - acc: 0.46]\n",
            "epoch 3  ->  train[loss: 1.14244 - acc: 0.60] | validation[loss: 1.16952 - acc: 0.60]\n",
            "epoch 4  ->  train[loss: 1.08944 - acc: 0.62] | validation[loss: 1.22298 - acc: 0.57]\n",
            "epoch 5  ->  train[loss: 1.04375 - acc: 0.64] | validation[loss: 1.24219 - acc: 0.58]\n",
            "epoch 6  ->  train[loss: 1.01026 - acc: 0.65] | validation[loss: 1.10631 - acc: 0.61]\n",
            "epoch 7  ->  train[loss: 0.98565 - acc: 0.66] | validation[loss: 1.02241 - acc: 0.64]\n",
            "epoch 8  ->  train[loss: 0.95677 - acc: 0.67] | validation[loss: 1.19718 - acc: 0.62]\n",
            "epoch 9  ->  train[loss: 0.93040 - acc: 0.68] | validation[loss: 1.10159 - acc: 0.62]\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(num_epochs):\n",
        "\n",
        "# train loop\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "\n",
        "    for x, y in trainloader:\n",
        "\n",
        "        # send data to GPU\n",
        "        x, y_true = x.to(device), y.to(device)\n",
        "\n",
        "        # forward\n",
        "        y_pred = model(x)\n",
        "        loss = criterion(y_pred, y_true)\n",
        "\n",
        "        # backward\n",
        "        loss.backward()\n",
        "\n",
        "        # update parameters\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # log loss & accuracy\n",
        "        train_loss += loss.item() * len(x)\n",
        "        train_acc.update(y_pred, y_true)\n",
        "\n",
        "    # store intermediate loss & accuracy\n",
        "    train_loss_per_epoch.append(train_loss / len(trainset))\n",
        "    train_acc_per_epoch.append(train_acc.compute().item())\n",
        "    train_acc.reset()\n",
        "\n",
        "\n",
        "# validation loop\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y in validationloader:\n",
        "\n",
        "            # send data to GPU\n",
        "            x, y_true = x.to(device), y.to(device)\n",
        "\n",
        "            # forward\n",
        "            y_pred = model(x)\n",
        "            loss = criterion(y_pred, y_true)\n",
        "\n",
        "            # log loss & accuracy\n",
        "            val_loss += loss.item() * len(x)\n",
        "            val_acc.update(y_pred, y_true)\n",
        "\n",
        "    # store intermediate loss & accuracy\n",
        "    val_loss_per_epoch.append(val_loss / len(validationset))\n",
        "    val_acc_per_epoch.append(val_acc.compute().item())\n",
        "    val_acc.reset()\n",
        "\n",
        "    # log\n",
        "    print(f\"epoch {epoch:>1}  ->  train[loss: {train_loss_per_epoch[epoch]:.5f} - acc: {train_acc_per_epoch[epoch]:.2f}] | validation[loss: {val_loss_per_epoch[epoch]:.5f} - acc: {val_acc_per_epoch[epoch]:.2f}]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# plot\n",
        "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(10, 4), layout='compressed')\n",
        "axs[0].plot(train_loss_per_epoch, label=\"Train loss\")\n",
        "axs[0].plot(val_loss_per_epoch, label=\"Validation loss\")\n",
        "axs[0].set(title=\"Loss over time\", xlabel='Epoch', ylabel='Loss')\n",
        "axs[0].legend(loc='best', fancybox=True, shadow=True)\n",
        "axs[1].plot(train_acc_per_epoch, label=\"Train accuracy\")\n",
        "axs[1].plot(val_acc_per_epoch, label=\"Validation accuracy\")\n",
        "axs[1].set(title=\"Accuracy over time\", xlabel='Epoch', ylabel='Accuracy')\n",
        "axs[1].legend(loc='best', fancybox=True, shadow=True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Test Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_acc = Accuracy(task='multiclass', num_classes=len(testset.classes), top_k=1).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test[loss: 1.07869 - acc: 0.62]\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "test_loss = 0\n",
        "predictions = []\n",
        "targets = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for x, y in testloader:\n",
        "\n",
        "        # send data to GPU\n",
        "        x, y_true = x.to(device), y.to(device)\n",
        "\n",
        "        # forward\n",
        "        y_pred = model(x)\n",
        "        loss = criterion(y_pred, y_true)\n",
        "\n",
        "        # log loss & accuracy\n",
        "        test_loss += loss.item() * len(x)\n",
        "        test_acc.update(y_pred, y_true)\n",
        "\n",
        "        predictions.extend(y_pred.argmax(dim=1).cpu())\n",
        "        targets.extend(y_true.cpu())\n",
        "\n",
        "# log\n",
        "print(f\"test[loss: {test_loss / len(testset):.5f} - acc: {test_acc.compute().item():.2f}]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Metrics\n",
        "   - Loss\n",
        "   - Accuracy\n",
        "   - Recall\n",
        "   - Precision\n",
        "   - F1-Score\n",
        "   - Confusion Matrix\n",
        "   - Area Under the ROC Curve (AUC-ROC)\n",
        "   - Area Under the Precision-Recall Curve (AUC-PR)\n",
        "   - ...\n",
        "\n",
        "**Docs**:\n",
        "   - [lightning.ai/docs/torchmetrics/stable/all-metrics.html](https://lightning.ai/docs/torchmetrics/stable/all-metrics.html)\n",
        "   - [scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.59      0.66      1000\n",
            "           1       0.85      0.71      0.77      1000\n",
            "           2       0.61      0.45      0.52      1000\n",
            "           3       0.52      0.39      0.44      1000\n",
            "           4       0.36      0.87      0.51      1000\n",
            "           5       0.76      0.38      0.51      1000\n",
            "           6       0.77      0.60      0.67      1000\n",
            "           7       0.62      0.66      0.64      1000\n",
            "           8       0.79      0.76      0.78      1000\n",
            "           9       0.70      0.82      0.75      1000\n",
            "\n",
            "    accuracy                           0.62     10000\n",
            "   macro avg       0.67      0.62      0.63     10000\n",
            "weighted avg       0.67      0.62      0.63     10000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# classification report\n",
        "print(classification_report(targets, predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[587,  31,  63,  16,  85,   4,  10,  41, 109,  54],\n",
            "        [ 18, 710,  14,   8,  37,   1,   4,  15,  22, 171],\n",
            "        [ 49,   3, 453,  55, 270,  17,  60,  72,  12,   9],\n",
            "        [ 11,   3,  57, 388, 306,  70,  57,  68,  11,  29],\n",
            "        [  8,   2,  25,  24, 870,   5,  26,  33,   3,   4],\n",
            "        [  8,   5,  42, 169, 239, 383,  17, 119,  10,   8],\n",
            "        [  3,   1,  53,  37, 274,   5, 601,  16,   5,   5],\n",
            "        [  9,   1,  21,  26, 253,  20,   2, 656,   1,  11],\n",
            "        [ 65,  31,   9,  15,  46,   0,   3,  17, 759,  55],\n",
            "        [ 11,  46,   7,  11,  56,   1,   3,  25,  24, 816]])\n"
          ]
        }
      ],
      "source": [
        "# confusion matrix\n",
        "metric = ConfusionMatrix(task='multiclass', num_classes=10)\n",
        "confusion_matrix = metric(torch.tensor(predictions), torch.tensor(targets))\n",
        "\n",
        "# log\n",
        "print(confusion_matrix)\n",
        "\n",
        "# plot\n",
        "fig, ax = plt.subplots(figsize=(8, 8))\n",
        "metric.plot(ax=ax)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "def predict(model: nn.Module, data: np.ndarray, classes: list, transform: v2._container.Compose = None) -> torch.Tensor:\n",
        "\n",
        "    # add batch dimension to a single data\n",
        "    if len(data.shape) == 3:\n",
        "        data = np.expand_dims(data, axis=0)\n",
        "\n",
        "    # apply the transform\n",
        "    if transform:\n",
        "        data = torch.stack([transform(sample) for sample in data])\n",
        "\n",
        "    # predict\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "\n",
        "        # send data to GPU\n",
        "        data = data.to(device)\n",
        "\n",
        "        # forward\n",
        "        y_pred = model(data).argmax(dim=1).cpu()\n",
        "\n",
        "        # idx to labels\n",
        "        y_pred = np.array(classes)[y_pred]\n",
        "\n",
        "    return y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "predictions:\n",
            "['cat' 'ship' 'ship' 'airplane' 'frog' 'frog' 'automobile' 'deer' 'deer'\n",
            " 'automobile' 'ship' 'truck' 'cat' 'horse' 'truck' 'ship' 'dog' 'horse'\n",
            " 'truck' 'frog' 'horse' 'airplane' 'deer' 'truck' 'deer' 'deer' 'cat'\n",
            " 'bird' 'truck' 'deer' 'frog' 'dog']\n"
          ]
        }
      ],
      "source": [
        "# some raw data\n",
        "raw_data = CIFAR10(root='./dataset', train=False, download=True, transform=None).data[:32]\n",
        "\n",
        "# predict\n",
        "y_pred = predict(model, data=raw_data, classes=testset.classes, transform=transforms)\n",
        "\n",
        "# log\n",
        "print(f\"predictions:\\n{y_pred}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# plot\n",
        "fig, axs = plt.subplots(nrows=4, ncols=8, figsize=(12, 6), layout='compressed')\n",
        "for i in range(4):\n",
        "    for j in range(8):\n",
        "        axs[i, j].imshow(raw_data[i * 8 + j], cmap='gray')\n",
        "        axs[i, j].set_title(predict(model, raw_data[i * 8 + j], testset.classes, transform=transforms))\n",
        "        axs[i, j].axis('off')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "author_name": "Amirhossein Heydari",
    "author_email": "AmirhosseinHeydari78@gmail.com",
    "author_github": "https://github.com/mr-pylin",
    "origin_repo": "https://github.com/mr-pylin/pytorch-workshop"
  },
  "nbformat": 4,
  "nbformat_minor": 2
}