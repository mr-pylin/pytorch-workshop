{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "📝 **Author:** Amirhossein Heydari - 📧 **Email:** amirhosseinheydari78@gmail.com - 📍 **Linktree:** [linktr.ee/mr_pylin](https://linktr.ee/mr_pylin)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.manifold import TSNE\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchinfo import summary\n",
    "\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set a seed for deterministic results\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if cuda is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# log\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embedding using Word2Vec [Skip-Grams method]\n",
    "🌟 **Example**:\n",
    "   - Sentence: **The quick brown fox jumps over the lazy dog.**\n",
    "   - **WINDOW_SIZE: 2**\n",
    "      - For \"The\" (center word), context words are [\"quick\"].\n",
    "      - For \"quick\" (center word), context words are [\"The\", \"brown\"].\n",
    "      - For \"brown\" (center word), context words are [\"quick\", \"The\", \"fox\", \"jumps\"].\n",
    "      - For \"fox\" (center word), context words are [\"brown\", \"quick\", \"jumps\"].\n",
    "      - For \"jumps\" (center word), context words are [\"fox\", \"brown\", \"over\"].\n",
    "      - For \"over\" (center word), context words are [\"jumps\", \"the\"].\n",
    "      - For \"the\" (center word), context words are [\"over\"].\n",
    "   - **NEGATIVE_SAMPLES: 5**\n",
    "      - If we are predicting \"brown\" and the context words are [\"quick\", \"The\", \"fox\", \"jumps\"].\n",
    "      - we will also randomly select 5 words from the rest of the vocabulary (e.g., \"lazy\", \"dog\", etc.) and treat them as negative samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "WINDOW_SIZE = 2\n",
    "BATCH_SIZE = 2048\n",
    "EPOCHS = 2\n",
    "LEARNING_RATE = 0.01\n",
    "NEGATIVE_SAMPLES = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load and preprocess the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\", cache_dir=\"../../datasets/\")\n",
    "train_text = dataset[\"train\"][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary size             : 76616\n",
      "top 5 most  frequent tokens : [('the', 113161), (',', 99913), ('.', 73388), ('of', 56889), ('and', 50603)]\n",
      "top 5 least frequent tokens : [('Unrecorded', 1), ('Calamaty', 1), ('forgiving', 1), ('unvoiced', 1), ('scanned', 1)]\n"
     ]
    }
   ],
   "source": [
    "# tokenize and build vocabulary\n",
    "tokenized_sentences = [sentence.split() for sentence in train_text if sentence.strip()]\n",
    "words = [word for sentence in tokenized_sentences for word in sentence]\n",
    "vocab = Counter(words)\n",
    "\n",
    "# log\n",
    "print(f\"vocabulary size             : {len(vocab)}\")\n",
    "print(f\"top 5 most  frequent tokens : {vocab.most_common(5)}\")\n",
    "print(f\"top 5 least frequent tokens : {sorted(vocab.items(), key=lambda x: x[1])[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary size             : 23378\n",
      "top 5 most  frequent tokens : [('the', 113161), (',', 99913), ('.', 73388), ('of', 56889), ('and', 50603)]\n",
      "top 5 least frequent tokens : [('Senjō', 5), ('penal', 5), ('Gallia', 5), ('adjustments', 5), ('newcomers', 5)]\n"
     ]
    }
   ],
   "source": [
    "# filter out rare words\n",
    "min_freq = 5\n",
    "vocab = {word: freq for word, freq in vocab.items() if freq >= min_freq}\n",
    "word2idx = {word: idx for idx, (word, _) in enumerate(vocab.items())}\n",
    "idx2word = {idx: word for word, idx in word2idx.items()}\n",
    "vocab_size = len(word2idx)\n",
    "\n",
    "# log\n",
    "print(f\"vocabulary size             : {vocab_size}\")\n",
    "print(f\"top 5 most  frequent tokens : {sorted(vocab.items(), key=lambda x: x[1], reverse=True)[:5]}\")\n",
    "print(f\"top 5 least frequent tokens : {sorted(vocab.items(), key=lambda x: x[1])[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of skip-grams         : 7532842\n",
      "sequence of words [1000 to 1006]   : ['they', 'are', 'nevertheless', 'up', 'to', 'the', 'task']\n",
      "{word:idx} for the above sequence] : {'they': 200, 'are': 72, 'nevertheless': 401, 'up': 402, 'to': 18, 'the': 14, 'task': 403}\n",
      "skip-gram pairs for above sequence : [(401, 200), (401, 72)]\n"
     ]
    }
   ],
   "source": [
    "# generate skip-grams with negative sampling\n",
    "def generate_skip_grams(words: list[str], word2idx: dict[str, int], window_size: int, vocab: dict[str, int]) -> list[tuple[int, int]]:\n",
    "    pairs = []\n",
    "    for idx, word in enumerate(words):\n",
    "        if word not in word2idx:\n",
    "            continue\n",
    "        center_idx = word2idx[word]\n",
    "        context_range = range(max(0, idx - window_size), min(len(words), idx + window_size + 1))\n",
    "        for context_idx in context_range:\n",
    "            if context_idx == idx:\n",
    "                continue\n",
    "            context_word = words[context_idx]\n",
    "            if context_word in word2idx:\n",
    "                pairs.append((center_idx, word2idx[context_word]))\n",
    "    return pairs\n",
    "\n",
    "# generate skip-grams\n",
    "skip_grams = generate_skip_grams(words, word2idx, WINDOW_SIZE, vocab)\n",
    "\n",
    "# log\n",
    "print(f\"total number of skip-grams         : {len(skip_grams)}\")\n",
    "print(f\"sequence of words [1000 to 1006]   : {words[1000:1007]}\")\n",
    "print(\"{word:idx} for the above sequence] :\", {w: word2idx[w] for w in words[1000:1007]})\n",
    "print(f\"skip-gram pairs for above sequence : {[skip_grams[skip_grams.index((401, 200)) + i] for i in range(WINDOW_SIZE)]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipGramDataset(Dataset):\n",
    "    def __init__(self, skip_grams, vocab_size, neg_samples):\n",
    "        self.skip_grams = skip_grams\n",
    "        self.vocab_size = vocab_size\n",
    "        self.neg_samples = neg_samples\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.skip_grams)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        center, context = self.skip_grams[idx]\n",
    "        negatives = torch.multinomial(\n",
    "            torch.tensor([1.0] * self.vocab_size), self.neg_samples, replacement=True\n",
    "        )\n",
    "        return torch.tensor(center, dtype=torch.long), torch.tensor(context, dtype=torch.long), negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(401), tensor(200), tensor([ 1359,  1470,  2889,  1229, 12300]))\n",
      "  negative samples:\n",
      "     {1359: '520'}\n",
      "     {1470: 'medicines'}\n",
      "     {2889: 'Vancouver'}\n",
      "     {1229: 'ultimate'}\n",
      "     {12300: 'Palestine'}\n",
      "\n",
      "(tensor(401), tensor(72), tensor([11146, 22331, 21712,  1953,  3100]))\n",
      "  negative samples:\n",
      "     {11146: 'antagonist'}\n",
      "     {22331: 'Rajamouli'}\n",
      "     {21712: 'Honors'}\n",
      "     {1953: 'show'}\n",
      "     {3100: 'statistic'}\n",
      "\n",
      "(tensor(401), tensor(402), tensor([ 3671,  8775, 19696, 20350,  8825]))\n",
      "  negative samples:\n",
      "     {3671: 'disguise'}\n",
      "     {8775: 'Influences'}\n",
      "     {19696: 'Store'}\n",
      "     {20350: 'Novoselic'}\n",
      "     {8825: 'arch'}\n",
      "\n",
      "(tensor(401), tensor(18), tensor([14317,  2059, 16392, 14573, 10222]))\n",
      "  negative samples:\n",
      "     {14317: 'Fraser'}\n",
      "     {2059: 'focusing'}\n",
      "     {16392: 'concentric'}\n",
      "     {14573: 'publishes'}\n",
      "     {10222: 'lifestyle'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = SkipGramDataset(skip_grams, vocab_size, NEGATIVE_SAMPLES)\n",
    "data_loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "num_batches = len(data_loader)\n",
    "\n",
    "# log\n",
    "for i in range(WINDOW_SIZE * 2):\n",
    "    temp_sample = dataset[skip_grams.index((401, 200)) + i]\n",
    "    print(temp_sample)\n",
    "    print(f\"  negative samples:\")\n",
    "    for j in range(NEGATIVE_SAMPLES):\n",
    "        print(\"    \", {temp_sample[2][j].item(): idx2word[temp_sample[2][j].item()]})\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Define and Initialize the Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word2Vec(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super(Word2Vec, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.context_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "    def forward(self, center, context, negatives):\n",
    "        center_embed = self.embeddings(center)\n",
    "        context_embed = self.context_embeddings(context)\n",
    "        neg_embed = self.context_embeddings(negatives)\n",
    "\n",
    "        # positive scores\n",
    "        positive_score = torch.sum(center_embed * context_embed, dim=1)\n",
    "        positive_loss = -torch.log(torch.sigmoid(positive_score + 1e-9))\n",
    "\n",
    "        # negative scores\n",
    "        negative_score = torch.bmm(neg_embed, center_embed.unsqueeze(2)).squeeze()\n",
    "        negative_loss = -torch.sum(torch.log(torch.sigmoid(-negative_score + 1e-9)), dim=1)\n",
    "\n",
    "        return (positive_loss + negative_loss).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(vocab_size, EMBEDDING_DIM).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Word2Vec(\n",
       "  (embeddings): Embedding(23378, 100)\n",
       "  (context_embeddings): Embedding(23378, 100)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Word2Vec                                 --                        --\n",
       "├─Embedding: 1-1                         [2048, 100]               2,337,800\n",
       "├─Embedding: 1-2                         [2048, 100]               2,337,800\n",
       "├─Embedding: 1-3                         [2048, 5, 100]            (recursive)\n",
       "==========================================================================================\n",
       "Total params: 4,675,600\n",
       "Trainable params: 4,675,600\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 14.36\n",
       "==========================================================================================\n",
       "Input size (MB): 0.11\n",
       "Forward/backward pass size (MB): 11.47\n",
       "Params size (MB): 18.70\n",
       "Estimated Total Size (MB): 30.29\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(\n",
    "    model,\n",
    "    input_data=(\n",
    "        (\n",
    "            torch.randint(0, vocab_size, (BATCH_SIZE,)).to(device),\n",
    "            torch.randint(0, vocab_size, (BATCH_SIZE,)).to(device),\n",
    "            torch.randint(0, vocab_size, (BATCH_SIZE, NEGATIVE_SAMPLES)).to(device)\n",
    "        )\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/2\n",
      "  iteration 0001/3679  |  loss: 24.5571  |  total loss: 24.5571\n",
      "  iteration 0101/3679  |  loss: 16.3418  |  total loss: 2042.5032\n",
      "  iteration 0201/3679  |  loss: 11.6497  |  total loss: 3448.2477\n",
      "  iteration 0301/3679  |  loss: 9.0296  |  total loss: 4465.6896\n",
      "  iteration 0401/3679  |  loss: 6.8504  |  total loss: 5235.8727\n",
      "  iteration 0501/3679  |  loss: 5.2581  |  total loss: 5843.1700\n",
      "  iteration 0601/3679  |  loss: 4.7532  |  total loss: 6337.2399\n",
      "  iteration 0701/3679  |  loss: 3.7600  |  total loss: 6754.2973\n",
      "  iteration 0801/3679  |  loss: 3.4022  |  total loss: 7118.3565\n",
      "  iteration 0901/3679  |  loss: 3.0965  |  total loss: 7442.5429\n",
      "  iteration 1001/3679  |  loss: 2.8195  |  total loss: 7738.0126\n",
      "  iteration 1101/3679  |  loss: 2.5631  |  total loss: 8013.6600\n",
      "  iteration 1201/3679  |  loss: 2.6182  |  total loss: 8273.9914\n",
      "  iteration 1301/3679  |  loss: 2.2488  |  total loss: 8521.8611\n",
      "  iteration 1401/3679  |  loss: 2.3285  |  total loss: 8759.4935\n",
      "  iteration 1501/3679  |  loss: 2.0391  |  total loss: 8986.4090\n",
      "  iteration 1601/3679  |  loss: 2.1636  |  total loss: 9206.5571\n",
      "  iteration 1701/3679  |  loss: 2.1534  |  total loss: 9417.8102\n",
      "  iteration 1801/3679  |  loss: 2.0473  |  total loss: 9625.7959\n",
      "  iteration 1901/3679  |  loss: 1.9612  |  total loss: 9828.2213\n",
      "  iteration 2001/3679  |  loss: 1.9284  |  total loss: 10026.7291\n",
      "  iteration 2101/3679  |  loss: 1.9916  |  total loss: 10220.5173\n",
      "  iteration 2201/3679  |  loss: 1.7846  |  total loss: 10410.5293\n",
      "  iteration 2301/3679  |  loss: 1.9237  |  total loss: 10597.3717\n",
      "  iteration 2401/3679  |  loss: 1.9080  |  total loss: 10779.6542\n",
      "  iteration 2501/3679  |  loss: 1.5875  |  total loss: 10959.5661\n",
      "  iteration 2601/3679  |  loss: 1.7738  |  total loss: 11137.5715\n",
      "  iteration 2701/3679  |  loss: 1.7759  |  total loss: 11312.9986\n",
      "  iteration 2801/3679  |  loss: 1.6067  |  total loss: 11485.5507\n",
      "  iteration 2901/3679  |  loss: 1.6634  |  total loss: 11657.1037\n",
      "  iteration 3001/3679  |  loss: 1.6677  |  total loss: 11825.6442\n",
      "  iteration 3101/3679  |  loss: 1.6802  |  total loss: 11992.6769\n",
      "  iteration 3201/3679  |  loss: 1.6533  |  total loss: 12157.9022\n",
      "  iteration 3301/3679  |  loss: 1.6526  |  total loss: 12321.5650\n",
      "  iteration 3401/3679  |  loss: 1.5088  |  total loss: 12482.9796\n",
      "  iteration 3501/3679  |  loss: 1.5645  |  total loss: 12643.5809\n",
      "  iteration 3601/3679  |  loss: 1.6280  |  total loss: 12801.3009\n",
      "epoch 1/2  |  total loss: 12923.7137\n",
      "--------------------------------------------------\n",
      "epoch 2/2\n",
      "  iteration 0001/3679  |  loss: 1.4025  |  total loss: 1.4025\n",
      "  iteration 0101/3679  |  loss: 1.3499  |  total loss: 138.0483\n",
      "  iteration 0201/3679  |  loss: 1.4256  |  total loss: 274.4598\n",
      "  iteration 0301/3679  |  loss: 1.3556  |  total loss: 410.1206\n",
      "  iteration 0401/3679  |  loss: 1.4114  |  total loss: 546.2862\n",
      "  iteration 0501/3679  |  loss: 1.3669  |  total loss: 682.6846\n",
      "  iteration 0601/3679  |  loss: 1.3850  |  total loss: 818.3880\n",
      "  iteration 0701/3679  |  loss: 1.3569  |  total loss: 953.8077\n",
      "  iteration 0801/3679  |  loss: 1.3735  |  total loss: 1089.3494\n",
      "  iteration 0901/3679  |  loss: 1.3484  |  total loss: 1225.5505\n",
      "  iteration 1001/3679  |  loss: 1.3101  |  total loss: 1361.5026\n",
      "  iteration 1101/3679  |  loss: 1.3650  |  total loss: 1496.8072\n",
      "  iteration 1201/3679  |  loss: 1.3107  |  total loss: 1632.0835\n",
      "  iteration 1301/3679  |  loss: 1.3864  |  total loss: 1767.4144\n",
      "  iteration 1401/3679  |  loss: 1.3294  |  total loss: 1901.9844\n",
      "  iteration 1501/3679  |  loss: 1.3211  |  total loss: 2036.9584\n",
      "  iteration 1601/3679  |  loss: 1.3513  |  total loss: 2172.0269\n",
      "  iteration 1701/3679  |  loss: 1.3370  |  total loss: 2307.2590\n",
      "  iteration 1801/3679  |  loss: 1.3219  |  total loss: 2442.2968\n",
      "  iteration 1901/3679  |  loss: 1.3111  |  total loss: 2577.1480\n",
      "  iteration 2001/3679  |  loss: 1.3849  |  total loss: 2711.9353\n",
      "  iteration 2101/3679  |  loss: 1.2752  |  total loss: 2846.8828\n",
      "  iteration 2201/3679  |  loss: 1.2710  |  total loss: 2981.4470\n",
      "  iteration 2301/3679  |  loss: 1.2956  |  total loss: 3115.6719\n",
      "  iteration 2401/3679  |  loss: 1.3975  |  total loss: 3250.1312\n",
      "  iteration 2501/3679  |  loss: 1.2783  |  total loss: 3384.0848\n",
      "  iteration 2601/3679  |  loss: 1.2913  |  total loss: 3518.1934\n",
      "  iteration 2701/3679  |  loss: 1.3122  |  total loss: 3651.3841\n",
      "  iteration 2801/3679  |  loss: 1.3616  |  total loss: 3785.0657\n",
      "  iteration 2901/3679  |  loss: 1.2887  |  total loss: 3919.0179\n",
      "  iteration 3001/3679  |  loss: 1.2797  |  total loss: 4051.9248\n",
      "  iteration 3101/3679  |  loss: 1.2659  |  total loss: 4185.1867\n",
      "  iteration 3201/3679  |  loss: 1.3814  |  total loss: 4318.2015\n",
      "  iteration 3301/3679  |  loss: 1.4359  |  total loss: 4451.6150\n",
      "  iteration 3401/3679  |  loss: 1.2981  |  total loss: 4584.1052\n",
      "  iteration 3501/3679  |  loss: 1.2795  |  total loss: 4717.1328\n",
      "  iteration 3601/3679  |  loss: 1.3427  |  total loss: 4849.7011\n",
      "epoch 2/2  |  total loss: 4952.8265\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "    model.train()\n",
    "    \n",
    "    # log\n",
    "    print(f\"epoch {epoch + 1:>0{len(str(EPOCHS))}}/{EPOCHS}\")\n",
    "    \n",
    "    for i, (center, context, negatives) in enumerate(data_loader):\n",
    "        # Move data to the correct device\n",
    "        center, context, negatives = center.to(device), context.to(device), negatives.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss = model(center, context, negatives)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # log\n",
    "        if i % 100 == 0:\n",
    "            print(f\"  iteration {i + 1:>0{len(str(num_batches))}}/{num_batches}  |  loss: {loss.item():.4f}  |  total loss: {total_loss:.4f}\")\n",
    "    \n",
    "    # log\n",
    "    print(f\"epoch {epoch + 1:>0{len(str(EPOCHS))}}/{EPOCHS}  |  total loss: {total_loss:.4f}\")\n",
    "    print('-' * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Save embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "embeddings = model.embeddings.weight.data\n",
    "torch.save(embeddings, \"../../assets/embeddings/word2vec_embeddings.pt\")\n",
    "\n",
    "# log\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Visualize word embeddings using t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_embeddings(embeddings: torch.Tensor, idx2word: dict[int, str], num_points: int = 100) -> None:\n",
    "    tsne = TSNE(n_components=2, random_state=seed)\n",
    "    reduced_embeddings = tsne.fit_transform(embeddings[:num_points].cpu().numpy())\n",
    "    \n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for idx, (x, y) in enumerate(reduced_embeddings):\n",
    "        plt.scatter(x, y)\n",
    "        plt.text(x, y, idx2word[idx], fontsize=9)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_embeddings(embeddings, idx2word)"
   ]
  }
 ],
 "metadata": {
  "author_email": "AmirhosseinHeydari78@gmail.com",
  "author_github": "https://github.com/mr-pylin",
  "author_name": "Amirhossein Heydari",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "origin_repo": "https://github.com/mr-pylin/pytorch-workshop"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
