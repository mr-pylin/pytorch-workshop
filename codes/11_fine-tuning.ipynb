{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ud83d\udcdd **Author:** Amirhossein Heydari - \ud83d\udce7 **Email:** amirhosseinheydari78@gmail.com - \ud83d\udccd **Linktree:** [linktr.ee/mr_pylin](https://linktr.ee/mr_pylin)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import DataLoader\n",
        "from torchmetrics import Accuracy\n",
        "from torchinfo import summary\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torchvision.models import ResNet50_Weights, resnet50\n",
        "from torchvision.transforms import v2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# set a seed for deterministic results\n",
        "random_state = 42\n",
        "torch.manual_seed(random_state)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# check if cuda is available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Pre-Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# initial transforms\n",
        "transforms = v2.Compose(\n",
        "    [\n",
        "        v2.ToImage(),\n",
        "        v2.ToDtype(torch.float32, scale=True)\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "trainset:\n",
            "    -> trainset.data.shape    : (50000, 32, 32, 3)\n",
            "    -> trainset.data.dtype    : uint8\n",
            "    -> type(trainset.data)    : <class 'numpy.ndarray'>\n",
            "    -> type(trainset.targets) : <class 'list'>\n",
            "--------------------------------------------------\n",
            "testset:\n",
            "    -> testset.data.shape     : (10000, 32, 32, 3)\n",
            "    -> testset.data.dtype     : uint8\n",
            "    -> type(testset.data)     : <class 'numpy.ndarray'>\n",
            "    -> type(testset.targets)  : <class 'list'>\n",
            "--------------------------------------------------\n",
            "classes : ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
            "trainset distribution : [5000 5000 5000 5000 5000 5000 5000 5000 5000 5000]\n",
            "testset  distribution : [1000 1000 1000 1000 1000 1000 1000 1000 1000 1000]\n"
          ]
        }
      ],
      "source": [
        "trainset = CIFAR10(root='./dataset', train=True , transform=transforms, download=True)\n",
        "testset  = CIFAR10(root='./dataset', train=False, transform=transforms, download=True)\n",
        "\n",
        "# log\n",
        "print('trainset:')\n",
        "print(f\"    -> trainset.data.shape    : {trainset.data.shape}\")\n",
        "print(f\"    -> trainset.data.dtype    : {trainset.data.dtype}\")\n",
        "print(f\"    -> type(trainset.data)    : {type(trainset.data)}\")\n",
        "print(f\"    -> type(trainset.targets) : {type(trainset.targets)}\")\n",
        "print('-' * 50)\n",
        "print('testset:')\n",
        "print(f\"    -> testset.data.shape     : {testset.data.shape}\")\n",
        "print(f\"    -> testset.data.dtype     : {testset.data.dtype}\")\n",
        "print(f\"    -> type(testset.data)     : {type(testset.data)}\")\n",
        "print(f\"    -> type(testset.targets)  : {type(testset.targets)}\")\n",
        "print('-' * 50)\n",
        "print(f\"classes : {trainset.classes}\")\n",
        "print(f\"trainset distribution : {np.unique(trainset.targets, return_counts=True)[1]}\")\n",
        "print(f\"testset  distribution : {np.unique(testset.targets, return_counts=True)[1]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# plot\n",
        "fig, axs = plt.subplots(nrows=4, ncols=8, figsize=(12, 6), layout='compressed')\n",
        "for i in range(4):\n",
        "    for j in range(8):\n",
        "        axs[i, j].imshow(trainset.data[i * 8 + j], cmap='gray')\n",
        "        axs[i, j].set_title(trainset.classes[trainset.targets[i * 8 + j]])\n",
        "        axs[i, j].axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train mean per channel : tensor([0.4914, 0.4822, 0.4465])\n",
            "train std  per channel : tensor([0.2470, 0.2435, 0.2616])\n"
          ]
        }
      ],
      "source": [
        "data = next(iter(DataLoader(trainset, batch_size=len(trainset))))[0]\n",
        "\n",
        "train_mean = data.mean(axis=(0, 2, 3))\n",
        "train_std = data.std(axis=(0, 2, 3))\n",
        "\n",
        "del data\n",
        "\n",
        "# log\n",
        "print(f\"train mean per channel : {train_mean}\")\n",
        "print(f\"train std  per channel : {train_std}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "StandardTransform\n",
            "Transform: Compose(\n",
            "                 ToImage()\n",
            "                 ToDtype(scale=True)\n",
            "                 Normalize(mean=[tensor(0.4914), tensor(0.4822), tensor(0.4465)], std=[tensor(0.2470), tensor(0.2435), tensor(0.2616)], inplace=False)\n",
            "           )\n",
            "StandardTransform\n",
            "Transform: Compose(\n",
            "                 ToImage()\n",
            "                 ToDtype(scale=True)\n",
            "                 Normalize(mean=[tensor(0.4914), tensor(0.4822), tensor(0.4465)], std=[tensor(0.2470), tensor(0.2435), tensor(0.2616)], inplace=False)\n",
            "           )\n"
          ]
        }
      ],
      "source": [
        "transforms.transforms.append(v2.Normalize(mean=train_mean, std=train_std))\n",
        "\n",
        "# log\n",
        "print(trainset.transforms)\n",
        "print(testset.transforms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "before applying transform:\n",
            "    -> type(testset.data[0]) : <class 'numpy.ndarray'>\n",
            "    -> testset.data[0].dtype : uint8\n",
            "    -> testset.data[0].shape : (32, 32, 3)\n",
            "--------------------------------------------------\n",
            "after applying transform:\n",
            "    -> type(testset[0][0])   : <class 'torchvision.tv_tensors._image.Image'>\n",
            "    -> testset[0][0].dtype   : torch.float32\n",
            "    -> testset[0][0].shape   : torch.Size([3, 32, 32])\n"
          ]
        }
      ],
      "source": [
        "# log\n",
        "print(\"before applying transform:\")\n",
        "print(f\"    -> type(testset.data[0]) : {type(testset.data[0])}\")\n",
        "print(f\"    -> testset.data[0].dtype : {testset.data[0].dtype}\")\n",
        "print(f\"    -> testset.data[0].shape : {testset.data[0].shape}\")\n",
        "print('-' * 50)\n",
        "print(\"after applying transform:\")\n",
        "print(f\"    -> type(testset[0][0])   : {type(testset[0][0])}\")\n",
        "print(f\"    -> testset[0][0].dtype   : {testset[0][0].dtype}\")\n",
        "print(f\"    -> testset[0][0].shape   : {testset[0][0].shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True , num_workers=2)\n",
        "testloader  = DataLoader(testset , batch_size=batch_size, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Transfer Learning & Fine-tuning\n",
        "   - resnet50 pretrained on IMAGENET1K_V1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (4): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (5): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "resnet = resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)\n",
        "\n",
        "# log\n",
        "print(resnet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "ResNet                                   [1, 1000]                 --\n",
              "\u251c\u2500Conv2d: 1-1                            [1, 64, 16, 16]           9,408\n",
              "\u251c\u2500BatchNorm2d: 1-2                       [1, 64, 16, 16]           128\n",
              "\u251c\u2500ReLU: 1-3                              [1, 64, 16, 16]           --\n",
              "\u251c\u2500MaxPool2d: 1-4                         [1, 64, 8, 8]             --\n",
              "\u251c\u2500Sequential: 1-5                        [1, 256, 8, 8]            --\n",
              "\u2502    \u2514\u2500Bottleneck: 2-1                   [1, 256, 8, 8]            --\n",
              "\u2502    \u2502    \u2514\u2500Conv2d: 3-1                  [1, 64, 8, 8]             4,096\n",
              "\u2502    \u2502    \u2514\u2500BatchNorm2d: 3-2             [1, 64, 8, 8]             128\n",
              "\u2502    \u2502    \u2514\u2500ReLU: 3-3                    [1, 64, 8, 8]             --\n",
              "\u2502    \u2502    \u2514\u2500Conv2d: 3-4                  [1, 64, 8, 8]             36,864\n",
              "\u2502    \u2502    \u2514\u2500BatchNorm2d: 3-5             [1, 64, 8, 8]             128\n",
              "\u2502    \u2502    \u2514\u2500ReLU: 3-6                    [1, 64, 8, 8]             --\n",
              "\u2502    \u2502    \u2514\u2500Conv2d: 3-7                  [1, 256, 8, 8]            16,384\n",
              "\u2502    \u2502    \u2514\u2500BatchNorm2d: 3-8             [1, 256, 8, 8]            512\n",
              "\u2502    \u2502    \u2514\u2500Sequential: 3-9              [1, 256, 8, 8]            16,896\n",
              "\u2502    \u2502    \u2514\u2500ReLU: 3-10                   [1, 256, 8, 8]            --\n",
              "\u2502    \u2514\u2500Bottleneck: 2-2                   [1, 256, 8, 8]            --\n",
              "\u2502    \u2502    \u2514\u2500Conv2d: 3-11                 [1, 64, 8, 8]             16,384\n",
              "\u2502    \u2502    \u2514\u2500BatchNorm2d: 3-12            [1, 64, 8, 8]             128\n",
              "\u2502    \u2502    \u2514\u2500ReLU: 3-13                   [1, 64, 8, 8]             --\n",
              "\u2502    \u2502    \u2514\u2500Conv2d: 3-14                 [1, 64, 8, 8]             36,864\n",
              "\u2502    \u2502    \u2514\u2500BatchNorm2d: 3-15            [1, 64, 8, 8]             128\n",
              "\u2502    \u2502    \u2514\u2500ReLU: 3-16                   [1, 64, 8, 8]             --\n",
              "\u2502    \u2502    \u2514\u2500Conv2d: 3-17                 [1, 256, 8, 8]            16,384\n",
              "\u2502    \u2502    \u2514\u2500BatchNorm2d: 3-18            [1, 256, 8, 8]            512\n",
              "\u2502    \u2502    \u2514\u2500ReLU: 3-19                   [1, 256, 8, 8]            --\n",
              "\u2502    \u2514\u2500Bottleneck: 2-3                   [1, 256, 8, 8]            --\n",
              "\u2502    \u2502    \u2514\u2500Conv2d: 3-20                 [1, 64, 8, 8]             16,384\n",
              "\u2502    \u2502    \u2514\u2500BatchNorm2d: 3-21            [1, 64, 8, 8]             128\n",
              "\u2502    \u2502    \u2514\u2500ReLU: 3-22                   [1, 64, 8, 8]             --\n",
              "\u2502    \u2502    \u2514\u2500Conv2d: 3-23                 [1, 64, 8, 8]             36,864\n",
              "\u2502    \u2502    \u2514\u2500BatchNorm2d: 3-24            [1, 64, 8, 8]             128\n",
              "\u2502    \u2502    \u2514\u2500ReLU: 3-25                   [1, 64, 8, 8]             --\n",
              "\u2502    \u2502    \u2514\u2500Conv2d: 3-26                 [1, 256, 8, 8]            16,384\n",
              "\u2502    \u2502    \u2514\u2500BatchNorm2d: 3-27            [1, 256, 8, 8]            512\n",
              "\u2502    \u2502    \u2514\u2500ReLU: 3-28                   [1, 256, 8, 8]            --\n",
              "\u251c\u2500Sequential: 1-6                        [1, 512, 4, 4]            --\n",
              "\u2502    \u2514\u2500Bottleneck: 2-4                   [1, 512, 4, 4]            --\n",
              "\u2502    \u2502    \u2514\u2500Conv2d: 3-29                 [1, 128, 8, 8]            32,768\n",
              "\u2502    \u2502    \u2514\u2500BatchNorm2d: 3-30            [1, 128, 8, 8]            256\n",
              "\u2502    \u2502    \u2514\u2500ReLU: 3-31                   [1, 128, 8, 8]            --\n",
              "\u2502    \u2502    \u2514\u2500Conv2d: 3-32                 [1, 128, 4, 4]            147,456\n",
              "\u2502    \u2502    \u2514\u2500BatchNorm2d: 3-33            [1, 128, 4, 4]            256\n",
              "\u2502    \u2502    \u2514\u2500ReLU: 3-34                   [1, 128, 4, 4]            --\n",
              "\u2502    \u2502    \u2514\u2500Conv2d: 3-35                 [1, 512, 4, 4]            65,536\n",
              "\u2502    \u2502    \u2514\u2500BatchNorm2d: 3-36            [1, 512, 4, 4]            1,024\n",
              "\u2502    \u2502    \u2514\u2500Sequential: 3-37             [1, 512, 4, 4]            132,096\n",
              "\u2502    \u2502    \u2514\u2500ReLU: 3-38                   [1, 512, 4, 4]            --\n",
              "\u2502    \u2514\u2500Bottleneck: 2-5                   [1, 512, 4, 4]            --\n",
              "\u2502    \u2502    \u2514\u2500Conv2d: 3-39                 [1, 128, 4, 4]            65,536\n",
              "\u2502    \u2502    \u2514\u2500BatchNorm2d: 3-40            [1, 128, 4, 4]            256\n",
              "\u2502    \u2502    \u2514\u2500ReLU: 3-41                   [1, 128, 4, 4]            --\n",
              "\u2502    \u2502    \u2514\u2500Conv2d: 3-42                 [1, 128, 4, 4]            147,456\n",
              "\u2502    \u2502    \u2514\u2500BatchNorm2d: 3-43            [1, 128, 4, 4]            256\n",
              "\u2502    \u2502    \u2514\u2500ReLU: 3-44                   [1, 128, 4, 4]            --\n",
              "\u2502    \u2502    \u2514\u2500Conv2d: 3-45                 [1, 512, 4, 4]            65,536\n",
              "\u2502    \u2502    \u2514\u2500BatchNorm2d: 3-46            [1, 512, 4, 4]            1,024\n",
              "\u2502    \u2502    \u2514\u2500ReLU: 3-47                   [1, 512, 4, 4]            --\n",
              "\u2502    \u2514\u2500Bottleneck: 2-6                   [1, 512, 4, 4]            --\n",
              "\u2502    \u2502    \u2514\u2500Conv2d: 3-48                 [1, 128, 4, 4]            65,536\n",
              "\u2502    \u2502    \u2514\u2500BatchNorm2d: 3-49            [1, 128, 4, 4]            256\n",
              "\u2502    \u2502    \u2514\u2500ReLU: 3-50                   [1, 128, 4, 4]            --\n",
              "\u2502    \u2502    \u2514\u2500Conv2d: 3-51                 [1, 128, 4, 4]            147,456\n",
              "\u2502    \u2502    \u2514\u2500BatchNorm2d: 3-52            [1, 128, 4, 4]            256\n",
              "\u2502    \u2502    \u2514\u2500ReLU: 3-53                   [1, 128, 4, 4]            --\n",
              "\u2502    \u2502    \u2514\u2500Conv2d: 3-54                 [1, 512, 4, 4]            65,536\n",
              "\u2502    \u2502    \u2514\u2500BatchNorm2d: 3-55            [1, 512, 4, 4]            1,024\n",
              "\u2502    \u2502    \u2514\u2500ReLU: 3-56                   [1, 512, 4, 4]            --\n",
              "\u2502    \u2514\u2500Bottleneck: 2-7                   [1, 512, 4, 4]            --\n",
              "\u2502    \u2502    \u2514\u2500Conv2d: 3-57                 [1, 128, 4, 4]            65,536\n",
              "\u2502    \u2502    \u2514\u2500BatchNorm2d: 3-58            [1, 128, 4, 4]            256\n",
              "\u2502    \u2502    \u2514\u2500ReLU: 3-59                   [1, 128, 4, 4]            --\n",
              "\u2502    \u2502    \u2514\u2500Conv2d: 3-60                 [1, 128, 4, 4]            147,456\n",
              "\u2502    \u2502    \u2514\u2500BatchNorm2d: 3-61            [1, 128, 4, 4]            256\n",
              "\u2502    \u2502    \u2514\u2500ReLU: 3-62                   [1, 128, 4, 4]            --\n",
              "\u2502    \u2502    \u2514\u2500Conv2d: 3-63                 [1, 512, 4, 4]            65,536\n",
              "\u2502    \u2502    \u2514\u2500BatchNorm2d: 3-64            [1, 512, 4, 4]            1,024\n",
              "\u2502    \u2502    \u2514\u2500ReLU: 3-65                   [1, 512, 4, 4]            --\n",
              "\u251c\u2500Sequential: 1-7                        [1, 1024, 2, 2]           --\n",
              "\u2502    \u2514\u2500Bottleneck: 2-8                   [1, 1024, 2, 2]           --\n",
              "\u2502    \u2502    \u2514\u2500Conv2d: 3-66                 [1, 256, 4, 4]            131,072\n",
              "\u2502    \u2502    \u2514\u2500BatchNorm2d: 3-67            [1, 256, 4, 4]            512\n",
              "\u2502    \u2502    \u2514\u2500ReLU: 3-68                   [1, 256, 4, 4]            --\n",
              "\u2502    \u2502    \u2514\u2500Conv2d: 3-69                 [1, 256, 2, 2]            589,824\n",
              "\u2502    \u2502    \u2514\u2500BatchNorm2d: 3-70            [1, 256, 2, 2]            512\n",
              "\u2502    \u2502    \u2514\u2500ReLU: 3-71                   [1, 256, 2, 2]            --\n",
              "\u2502    \u2502    \u2514\u2500Conv2d: 3-72                 [1, 1024, 2, 2]           262,144\n",
              "\u2502    \u2502    \u2514\u2500BatchNorm2d: 3-73            [1, 1024, 2, 2]           2,048\n",
              "\u2502    \u2502    \u2514\u2500Sequential: 3-74             [1, 1024, 2, 2]           526,336\n",
              "\u2502    \u2502    \u2514\u2500ReLU: 3-75                   [1, 1024, 2, 2]           --\n",
              "\u2502    \u2514\u2500Bottleneck: 2-9                   [1, 1024, 2, 2]           --\n",
              "\u2502    \u2502    \u2514\u2500Conv2d: 3-76                 [1, 256, 2, 2]            262,144\n",
              "\u2502    \u2502    \u2514\u2500BatchNorm2d: 3-77            [1, 256, 2, 2]            512\n",
              "\u2502    \u2502    \u2514\u2500ReLU: 3-78                   [1, 256, 2, 2]            --\n",
              "\u2502    \u2502    \u2514\u2500Conv2d: 3-79                 [1, 256, 2, 2]            589,824\n",
              "\u2502    \u2502    \u2514\u2500BatchNorm2d: 3-80            [1, 256, 2, 2]            512\n",
              "\u2502    \u2502    \u2514\u2500ReLU: 3-81                   [1, 256, 2, 2]            --\n",
              "\u2502    \u2502    \u2514\u2500Conv2d: 3-82                 [1, 1024, 2, 2]           262,144\n",
              "\u2502    \u2502    \u2514\u2500BatchNorm2d: 3-83            [1, 1024, 2, 2]           2,048\n",
              "\u2502    \u2502    \u2514\u2500ReLU: 3-84                   [1, 1024, 2, 2]           --\n",
              "\u2502    \u2514\u2500Bottleneck: 2-10                  [1, 1024, 2, 2]           --\n",
              "\u2502    \u2502    \u2514\u2500Conv2d: 3-85                 [1, 256, 2, 2]            262,144\n",
              "\u2502    \u2502    \u2514\u2500BatchNorm2d: 3-86            [1, 256, 2, 2]            512\n",
              "\u2502    \u2502    \u2514\u2500ReLU: 3-87                   [1, 256, 2, 2]            --\n",
              "\u2502    \u2502    \u2514\u2500Conv2d: 3-88                 [1, 256, 2, 2]            589,824\n",
              "\u2502    \u2502    \u2514\u2500BatchNorm2d: 3-89            [1, 256, 2, 2]            512\n",
              "\u2502    \u2502    \u2514\u2500ReLU: 3-90                   [1, 256, 2, 2]            --\n",
              "\u2502    \u2502    \u2514\u2500Conv2d: 3-91                 [1, 1024, 2, 2]           262,144\n",
              "\u2502    \u2502    \u2514\u2500BatchNorm2d: 3-92            [1, 1024, 2, 2]           2,048\n",
              "\u2502    \u2502    \u2514\u2500ReLU: 3-93                   [1, 1024, 2, 2]           --\n",
              "\u2502    \u2514\u2500Bottleneck: 2-11                  [1, 1024, 2, 2]           --\n",
              "\u2502    \u2502    \u2514\u2500Conv2d: 3-94                 [1, 256, 2, 2]            262,144\n",
              "\u2502    \u2502    \u2514\u2500BatchNorm2d: 3-95            [1, 256, 2, 2]            512\n",
              "\u2502    \u2502    \u2514\u2500ReLU: 3-96                   [1, 256, 2, 2]            --\n",
              "\u2502    \u2502    \u2514\u2500Conv2d: 3-97                 [1, 256, 2, 2]            589,824\n",
              "\u2502    \u2502    \u2514\u2500BatchNorm2d: 3-98            [1, 256, 2, 2]            512\n",
              "\u2502    \u2502    \u2514\u2500ReLU: 3-99                   [1, 256, 2, 2]            --\n",
              "\u2502    \u2502    \u2514\u2500Conv2d: 3-100                [1, 1024, 2, 2]           262,144\n",
              "\u2502    \u2502    \u2514\u2500BatchNorm2d: 3-101           [1, 1024, 2, 2]           2,048\n",
              "\u2502    \u2502    \u2514\u2500ReLU: 3-102                  [1, 1024, 2, 2]           --\n",
              "\u2502    \u2514\u2500Bottleneck: 2-12                  [1, 1024, 2, 2]           --\n",
              "\u2502    \u2502    \u2514\u2500Conv2d: 3-103                [1, 256, 2, 2]            262,144\n",
              "\u2502    \u2502    \u2514\u2500BatchNorm2d: 3-104           [1, 256, 2, 2]            512\n",
              "\u2502    \u2502    \u2514\u2500ReLU: 3-105                  [1, 256, 2, 2]            --\n",
              "\u2502    \u2502    \u2514\u2500Conv2d: 3-106                [1, 256, 2, 2]            589,824\n",
              "\u2502    \u2502    \u2514\u2500BatchNorm2d: 3-107           [1, 256, 2, 2]            512\n",
              "\u2502    \u2502    \u2514\u2500ReLU: 3-108                  [1, 256, 2, 2]            --\n",
              "\u2502    \u2502    \u2514\u2500Conv2d: 3-109                [1, 1024, 2, 2]           262,144\n",
              "\u2502    \u2502    \u2514\u2500BatchNorm2d: 3-110           [1, 1024, 2, 2]           2,048\n",
              "\u2502    \u2502    \u2514\u2500ReLU: 3-111                  [1, 1024, 2, 2]           --\n",
              "\u2502    \u2514\u2500Bottleneck: 2-13                  [1, 1024, 2, 2]           --\n",
              "\u2502    \u2502    \u2514\u2500Conv2d: 3-112                [1, 256, 2, 2]            262,144\n",
              "\u2502    \u2502    \u2514\u2500BatchNorm2d: 3-113           [1, 256, 2, 2]            512\n",
              "\u2502    \u2502    \u2514\u2500ReLU: 3-114                  [1, 256, 2, 2]            --\n",
              "\u2502    \u2502    \u2514\u2500Conv2d: 3-115                [1, 256, 2, 2]            589,824\n",
              "\u2502    \u2502    \u2514\u2500BatchNorm2d: 3-116           [1, 256, 2, 2]            512\n",
              "\u2502    \u2502    \u2514\u2500ReLU: 3-117                  [1, 256, 2, 2]            --\n",
              "\u2502    \u2502    \u2514\u2500Conv2d: 3-118                [1, 1024, 2, 2]           262,144\n",
              "\u2502    \u2502    \u2514\u2500BatchNorm2d: 3-119           [1, 1024, 2, 2]           2,048\n",
              "\u2502    \u2502    \u2514\u2500ReLU: 3-120                  [1, 1024, 2, 2]           --\n",
              "\u251c\u2500Sequential: 1-8                        [1, 2048, 1, 1]           --\n",
              "\u2502    \u2514\u2500Bottleneck: 2-14                  [1, 2048, 1, 1]           --\n",
              "\u2502    \u2502    \u2514\u2500Conv2d: 3-121                [1, 512, 2, 2]            524,288\n",
              "\u2502    \u2502    \u2514\u2500BatchNorm2d: 3-122           [1, 512, 2, 2]            1,024\n",
              "\u2502    \u2502    \u2514\u2500ReLU: 3-123                  [1, 512, 2, 2]            --\n",
              "\u2502    \u2502    \u2514\u2500Conv2d: 3-124                [1, 512, 1, 1]            2,359,296\n",
              "\u2502    \u2502    \u2514\u2500BatchNorm2d: 3-125           [1, 512, 1, 1]            1,024\n",
              "\u2502    \u2502    \u2514\u2500ReLU: 3-126                  [1, 512, 1, 1]            --\n",
              "\u2502    \u2502    \u2514\u2500Conv2d: 3-127                [1, 2048, 1, 1]           1,048,576\n",
              "\u2502    \u2502    \u2514\u2500BatchNorm2d: 3-128           [1, 2048, 1, 1]           4,096\n",
              "\u2502    \u2502    \u2514\u2500Sequential: 3-129            [1, 2048, 1, 1]           2,101,248\n",
              "\u2502    \u2502    \u2514\u2500ReLU: 3-130                  [1, 2048, 1, 1]           --\n",
              "\u2502    \u2514\u2500Bottleneck: 2-15                  [1, 2048, 1, 1]           --\n",
              "\u2502    \u2502    \u2514\u2500Conv2d: 3-131                [1, 512, 1, 1]            1,048,576\n",
              "\u2502    \u2502    \u2514\u2500BatchNorm2d: 3-132           [1, 512, 1, 1]            1,024\n",
              "\u2502    \u2502    \u2514\u2500ReLU: 3-133                  [1, 512, 1, 1]            --\n",
              "\u2502    \u2502    \u2514\u2500Conv2d: 3-134                [1, 512, 1, 1]            2,359,296\n",
              "\u2502    \u2502    \u2514\u2500BatchNorm2d: 3-135           [1, 512, 1, 1]            1,024\n",
              "\u2502    \u2502    \u2514\u2500ReLU: 3-136                  [1, 512, 1, 1]            --\n",
              "\u2502    \u2502    \u2514\u2500Conv2d: 3-137                [1, 2048, 1, 1]           1,048,576\n",
              "\u2502    \u2502    \u2514\u2500BatchNorm2d: 3-138           [1, 2048, 1, 1]           4,096\n",
              "\u2502    \u2502    \u2514\u2500ReLU: 3-139                  [1, 2048, 1, 1]           --\n",
              "\u2502    \u2514\u2500Bottleneck: 2-16                  [1, 2048, 1, 1]           --\n",
              "\u2502    \u2502    \u2514\u2500Conv2d: 3-140                [1, 512, 1, 1]            1,048,576\n",
              "\u2502    \u2502    \u2514\u2500BatchNorm2d: 3-141           [1, 512, 1, 1]            1,024\n",
              "\u2502    \u2502    \u2514\u2500ReLU: 3-142                  [1, 512, 1, 1]            --\n",
              "\u2502    \u2502    \u2514\u2500Conv2d: 3-143                [1, 512, 1, 1]            2,359,296\n",
              "\u2502    \u2502    \u2514\u2500BatchNorm2d: 3-144           [1, 512, 1, 1]            1,024\n",
              "\u2502    \u2502    \u2514\u2500ReLU: 3-145                  [1, 512, 1, 1]            --\n",
              "\u2502    \u2502    \u2514\u2500Conv2d: 3-146                [1, 2048, 1, 1]           1,048,576\n",
              "\u2502    \u2502    \u2514\u2500BatchNorm2d: 3-147           [1, 2048, 1, 1]           4,096\n",
              "\u2502    \u2502    \u2514\u2500ReLU: 3-148                  [1, 2048, 1, 1]           --\n",
              "\u251c\u2500AdaptiveAvgPool2d: 1-9                 [1, 2048, 1, 1]           --\n",
              "\u251c\u2500Linear: 1-10                           [1, 1000]                 2,049,000\n",
              "==========================================================================================\n",
              "Total params: 25,557,032\n",
              "Trainable params: 25,557,032\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (Units.MEGABYTES): 85.51\n",
              "==========================================================================================\n",
              "Input size (MB): 0.01\n",
              "Forward/backward pass size (MB): 3.64\n",
              "Params size (MB): 102.23\n",
              "Estimated Total Size (MB): 105.88\n",
              "=========================================================================================="
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "summary(resnet, input_size=(1, *trainset[0][0].shape), device='cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Extract a subset of Pretrained Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.weight                - requires_grad : True\n",
            "1.weight                - requires_grad : True\n",
            "1.bias                  - requires_grad : True\n",
            "4.0.conv1.weight        - requires_grad : True\n",
            "4.0.bn1.weight          - requires_grad : True\n",
            "4.0.bn1.bias            - requires_grad : True\n",
            "4.0.conv2.weight        - requires_grad : True\n",
            "4.0.bn2.weight          - requires_grad : True\n",
            "4.0.bn2.bias            - requires_grad : True\n",
            "4.0.conv3.weight        - requires_grad : True\n",
            "4.0.bn3.weight          - requires_grad : True\n",
            "4.0.bn3.bias            - requires_grad : True\n",
            "4.0.downsample.0.weight - requires_grad : True\n",
            "4.0.downsample.1.weight - requires_grad : True\n",
            "4.0.downsample.1.bias   - requires_grad : True\n",
            "4.1.conv1.weight        - requires_grad : True\n",
            "4.1.bn1.weight          - requires_grad : True\n",
            "4.1.bn1.bias            - requires_grad : True\n",
            "4.1.conv2.weight        - requires_grad : True\n",
            "4.1.bn2.weight          - requires_grad : True\n",
            "4.1.bn2.bias            - requires_grad : True\n",
            "4.1.conv3.weight        - requires_grad : True\n",
            "4.1.bn3.weight          - requires_grad : True\n",
            "4.1.bn3.bias            - requires_grad : True\n",
            "4.2.conv1.weight        - requires_grad : True\n",
            "4.2.bn1.weight          - requires_grad : True\n",
            "4.2.bn1.bias            - requires_grad : True\n",
            "4.2.conv2.weight        - requires_grad : True\n",
            "4.2.bn2.weight          - requires_grad : True\n",
            "4.2.bn2.bias            - requires_grad : True\n",
            "4.2.conv3.weight        - requires_grad : True\n",
            "4.2.bn3.weight          - requires_grad : True\n",
            "4.2.bn3.bias            - requires_grad : True\n",
            "5.0.conv1.weight        - requires_grad : True\n",
            "5.0.bn1.weight          - requires_grad : True\n",
            "5.0.bn1.bias            - requires_grad : True\n",
            "5.0.conv2.weight        - requires_grad : True\n",
            "5.0.bn2.weight          - requires_grad : True\n",
            "5.0.bn2.bias            - requires_grad : True\n",
            "5.0.conv3.weight        - requires_grad : True\n",
            "5.0.bn3.weight          - requires_grad : True\n",
            "5.0.bn3.bias            - requires_grad : True\n",
            "5.0.downsample.0.weight - requires_grad : True\n",
            "5.0.downsample.1.weight - requires_grad : True\n",
            "5.0.downsample.1.bias   - requires_grad : True\n",
            "5.1.conv1.weight        - requires_grad : True\n",
            "5.1.bn1.weight          - requires_grad : True\n",
            "5.1.bn1.bias            - requires_grad : True\n",
            "5.1.conv2.weight        - requires_grad : True\n",
            "5.1.bn2.weight          - requires_grad : True\n",
            "5.1.bn2.bias            - requires_grad : True\n",
            "5.1.conv3.weight        - requires_grad : True\n",
            "5.1.bn3.weight          - requires_grad : True\n",
            "5.1.bn3.bias            - requires_grad : True\n",
            "5.2.conv1.weight        - requires_grad : True\n",
            "5.2.bn1.weight          - requires_grad : True\n",
            "5.2.bn1.bias            - requires_grad : True\n",
            "5.2.conv2.weight        - requires_grad : True\n",
            "5.2.bn2.weight          - requires_grad : True\n",
            "5.2.bn2.bias            - requires_grad : True\n",
            "5.2.conv3.weight        - requires_grad : True\n",
            "5.2.bn3.weight          - requires_grad : True\n",
            "5.2.bn3.bias            - requires_grad : True\n",
            "5.3.conv1.weight        - requires_grad : True\n",
            "5.3.bn1.weight          - requires_grad : True\n",
            "5.3.bn1.bias            - requires_grad : True\n",
            "5.3.conv2.weight        - requires_grad : True\n",
            "5.3.bn2.weight          - requires_grad : True\n",
            "5.3.bn2.bias            - requires_grad : True\n",
            "5.3.conv3.weight        - requires_grad : True\n",
            "5.3.bn3.weight          - requires_grad : True\n",
            "5.3.bn3.bias            - requires_grad : True\n",
            "6.0.conv1.weight        - requires_grad : True\n",
            "6.0.bn1.weight          - requires_grad : True\n",
            "6.0.bn1.bias            - requires_grad : True\n",
            "6.0.conv2.weight        - requires_grad : True\n",
            "6.0.bn2.weight          - requires_grad : True\n",
            "6.0.bn2.bias            - requires_grad : True\n",
            "6.0.conv3.weight        - requires_grad : True\n",
            "6.0.bn3.weight          - requires_grad : True\n",
            "6.0.bn3.bias            - requires_grad : True\n",
            "6.0.downsample.0.weight - requires_grad : True\n",
            "6.0.downsample.1.weight - requires_grad : True\n",
            "6.0.downsample.1.bias   - requires_grad : True\n",
            "6.1.conv1.weight        - requires_grad : True\n",
            "6.1.bn1.weight          - requires_grad : True\n",
            "6.1.bn1.bias            - requires_grad : True\n",
            "6.1.conv2.weight        - requires_grad : True\n",
            "6.1.bn2.weight          - requires_grad : True\n",
            "6.1.bn2.bias            - requires_grad : True\n",
            "6.1.conv3.weight        - requires_grad : True\n",
            "6.1.bn3.weight          - requires_grad : True\n",
            "6.1.bn3.bias            - requires_grad : True\n",
            "6.2.conv1.weight        - requires_grad : True\n",
            "6.2.bn1.weight          - requires_grad : True\n",
            "6.2.bn1.bias            - requires_grad : True\n",
            "6.2.conv2.weight        - requires_grad : True\n",
            "6.2.bn2.weight          - requires_grad : True\n",
            "6.2.bn2.bias            - requires_grad : True\n",
            "6.2.conv3.weight        - requires_grad : True\n",
            "6.2.bn3.weight          - requires_grad : True\n",
            "6.2.bn3.bias            - requires_grad : True\n",
            "6.3.conv1.weight        - requires_grad : True\n",
            "6.3.bn1.weight          - requires_grad : True\n",
            "6.3.bn1.bias            - requires_grad : True\n",
            "6.3.conv2.weight        - requires_grad : True\n",
            "6.3.bn2.weight          - requires_grad : True\n",
            "6.3.bn2.bias            - requires_grad : True\n",
            "6.3.conv3.weight        - requires_grad : True\n",
            "6.3.bn3.weight          - requires_grad : True\n",
            "6.3.bn3.bias            - requires_grad : True\n",
            "6.4.conv1.weight        - requires_grad : True\n",
            "6.4.bn1.weight          - requires_grad : True\n",
            "6.4.bn1.bias            - requires_grad : True\n",
            "6.4.conv2.weight        - requires_grad : True\n",
            "6.4.bn2.weight          - requires_grad : True\n",
            "6.4.bn2.bias            - requires_grad : True\n",
            "6.4.conv3.weight        - requires_grad : True\n",
            "6.4.bn3.weight          - requires_grad : True\n",
            "6.4.bn3.bias            - requires_grad : True\n",
            "6.5.conv1.weight        - requires_grad : True\n",
            "6.5.bn1.weight          - requires_grad : True\n",
            "6.5.bn1.bias            - requires_grad : True\n",
            "6.5.conv2.weight        - requires_grad : True\n",
            "6.5.bn2.weight          - requires_grad : True\n",
            "6.5.bn2.bias            - requires_grad : True\n",
            "6.5.conv3.weight        - requires_grad : True\n",
            "6.5.bn3.weight          - requires_grad : True\n",
            "6.5.bn3.bias            - requires_grad : True\n",
            "7.0.conv1.weight        - requires_grad : True\n",
            "7.0.bn1.weight          - requires_grad : True\n",
            "7.0.bn1.bias            - requires_grad : True\n",
            "7.0.conv2.weight        - requires_grad : True\n",
            "7.0.bn2.weight          - requires_grad : True\n",
            "7.0.bn2.bias            - requires_grad : True\n",
            "7.0.conv3.weight        - requires_grad : True\n",
            "7.0.bn3.weight          - requires_grad : True\n",
            "7.0.bn3.bias            - requires_grad : True\n",
            "7.0.downsample.0.weight - requires_grad : True\n",
            "7.0.downsample.1.weight - requires_grad : True\n",
            "7.0.downsample.1.bias   - requires_grad : True\n",
            "7.1.conv1.weight        - requires_grad : True\n",
            "7.1.bn1.weight          - requires_grad : True\n",
            "7.1.bn1.bias            - requires_grad : True\n",
            "7.1.conv2.weight        - requires_grad : True\n",
            "7.1.bn2.weight          - requires_grad : True\n",
            "7.1.bn2.bias            - requires_grad : True\n",
            "7.1.conv3.weight        - requires_grad : True\n",
            "7.1.bn3.weight          - requires_grad : True\n",
            "7.1.bn3.bias            - requires_grad : True\n",
            "7.2.conv1.weight        - requires_grad : True\n",
            "7.2.bn1.weight          - requires_grad : True\n",
            "7.2.bn1.bias            - requires_grad : True\n",
            "7.2.conv2.weight        - requires_grad : True\n",
            "7.2.bn2.weight          - requires_grad : True\n",
            "7.2.bn2.bias            - requires_grad : True\n",
            "7.2.conv3.weight        - requires_grad : True\n",
            "7.2.bn3.weight          - requires_grad : True\n",
            "7.2.bn3.bias            - requires_grad : True\n"
          ]
        }
      ],
      "source": [
        "feature_extractor = nn.Sequential(*list(resnet.children())[:-1])\n",
        "\n",
        "# log\n",
        "for name, param in feature_extractor.named_parameters():\n",
        "    print(f\"{name:<23} - requires_grad : {param.requires_grad}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Freeze Low-Level Layers\n",
        "   - Sometimes all layers are Unfreezed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.weight                     - requires_grad : False\n",
            "1.weight                     - requires_grad : False\n",
            "1.bias                       - requires_grad : False\n",
            "4.0.conv1.weight             - requires_grad : False\n",
            "4.0.bn1.weight               - requires_grad : False\n",
            "4.0.bn1.bias                 - requires_grad : False\n",
            "4.0.conv2.weight             - requires_grad : False\n",
            "4.0.bn2.weight               - requires_grad : False\n",
            "4.0.bn2.bias                 - requires_grad : False\n",
            "4.0.conv3.weight             - requires_grad : False\n",
            "4.0.bn3.weight               - requires_grad : False\n",
            "4.0.bn3.bias                 - requires_grad : False\n",
            "4.0.downsample.0.weight      - requires_grad : False\n",
            "4.0.downsample.1.weight      - requires_grad : False\n",
            "4.0.downsample.1.bias        - requires_grad : False\n",
            "4.1.conv1.weight             - requires_grad : False\n",
            "4.1.bn1.weight               - requires_grad : False\n",
            "4.1.bn1.bias                 - requires_grad : False\n",
            "4.1.conv2.weight             - requires_grad : False\n",
            "4.1.bn2.weight               - requires_grad : False\n",
            "4.1.bn2.bias                 - requires_grad : False\n",
            "4.1.conv3.weight             - requires_grad : False\n",
            "4.1.bn3.weight               - requires_grad : False\n",
            "4.1.bn3.bias                 - requires_grad : False\n",
            "4.2.conv1.weight             - requires_grad : True\n",
            "4.2.bn1.weight               - requires_grad : True\n",
            "4.2.bn1.bias                 - requires_grad : True\n",
            "4.2.conv2.weight             - requires_grad : True\n",
            "4.2.bn2.weight               - requires_grad : True\n",
            "4.2.bn2.bias                 - requires_grad : True\n",
            "4.2.conv3.weight             - requires_grad : True\n",
            "4.2.bn3.weight               - requires_grad : True\n",
            "4.2.bn3.bias                 - requires_grad : True\n",
            "5.0.conv1.weight             - requires_grad : True\n",
            "5.0.bn1.weight               - requires_grad : True\n",
            "5.0.bn1.bias                 - requires_grad : True\n",
            "5.0.conv2.weight             - requires_grad : True\n",
            "5.0.bn2.weight               - requires_grad : True\n",
            "5.0.bn2.bias                 - requires_grad : True\n",
            "5.0.conv3.weight             - requires_grad : True\n",
            "5.0.bn3.weight               - requires_grad : True\n",
            "5.0.bn3.bias                 - requires_grad : True\n",
            "5.0.downsample.0.weight      - requires_grad : True\n",
            "5.0.downsample.1.weight      - requires_grad : True\n",
            "5.0.downsample.1.bias        - requires_grad : True\n",
            "5.1.conv1.weight             - requires_grad : True\n",
            "5.1.bn1.weight               - requires_grad : True\n",
            "5.1.bn1.bias                 - requires_grad : True\n",
            "5.1.conv2.weight             - requires_grad : True\n",
            "5.1.bn2.weight               - requires_grad : True\n",
            "5.1.bn2.bias                 - requires_grad : True\n",
            "5.1.conv3.weight             - requires_grad : True\n",
            "5.1.bn3.weight               - requires_grad : True\n",
            "5.1.bn3.bias                 - requires_grad : True\n",
            "5.2.conv1.weight             - requires_grad : True\n",
            "5.2.bn1.weight               - requires_grad : True\n",
            "5.2.bn1.bias                 - requires_grad : True\n",
            "5.2.conv2.weight             - requires_grad : True\n",
            "5.2.bn2.weight               - requires_grad : True\n",
            "5.2.bn2.bias                 - requires_grad : True\n",
            "5.2.conv3.weight             - requires_grad : True\n",
            "5.2.bn3.weight               - requires_grad : True\n",
            "5.2.bn3.bias                 - requires_grad : True\n",
            "5.3.conv1.weight             - requires_grad : True\n",
            "5.3.bn1.weight               - requires_grad : True\n",
            "5.3.bn1.bias                 - requires_grad : True\n",
            "5.3.conv2.weight             - requires_grad : True\n",
            "5.3.bn2.weight               - requires_grad : True\n",
            "5.3.bn2.bias                 - requires_grad : True\n",
            "5.3.conv3.weight             - requires_grad : True\n",
            "5.3.bn3.weight               - requires_grad : True\n",
            "5.3.bn3.bias                 - requires_grad : True\n",
            "6.0.conv1.weight             - requires_grad : True\n",
            "6.0.bn1.weight               - requires_grad : True\n",
            "6.0.bn1.bias                 - requires_grad : True\n",
            "6.0.conv2.weight             - requires_grad : True\n",
            "6.0.bn2.weight               - requires_grad : True\n",
            "6.0.bn2.bias                 - requires_grad : True\n",
            "6.0.conv3.weight             - requires_grad : True\n",
            "6.0.bn3.weight               - requires_grad : True\n",
            "6.0.bn3.bias                 - requires_grad : True\n",
            "6.0.downsample.0.weight      - requires_grad : True\n",
            "6.0.downsample.1.weight      - requires_grad : True\n",
            "6.0.downsample.1.bias        - requires_grad : True\n",
            "6.1.conv1.weight             - requires_grad : True\n",
            "6.1.bn1.weight               - requires_grad : True\n",
            "6.1.bn1.bias                 - requires_grad : True\n",
            "6.1.conv2.weight             - requires_grad : True\n",
            "6.1.bn2.weight               - requires_grad : True\n",
            "6.1.bn2.bias                 - requires_grad : True\n",
            "6.1.conv3.weight             - requires_grad : True\n",
            "6.1.bn3.weight               - requires_grad : True\n",
            "6.1.bn3.bias                 - requires_grad : True\n",
            "6.2.conv1.weight             - requires_grad : True\n",
            "6.2.bn1.weight               - requires_grad : True\n",
            "6.2.bn1.bias                 - requires_grad : True\n",
            "6.2.conv2.weight             - requires_grad : True\n",
            "6.2.bn2.weight               - requires_grad : True\n",
            "6.2.bn2.bias                 - requires_grad : True\n",
            "6.2.conv3.weight             - requires_grad : True\n",
            "6.2.bn3.weight               - requires_grad : True\n",
            "6.2.bn3.bias                 - requires_grad : True\n",
            "6.3.conv1.weight             - requires_grad : True\n",
            "6.3.bn1.weight               - requires_grad : True\n",
            "6.3.bn1.bias                 - requires_grad : True\n",
            "6.3.conv2.weight             - requires_grad : True\n",
            "6.3.bn2.weight               - requires_grad : True\n",
            "6.3.bn2.bias                 - requires_grad : True\n",
            "6.3.conv3.weight             - requires_grad : True\n",
            "6.3.bn3.weight               - requires_grad : True\n",
            "6.3.bn3.bias                 - requires_grad : True\n",
            "6.4.conv1.weight             - requires_grad : True\n",
            "6.4.bn1.weight               - requires_grad : True\n",
            "6.4.bn1.bias                 - requires_grad : True\n",
            "6.4.conv2.weight             - requires_grad : True\n",
            "6.4.bn2.weight               - requires_grad : True\n",
            "6.4.bn2.bias                 - requires_grad : True\n",
            "6.4.conv3.weight             - requires_grad : True\n",
            "6.4.bn3.weight               - requires_grad : True\n",
            "6.4.bn3.bias                 - requires_grad : True\n",
            "6.5.conv1.weight             - requires_grad : True\n",
            "6.5.bn1.weight               - requires_grad : True\n",
            "6.5.bn1.bias                 - requires_grad : True\n",
            "6.5.conv2.weight             - requires_grad : True\n",
            "6.5.bn2.weight               - requires_grad : True\n",
            "6.5.bn2.bias                 - requires_grad : True\n",
            "6.5.conv3.weight             - requires_grad : True\n",
            "6.5.bn3.weight               - requires_grad : True\n",
            "6.5.bn3.bias                 - requires_grad : True\n",
            "7.0.conv1.weight             - requires_grad : True\n",
            "7.0.bn1.weight               - requires_grad : True\n",
            "7.0.bn1.bias                 - requires_grad : True\n",
            "7.0.conv2.weight             - requires_grad : True\n",
            "7.0.bn2.weight               - requires_grad : True\n",
            "7.0.bn2.bias                 - requires_grad : True\n",
            "7.0.conv3.weight             - requires_grad : True\n",
            "7.0.bn3.weight               - requires_grad : True\n",
            "7.0.bn3.bias                 - requires_grad : True\n",
            "7.0.downsample.0.weight      - requires_grad : True\n",
            "7.0.downsample.1.weight      - requires_grad : True\n",
            "7.0.downsample.1.bias        - requires_grad : True\n",
            "7.1.conv1.weight             - requires_grad : True\n",
            "7.1.bn1.weight               - requires_grad : True\n",
            "7.1.bn1.bias                 - requires_grad : True\n",
            "7.1.conv2.weight             - requires_grad : True\n",
            "7.1.bn2.weight               - requires_grad : True\n",
            "7.1.bn2.bias                 - requires_grad : True\n",
            "7.1.conv3.weight             - requires_grad : True\n",
            "7.1.bn3.weight               - requires_grad : True\n",
            "7.1.bn3.bias                 - requires_grad : True\n",
            "7.2.conv1.weight             - requires_grad : True\n",
            "7.2.bn1.weight               - requires_grad : True\n",
            "7.2.bn1.bias                 - requires_grad : True\n",
            "7.2.conv2.weight             - requires_grad : True\n",
            "7.2.bn2.weight               - requires_grad : True\n",
            "7.2.bn2.bias                 - requires_grad : True\n",
            "7.2.conv3.weight             - requires_grad : True\n",
            "7.2.bn3.weight               - requires_grad : True\n",
            "7.2.bn3.bias                 - requires_grad : True\n"
          ]
        }
      ],
      "source": [
        "for name, param in feature_extractor.named_parameters():\n",
        "    if name.startswith('4.2'):\n",
        "        break\n",
        "    param.requires_grad_(False)\n",
        "\n",
        "# log\n",
        "for name, param in feature_extractor.named_parameters():\n",
        "    print(f\"{name:<28} - requires_grad : {param.requires_grad}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Transfer the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "MyModel(\n",
              "  (feature_extractor): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (4): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (5): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (6): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (4): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (5): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (7): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  )\n",
              "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=2048, out_features=256, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=256, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class MyModel(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.feature_extractor = feature_extractor\n",
        "        self.flatten = nn.Flatten(start_dim=1)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(2048, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.feature_extractor(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "model = MyModel()\n",
        "\n",
        "# log\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "feature_extractor.0.weight                - requires_grad : False\n",
            "feature_extractor.1.weight                - requires_grad : False\n",
            "feature_extractor.1.bias                  - requires_grad : False\n",
            "feature_extractor.4.0.conv1.weight        - requires_grad : False\n",
            "feature_extractor.4.0.bn1.weight          - requires_grad : False\n",
            "feature_extractor.4.0.bn1.bias            - requires_grad : False\n",
            "feature_extractor.4.0.conv2.weight        - requires_grad : False\n",
            "feature_extractor.4.0.bn2.weight          - requires_grad : False\n",
            "feature_extractor.4.0.bn2.bias            - requires_grad : False\n",
            "feature_extractor.4.0.conv3.weight        - requires_grad : False\n",
            "feature_extractor.4.0.bn3.weight          - requires_grad : False\n",
            "feature_extractor.4.0.bn3.bias            - requires_grad : False\n",
            "feature_extractor.4.0.downsample.0.weight - requires_grad : False\n",
            "feature_extractor.4.0.downsample.1.weight - requires_grad : False\n",
            "feature_extractor.4.0.downsample.1.bias   - requires_grad : False\n",
            "feature_extractor.4.1.conv1.weight        - requires_grad : False\n",
            "feature_extractor.4.1.bn1.weight          - requires_grad : False\n",
            "feature_extractor.4.1.bn1.bias            - requires_grad : False\n",
            "feature_extractor.4.1.conv2.weight        - requires_grad : False\n",
            "feature_extractor.4.1.bn2.weight          - requires_grad : False\n",
            "feature_extractor.4.1.bn2.bias            - requires_grad : False\n",
            "feature_extractor.4.1.conv3.weight        - requires_grad : False\n",
            "feature_extractor.4.1.bn3.weight          - requires_grad : False\n",
            "feature_extractor.4.1.bn3.bias            - requires_grad : False\n",
            "feature_extractor.4.2.conv1.weight        - requires_grad : True\n",
            "feature_extractor.4.2.bn1.weight          - requires_grad : True\n",
            "feature_extractor.4.2.bn1.bias            - requires_grad : True\n",
            "feature_extractor.4.2.conv2.weight        - requires_grad : True\n",
            "feature_extractor.4.2.bn2.weight          - requires_grad : True\n",
            "feature_extractor.4.2.bn2.bias            - requires_grad : True\n",
            "feature_extractor.4.2.conv3.weight        - requires_grad : True\n",
            "feature_extractor.4.2.bn3.weight          - requires_grad : True\n",
            "feature_extractor.4.2.bn3.bias            - requires_grad : True\n",
            "feature_extractor.5.0.conv1.weight        - requires_grad : True\n",
            "feature_extractor.5.0.bn1.weight          - requires_grad : True\n",
            "feature_extractor.5.0.bn1.bias            - requires_grad : True\n",
            "feature_extractor.5.0.conv2.weight        - requires_grad : True\n",
            "feature_extractor.5.0.bn2.weight          - requires_grad : True\n",
            "feature_extractor.5.0.bn2.bias            - requires_grad : True\n",
            "feature_extractor.5.0.conv3.weight        - requires_grad : True\n",
            "feature_extractor.5.0.bn3.weight          - requires_grad : True\n",
            "feature_extractor.5.0.bn3.bias            - requires_grad : True\n",
            "feature_extractor.5.0.downsample.0.weight - requires_grad : True\n",
            "feature_extractor.5.0.downsample.1.weight - requires_grad : True\n",
            "feature_extractor.5.0.downsample.1.bias   - requires_grad : True\n",
            "feature_extractor.5.1.conv1.weight        - requires_grad : True\n",
            "feature_extractor.5.1.bn1.weight          - requires_grad : True\n",
            "feature_extractor.5.1.bn1.bias            - requires_grad : True\n",
            "feature_extractor.5.1.conv2.weight        - requires_grad : True\n",
            "feature_extractor.5.1.bn2.weight          - requires_grad : True\n",
            "feature_extractor.5.1.bn2.bias            - requires_grad : True\n",
            "feature_extractor.5.1.conv3.weight        - requires_grad : True\n",
            "feature_extractor.5.1.bn3.weight          - requires_grad : True\n",
            "feature_extractor.5.1.bn3.bias            - requires_grad : True\n",
            "feature_extractor.5.2.conv1.weight        - requires_grad : True\n",
            "feature_extractor.5.2.bn1.weight          - requires_grad : True\n",
            "feature_extractor.5.2.bn1.bias            - requires_grad : True\n",
            "feature_extractor.5.2.conv2.weight        - requires_grad : True\n",
            "feature_extractor.5.2.bn2.weight          - requires_grad : True\n",
            "feature_extractor.5.2.bn2.bias            - requires_grad : True\n",
            "feature_extractor.5.2.conv3.weight        - requires_grad : True\n",
            "feature_extractor.5.2.bn3.weight          - requires_grad : True\n",
            "feature_extractor.5.2.bn3.bias            - requires_grad : True\n",
            "feature_extractor.5.3.conv1.weight        - requires_grad : True\n",
            "feature_extractor.5.3.bn1.weight          - requires_grad : True\n",
            "feature_extractor.5.3.bn1.bias            - requires_grad : True\n",
            "feature_extractor.5.3.conv2.weight        - requires_grad : True\n",
            "feature_extractor.5.3.bn2.weight          - requires_grad : True\n",
            "feature_extractor.5.3.bn2.bias            - requires_grad : True\n",
            "feature_extractor.5.3.conv3.weight        - requires_grad : True\n",
            "feature_extractor.5.3.bn3.weight          - requires_grad : True\n",
            "feature_extractor.5.3.bn3.bias            - requires_grad : True\n",
            "feature_extractor.6.0.conv1.weight        - requires_grad : True\n",
            "feature_extractor.6.0.bn1.weight          - requires_grad : True\n",
            "feature_extractor.6.0.bn1.bias            - requires_grad : True\n",
            "feature_extractor.6.0.conv2.weight        - requires_grad : True\n",
            "feature_extractor.6.0.bn2.weight          - requires_grad : True\n",
            "feature_extractor.6.0.bn2.bias            - requires_grad : True\n",
            "feature_extractor.6.0.conv3.weight        - requires_grad : True\n",
            "feature_extractor.6.0.bn3.weight          - requires_grad : True\n",
            "feature_extractor.6.0.bn3.bias            - requires_grad : True\n",
            "feature_extractor.6.0.downsample.0.weight - requires_grad : True\n",
            "feature_extractor.6.0.downsample.1.weight - requires_grad : True\n",
            "feature_extractor.6.0.downsample.1.bias   - requires_grad : True\n",
            "feature_extractor.6.1.conv1.weight        - requires_grad : True\n",
            "feature_extractor.6.1.bn1.weight          - requires_grad : True\n",
            "feature_extractor.6.1.bn1.bias            - requires_grad : True\n",
            "feature_extractor.6.1.conv2.weight        - requires_grad : True\n",
            "feature_extractor.6.1.bn2.weight          - requires_grad : True\n",
            "feature_extractor.6.1.bn2.bias            - requires_grad : True\n",
            "feature_extractor.6.1.conv3.weight        - requires_grad : True\n",
            "feature_extractor.6.1.bn3.weight          - requires_grad : True\n",
            "feature_extractor.6.1.bn3.bias            - requires_grad : True\n",
            "feature_extractor.6.2.conv1.weight        - requires_grad : True\n",
            "feature_extractor.6.2.bn1.weight          - requires_grad : True\n",
            "feature_extractor.6.2.bn1.bias            - requires_grad : True\n",
            "feature_extractor.6.2.conv2.weight        - requires_grad : True\n",
            "feature_extractor.6.2.bn2.weight          - requires_grad : True\n",
            "feature_extractor.6.2.bn2.bias            - requires_grad : True\n",
            "feature_extractor.6.2.conv3.weight        - requires_grad : True\n",
            "feature_extractor.6.2.bn3.weight          - requires_grad : True\n",
            "feature_extractor.6.2.bn3.bias            - requires_grad : True\n",
            "feature_extractor.6.3.conv1.weight        - requires_grad : True\n",
            "feature_extractor.6.3.bn1.weight          - requires_grad : True\n",
            "feature_extractor.6.3.bn1.bias            - requires_grad : True\n",
            "feature_extractor.6.3.conv2.weight        - requires_grad : True\n",
            "feature_extractor.6.3.bn2.weight          - requires_grad : True\n",
            "feature_extractor.6.3.bn2.bias            - requires_grad : True\n",
            "feature_extractor.6.3.conv3.weight        - requires_grad : True\n",
            "feature_extractor.6.3.bn3.weight          - requires_grad : True\n",
            "feature_extractor.6.3.bn3.bias            - requires_grad : True\n",
            "feature_extractor.6.4.conv1.weight        - requires_grad : True\n",
            "feature_extractor.6.4.bn1.weight          - requires_grad : True\n",
            "feature_extractor.6.4.bn1.bias            - requires_grad : True\n",
            "feature_extractor.6.4.conv2.weight        - requires_grad : True\n",
            "feature_extractor.6.4.bn2.weight          - requires_grad : True\n",
            "feature_extractor.6.4.bn2.bias            - requires_grad : True\n",
            "feature_extractor.6.4.conv3.weight        - requires_grad : True\n",
            "feature_extractor.6.4.bn3.weight          - requires_grad : True\n",
            "feature_extractor.6.4.bn3.bias            - requires_grad : True\n",
            "feature_extractor.6.5.conv1.weight        - requires_grad : True\n",
            "feature_extractor.6.5.bn1.weight          - requires_grad : True\n",
            "feature_extractor.6.5.bn1.bias            - requires_grad : True\n",
            "feature_extractor.6.5.conv2.weight        - requires_grad : True\n",
            "feature_extractor.6.5.bn2.weight          - requires_grad : True\n",
            "feature_extractor.6.5.bn2.bias            - requires_grad : True\n",
            "feature_extractor.6.5.conv3.weight        - requires_grad : True\n",
            "feature_extractor.6.5.bn3.weight          - requires_grad : True\n",
            "feature_extractor.6.5.bn3.bias            - requires_grad : True\n",
            "feature_extractor.7.0.conv1.weight        - requires_grad : True\n",
            "feature_extractor.7.0.bn1.weight          - requires_grad : True\n",
            "feature_extractor.7.0.bn1.bias            - requires_grad : True\n",
            "feature_extractor.7.0.conv2.weight        - requires_grad : True\n",
            "feature_extractor.7.0.bn2.weight          - requires_grad : True\n",
            "feature_extractor.7.0.bn2.bias            - requires_grad : True\n",
            "feature_extractor.7.0.conv3.weight        - requires_grad : True\n",
            "feature_extractor.7.0.bn3.weight          - requires_grad : True\n",
            "feature_extractor.7.0.bn3.bias            - requires_grad : True\n",
            "feature_extractor.7.0.downsample.0.weight - requires_grad : True\n",
            "feature_extractor.7.0.downsample.1.weight - requires_grad : True\n",
            "feature_extractor.7.0.downsample.1.bias   - requires_grad : True\n",
            "feature_extractor.7.1.conv1.weight        - requires_grad : True\n",
            "feature_extractor.7.1.bn1.weight          - requires_grad : True\n",
            "feature_extractor.7.1.bn1.bias            - requires_grad : True\n",
            "feature_extractor.7.1.conv2.weight        - requires_grad : True\n",
            "feature_extractor.7.1.bn2.weight          - requires_grad : True\n",
            "feature_extractor.7.1.bn2.bias            - requires_grad : True\n",
            "feature_extractor.7.1.conv3.weight        - requires_grad : True\n",
            "feature_extractor.7.1.bn3.weight          - requires_grad : True\n",
            "feature_extractor.7.1.bn3.bias            - requires_grad : True\n",
            "feature_extractor.7.2.conv1.weight        - requires_grad : True\n",
            "feature_extractor.7.2.bn1.weight          - requires_grad : True\n",
            "feature_extractor.7.2.bn1.bias            - requires_grad : True\n",
            "feature_extractor.7.2.conv2.weight        - requires_grad : True\n",
            "feature_extractor.7.2.bn2.weight          - requires_grad : True\n",
            "feature_extractor.7.2.bn2.bias            - requires_grad : True\n",
            "feature_extractor.7.2.conv3.weight        - requires_grad : True\n",
            "feature_extractor.7.2.bn3.weight          - requires_grad : True\n",
            "feature_extractor.7.2.bn3.bias            - requires_grad : True\n",
            "classifier.0.weight                       - requires_grad : True\n",
            "classifier.0.bias                         - requires_grad : True\n",
            "classifier.2.weight                       - requires_grad : True\n",
            "classifier.2.bias                         - requires_grad : True\n"
          ]
        }
      ],
      "source": [
        "for name, param in model.named_parameters():\n",
        "    print(f\"{name:<41} - requires_grad : {param.requires_grad}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "===============================================================================================\n",
              "Layer (type:depth-idx)                        Output Shape              Param #\n",
              "===============================================================================================\n",
              "MyModel                                       [1, 10]                   --\n",
              "\u251c\u2500Sequential: 1-1                             [1, 2048, 1, 1]           --\n",
              "\u2502    \u2514\u2500Conv2d: 2-1                            [1, 64, 16, 16]           (9,408)\n",
              "\u2502    \u2514\u2500BatchNorm2d: 2-2                       [1, 64, 16, 16]           (128)\n",
              "\u2502    \u2514\u2500ReLU: 2-3                              [1, 64, 16, 16]           --\n",
              "\u2502    \u2514\u2500MaxPool2d: 2-4                         [1, 64, 8, 8]             --\n",
              "\u2502    \u2514\u2500Sequential: 2-5                        [1, 256, 8, 8]            --\n",
              "\u2502    \u2502    \u2514\u2500Bottleneck: 3-1                   [1, 256, 8, 8]            (75,008)\n",
              "\u2502    \u2502    \u2514\u2500Bottleneck: 3-2                   [1, 256, 8, 8]            (70,400)\n",
              "\u2502    \u2502    \u2514\u2500Bottleneck: 3-3                   [1, 256, 8, 8]            70,400\n",
              "\u2502    \u2514\u2500Sequential: 2-6                        [1, 512, 4, 4]            --\n",
              "\u2502    \u2502    \u2514\u2500Bottleneck: 3-4                   [1, 512, 4, 4]            379,392\n",
              "\u2502    \u2502    \u2514\u2500Bottleneck: 3-5                   [1, 512, 4, 4]            280,064\n",
              "\u2502    \u2502    \u2514\u2500Bottleneck: 3-6                   [1, 512, 4, 4]            280,064\n",
              "\u2502    \u2502    \u2514\u2500Bottleneck: 3-7                   [1, 512, 4, 4]            280,064\n",
              "\u2502    \u2514\u2500Sequential: 2-7                        [1, 1024, 2, 2]           --\n",
              "\u2502    \u2502    \u2514\u2500Bottleneck: 3-8                   [1, 1024, 2, 2]           1,512,448\n",
              "\u2502    \u2502    \u2514\u2500Bottleneck: 3-9                   [1, 1024, 2, 2]           1,117,184\n",
              "\u2502    \u2502    \u2514\u2500Bottleneck: 3-10                  [1, 1024, 2, 2]           1,117,184\n",
              "\u2502    \u2502    \u2514\u2500Bottleneck: 3-11                  [1, 1024, 2, 2]           1,117,184\n",
              "\u2502    \u2502    \u2514\u2500Bottleneck: 3-12                  [1, 1024, 2, 2]           1,117,184\n",
              "\u2502    \u2502    \u2514\u2500Bottleneck: 3-13                  [1, 1024, 2, 2]           1,117,184\n",
              "\u2502    \u2514\u2500Sequential: 2-8                        [1, 2048, 1, 1]           --\n",
              "\u2502    \u2502    \u2514\u2500Bottleneck: 3-14                  [1, 2048, 1, 1]           6,039,552\n",
              "\u2502    \u2502    \u2514\u2500Bottleneck: 3-15                  [1, 2048, 1, 1]           4,462,592\n",
              "\u2502    \u2502    \u2514\u2500Bottleneck: 3-16                  [1, 2048, 1, 1]           4,462,592\n",
              "\u2502    \u2514\u2500AdaptiveAvgPool2d: 2-9                 [1, 2048, 1, 1]           --\n",
              "\u251c\u2500Flatten: 1-2                                [1, 2048]                 --\n",
              "\u251c\u2500Sequential: 1-3                             [1, 10]                   --\n",
              "\u2502    \u2514\u2500Linear: 2-10                           [1, 256]                  524,544\n",
              "\u2502    \u2514\u2500ReLU: 2-11                             [1, 256]                  --\n",
              "\u2502    \u2514\u2500Linear: 2-12                           [1, 10]                   2,570\n",
              "===============================================================================================\n",
              "Total params: 24,035,146\n",
              "Trainable params: 23,880,202\n",
              "Non-trainable params: 154,944\n",
              "Total mult-adds (Units.MEGABYTES): 83.99\n",
              "===============================================================================================\n",
              "Input size (MB): 0.01\n",
              "Forward/backward pass size (MB): 3.63\n",
              "Params size (MB): 96.14\n",
              "Estimated Total Size (MB): 99.78\n",
              "==============================================================================================="
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "summary(model, input_size=(1, *trainset[0][0].shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Set up remaining Hyper-Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "lr = 0.001\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = Adam(params=model.parameters(), lr=lr)\n",
        "num_epochs = 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Train Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_acc_per_epoch = []\n",
        "train_loss_per_epoch = []\n",
        "train_acc = Accuracy(task='multiclass', num_classes=len(testset.classes), top_k=1).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch  0  ->  train[loss: 0.92424 - acc: 0.69]\n",
            "epoch  1  ->  train[loss: 0.60700 - acc: 0.80]\n",
            "epoch  2  ->  train[loss: 0.46458 - acc: 0.85]\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(num_epochs):\n",
        "\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "\n",
        "    for x, y in trainloader:\n",
        "\n",
        "        # send data to GPU\n",
        "        x, y_true = x.to(device), y.to(device)\n",
        "\n",
        "        # forward\n",
        "        y_pred = model(x)\n",
        "        loss = criterion(y_pred, y_true)\n",
        "\n",
        "        # backward\n",
        "        loss.backward()\n",
        "\n",
        "        # update parameters\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # log loss & accuracy\n",
        "        train_loss += loss.item() * len(x)\n",
        "        train_acc.update(y_pred, y_true)\n",
        "\n",
        "    train_loss_per_epoch.append(train_loss / len(trainset))\n",
        "    train_acc_per_epoch.append(train_acc.compute().item())\n",
        "    train_acc.reset()\n",
        "\n",
        "    # log\n",
        "    print(f\"epoch {epoch:>2}  ->  train[loss: {train_loss_per_epoch[epoch]:.5f} - acc: {train_acc_per_epoch[epoch]:.2f}]\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "author_name": "Amirhossein Heydari",
    "author_email": "AmirhosseinHeydari78@gmail.com",
    "author_github": "https://github.com/mr-pylin",
    "origin_repo": "https://github.com/mr-pylin/pytorch-workshop"
  },
  "nbformat": 4,
  "nbformat_minor": 2
}