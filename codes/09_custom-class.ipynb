{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ud83d\udcdd **Author:** Amirhossein Heydari - \ud83d\udce7 **Email:** amirhosseinheydari78@gmail.com - \ud83d\udccd **Linktree:** [linktr.ee/mr_pylin](https://linktr.ee/mr_pylin)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
        "from torchvision import transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Custom Classes in PyTorch\n",
        "   - PyTorch is a flexible deep learning framework that allows developers to customize different components according to their specific needs.\n",
        "   - This flexibility is essential for implementing custom datasets, models, and optimization routines, which may not be covered by the built-in classes.\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Custom Dataset\n",
        "   - PyTorch\u2019s `Dataset` class can be easily subclassed to define custom datasets\n",
        "   - This allows you to load and preprocess your data according to your needs.\n",
        "   - Use `torch.utils.data.Dataset` as the parent class and override `__len__` and `__getitem__`.\n",
        "\n",
        "\ud83d\udcdd **Docs & Tutorials** \ud83d\udcda:\n",
        "   - Data Loading Utility: [pytorch.org/docs/stable/data.html](https://pytorch.org/docs/stable/data.html)\n",
        "   - Datasets & DataLoaders: [pytorch.org/tutorials/beginner/basics/data_tutorial.html](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "type(X): <class 'numpy.ndarray'>  |  X.dtype: float64  |  X.shape: (569, 30)\n",
            "type(y): <class 'numpy.ndarray'>  |  y.dtype: int32    |  y.shape: (569,)\n",
            "--------------------------------------------------\n",
            "unique labels     : [0 1]\n",
            "samples per label : [212 357]\n",
            "--------------------------------------------------\n",
            "X[0]: [1.799e+01 1.038e+01 1.228e+02 1.001e+03 1.184e-01 2.776e-01 3.001e-01\n",
            " 1.471e-01 2.419e-01 7.871e-02 1.095e+00 9.053e-01 8.589e+00 1.534e+02\n",
            " 6.399e-03 4.904e-02 5.373e-02 1.587e-02 3.003e-02 6.193e-03 2.538e+01\n",
            " 1.733e+01 1.846e+02 2.019e+03 1.622e-01 6.656e-01 7.119e-01 2.654e-01\n",
            " 4.601e-01 1.189e-01]\n",
            "\n",
            "y[0]: 0\n"
          ]
        }
      ],
      "source": [
        "cancer_dataset = load_breast_cancer(return_X_y=True)\n",
        "X, y = cancer_dataset\n",
        "\n",
        "# log\n",
        "print(f\"type(X): {type(X)}  |  X.dtype: {X.dtype}  |  X.shape: {X.shape}\")\n",
        "print(f\"type(y): {type(y)}  |  y.dtype: {y.dtype}    |  y.shape: {y.shape}\")\n",
        "print('-' * 50)\n",
        "print(f\"unique labels     : {np.unique(y)}\")\n",
        "print(f\"samples per label : {np.unique(y, return_counts=True)[1]}\")\n",
        "print('-' * 50)\n",
        "print(f\"X[0]: {X[0]}\\n\")\n",
        "print(f\"y[0]: {y[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "type(X): <class 'torch.Tensor'>  |  X.dtype: torch.float32  |  X.shape: torch.Size([569, 30])\n",
            "type(y): <class 'torch.Tensor'>  |  y.dtype: torch.float32  |  y.shape: torch.Size([569, 1])\n"
          ]
        }
      ],
      "source": [
        "# convert numpy.ndarray to torch.Tensor\n",
        "X = torch.tensor(X, dtype=torch.float32)\n",
        "y = torch.tensor(y, dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "# log\n",
        "print(f\"type(X): {type(X)}  |  X.dtype: {X.dtype}  |  X.shape: {X.shape}\")\n",
        "print(f\"type(y): {type(y)}  |  y.dtype: {y.dtype}  |  y.shape: {y.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, data: torch.Tensor, labels: torch.Tensor) -> None:\n",
        "        self.data = data\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index: int) -> tuple[torch.Tensor, torch.Tensor]:\n",
        "        return self.data[index], self.labels[index]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "type(dataset_1) : <class '__main__.CustomDataset'>\n",
            "len(dataset_1)  : 569\n",
            "dataset_1[0]    : (tensor([1.7990e+01, 1.0380e+01, 1.2280e+02, 1.0010e+03, 1.1840e-01, 2.7760e-01,\n",
            "        3.0010e-01, 1.4710e-01, 2.4190e-01, 7.8710e-02, 1.0950e+00, 9.0530e-01,\n",
            "        8.5890e+00, 1.5340e+02, 6.3990e-03, 4.9040e-02, 5.3730e-02, 1.5870e-02,\n",
            "        3.0030e-02, 6.1930e-03, 2.5380e+01, 1.7330e+01, 1.8460e+02, 2.0190e+03,\n",
            "        1.6220e-01, 6.6560e-01, 7.1190e-01, 2.6540e-01, 4.6010e-01, 1.1890e-01]), tensor([0.]))\n",
            "--------------------------------------------------\n",
            "type(dataset_2) : <class 'torch.utils.data.dataset.TensorDataset'>\n",
            "len(dataset_2)  : 569\n",
            "dataset_2[0]    : (tensor([1.7990e+01, 1.0380e+01, 1.2280e+02, 1.0010e+03, 1.1840e-01, 2.7760e-01,\n",
            "        3.0010e-01, 1.4710e-01, 2.4190e-01, 7.8710e-02, 1.0950e+00, 9.0530e-01,\n",
            "        8.5890e+00, 1.5340e+02, 6.3990e-03, 4.9040e-02, 5.3730e-02, 1.5870e-02,\n",
            "        3.0030e-02, 6.1930e-03, 2.5380e+01, 1.7330e+01, 1.8460e+02, 2.0190e+03,\n",
            "        1.6220e-01, 6.6560e-01, 7.1190e-01, 2.6540e-01, 4.6010e-01, 1.1890e-01]), tensor([0.]))\n"
          ]
        }
      ],
      "source": [
        "# create a pytorch dataset\n",
        "dataset_1 = CustomDataset(X, y)  # custom\n",
        "dataset_2 = TensorDataset(X, y)  # built-in\n",
        "\n",
        "# log\n",
        "print(f\"type(dataset_1) : {type(dataset_1)}\")\n",
        "print(f\"len(dataset_1)  : {len(dataset_1)}\")\n",
        "print(f\"dataset_1[0]    : {dataset_1[0]}\")\n",
        "print('-' * 50)\n",
        "print(f\"type(dataset_2) : {type(dataset_2)}\")\n",
        "print(f\"len(dataset_2)  : {len(dataset_2)}\")\n",
        "print(f\"dataset_2[0]    : {dataset_2[0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Custom Transform\n",
        "   - Transforms are used to modify the input data before feeding it into the model.\n",
        "   - PyTorch provides a lot of built-in transforms (like cropping, flipping, etc.) in `torchvision.transforms`.\n",
        "   - you can define your own transformation by implementing the `__call__` method.\n",
        "\n",
        "\ud83d\udcdd **Docs & Tutorials** \ud83d\udcda:\n",
        "   - Transforming and augmenting images: [pytorch.org/vision/stable/transforms.html](https://pytorch.org/vision/stable/transforms.html)\n",
        "   - Transforms: [pytorch.org/tutorials/beginner/basics/transforms_tutorial.html](https://pytorch.org/tutorials/beginner/basics/transforms_tutorial.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "class NumpyToTensor():\n",
        "    def __call__(self, sample: np.ndarray) -> tuple[torch.Tensor, torch.Tensor]:\n",
        "        converted_sample = torch.tensor(sample[0], dtype=torch.float32), torch.tensor(sample[1], dtype=torch.float32)\n",
        "        return converted_sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "class NormalizeTo01():\n",
        "    def __init__(self) -> None:\n",
        "        self.min_val = None\n",
        "        self.max_val = None\n",
        "\n",
        "    def fit(self, data: np.ndarray) -> None:\n",
        "        self.min_val = np.min(data, axis=0).astype(np.float32)\n",
        "        self.max_val = np.max(data, axis=0).astype(np.float32)\n",
        "\n",
        "    def __call__(self, sample: tuple[torch.Tensor, torch.Tensor]):\n",
        "        normalized_sample = (sample[0] - self.min_val) / (self.max_val - self.min_val), sample[1]\n",
        "        return normalized_sample"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Direct transform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dataset : [(array([1, 2, 3]), array([0])), (array([5, 1, 2]), array([0])), (array([3, 3, 3]), array([1]))]\n"
          ]
        }
      ],
      "source": [
        "# dataset\n",
        "X = np.array([[1, 2, 3], [5, 1, 2], [3, 3, 3]])\n",
        "y = np.array([[0], [0], [1]])\n",
        "dataset = list(zip(X, y))\n",
        "\n",
        "# log\n",
        "print(f\"dataset : {dataset}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "result          : (tensor([0.0000, 0.5000, 1.0000]), tensor([0.]))\n",
            "result[0].dtype : torch.float32\n",
            "result[1].dtype : torch.float32\n"
          ]
        }
      ],
      "source": [
        "# NumpyToTensor\n",
        "t_totensor = NumpyToTensor()\n",
        "\n",
        "# NormalizeTo01\n",
        "t_normalize = NormalizeTo01()\n",
        "t_normalize.fit(X)\n",
        "\n",
        "# transform the first input\n",
        "result = t_normalize(t_totensor(dataset[0]))\n",
        "\n",
        "# log\n",
        "print(f\"result          : {result}\")\n",
        "print(f\"result[0].dtype : {result[0].dtype}\")\n",
        "print(f\"result[1].dtype : {result[1].dtype}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Integrated transform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "# advanced Dataset with transform support\n",
        "class AdvancedCustomDataset(Dataset):\n",
        "    def __init__(self, data, labels, transform=None):\n",
        "        self.data = data\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "        # if NormalizeTo01 is included, call <fit> method for that\n",
        "        if self.transform:\n",
        "            for t in self.transform.transforms:\n",
        "                if isinstance(t, NormalizeTo01):\n",
        "                    t.fit(self.data)\n",
        "                    break\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        sample = self.data[index], self.labels[index]\n",
        "\n",
        "        if self.transform:\n",
        "            sample = self.transform(sample)\n",
        "\n",
        "        return sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dataset[0]: (tensor([0.0000, 0.5000, 1.0000]), tensor([0.]))\n",
            "    -> input data : tensor([0.0000, 0.5000, 1.0000])\n",
            "    -> label      : tensor([0.])\n",
            "\n",
            "dataset[1]: (tensor([1., 0., 0.]), tensor([0.]))\n",
            "    -> input data : tensor([1., 0., 0.])\n",
            "    -> label      : tensor([0.])\n",
            "\n",
            "dataset[2]: (tensor([0.5000, 1.0000, 1.0000]), tensor([1.]))\n",
            "    -> input data : tensor([0.5000, 1.0000, 1.0000])\n",
            "    -> label      : tensor([1.])\n",
            "\n"
          ]
        }
      ],
      "source": [
        "X = np.array([[1, 2, 3], [5, 1, 2], [3, 3, 3]])\n",
        "y = np.array([[0], [0], [1]])\n",
        "\n",
        "transformations = transforms.Compose([\n",
        "    NumpyToTensor(),\n",
        "    NormalizeTo01(),\n",
        "])\n",
        "\n",
        "dataset = AdvancedCustomDataset(X, y, transformations)\n",
        "\n",
        "# log\n",
        "for i in range(len(y)):\n",
        "    print(f\"dataset[{i}]: {dataset[i]}\")\n",
        "    print(f\"    -> input data : {dataset[i][0]}\")\n",
        "    print(f\"    -> label      : {dataset[i][1]}\", end='\\n\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Custom Activation Function\n",
        "   - you can create your own activation function by subclassing `torch.nn.Module`.\n",
        "   - Use `torch.nn.Module` as the parent class and implement  `forward` method.\n",
        "\n",
        "\ud83d\udcdd **Docs & Tutorials** \ud83d\udcda:\n",
        "   - Non-linear Activations (weighted sum, nonlinearity): [pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity](https://pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity)\n",
        "   - Non-linear Activations (other): [pytorch.org/docs/stable/nn.html#non-linear-activations-other](https://pytorch.org/docs/stable/nn.html#non-linear-activations-other)\n",
        "   - Non-linear activation functions: [pytorch.org/docs/stable/nn.functional.html#non-linear-activation-functions](https://pytorch.org/docs/stable/nn.functional.html#non-linear-activation-functions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CustomSigmoid(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CustomSigmoid, self).__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return torch.sigmoid(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sig_1(values) : tensor([9.9995e-01, 5.0000e-01, 4.5398e-05])\n",
            "sig_2(values) : tensor([9.9995e-01, 5.0000e-01, 4.5398e-05])\n"
          ]
        }
      ],
      "source": [
        "sig_1 = CustomSigmoid()\n",
        "sig_2 = nn.Sigmoid()\n",
        "\n",
        "values = torch.tensor([10, 0, -10], dtype=torch.float32)\n",
        "\n",
        "# log\n",
        "print(f\"sig_1(values) : {sig_1(values)}\")\n",
        "print(f\"sig_2(values) : {sig_2(values)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Custom Model\n",
        "   - Sequential Model:\n",
        "      - Useful for simpler models where the layers are stacked in a linear sequence\n",
        "      - The `torch.nn.Sequential` class allows you to stack layers in a sequence, passing the output of one layer directly to the next.\n",
        "      - This is great for simple models like fully-connected neural networks or basic CNNs.\n",
        "      - Key Points\n",
        "         - Layers are defined in the order they are passed to `Sequential`.\n",
        "         - You don't need to define the `forward` method manually; PyTorch handles it for you.\n",
        "   - Functional Model:\n",
        "      - Allowing for complex architectures where you might need non-linear layer connections (e.g., skip connections in ResNet)\n",
        "      - models are created by subclassing `torch.nn.Module`.\n",
        "      - This allows you to define any neural network architecture, from simple feedforward networks to complex architectures like GANs or transformers\n",
        "      - Key Points\n",
        "         - Use `torch.nn.Module` as the parent class and implement  `forward` method.\n",
        "\n",
        "\ud83d\udcdd **Docs & Tutorials** \ud83d\udcda:\n",
        "   - Module: [pytorch.org/docs/stable/generated/torch.nn.Module.html](https://pytorch.org/docs/stable/generated/torch.nn.Module.html)\n",
        "   - torch.nn: [pytorch.org/docs/stable/nn.html](https://pytorch.org/docs/stable/nn.html)\n",
        "   - Building Models with PyTorch: [pytorch.org/tutorials/beginner/introyt/modelsyt_tutorial.html](https://pytorch.org/tutorials/beginner/introyt/modelsyt_tutorial.html)\n",
        "   - Build the Neural Network: [pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html](https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=30, out_features=16, bias=True)\n",
              "  (1): Sigmoid()\n",
              "  (2): Linear(in_features=16, out_features=1, bias=True)\n",
              "  (3): Sigmoid()\n",
              ")"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# a simple sequential model\n",
        "model_1 = nn.Sequential(\n",
        "    nn.Linear(in_features=30, out_features=16),\n",
        "    nn.Sigmoid(),\n",
        "    nn.Linear(in_features=16, out_features=1),\n",
        "    nn.Sigmoid()\n",
        ")\n",
        "\n",
        "# log\n",
        "model_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "CustomLogisticRegression(\n",
              "  (fc1): Linear(in_features=30, out_features=16, bias=True)\n",
              "  (sigmoid1): CustomSigmoid()\n",
              "  (fc2): Linear(in_features=16, out_features=1, bias=True)\n",
              "  (sigmoid2): CustomSigmoid()\n",
              ")"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# a simple functional model\n",
        "class CustomLogisticRegression(nn.Module):\n",
        "    def __init__(self, input_size: int, hidden_size: int, output_size: int) -> None:\n",
        "        super(CustomLogisticRegression, self).__init__()\n",
        "\n",
        "        self.fc1 = nn.Linear(in_features=input_size, out_features=hidden_size)\n",
        "        self.sigmoid1 = CustomSigmoid()\n",
        "        self.fc2 = nn.Linear(in_features=hidden_size, out_features=output_size)\n",
        "        self.sigmoid2 = CustomSigmoid()\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.fc1(x)\n",
        "        x = self.sigmoid1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.sigmoid2(x)\n",
        "        return x\n",
        "\n",
        "# initialize the model\n",
        "model_2 = CustomLogisticRegression(30, 16, 1)\n",
        "\n",
        "# log\n",
        "model_2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Custom Loss Function\n",
        "   - PyTorch comes with standard loss functions like MSE, Cross-Entropy, etc.\n",
        "   - you can create your own loss function by subclassing `torch.nn.Module`.\n",
        "   - Use `torch.nn.Module` as the parent class and implement  `forward` method.\n",
        "\n",
        "\ud83d\udcdd **Docs & Tutorials** \ud83d\udcda:\n",
        "   - Loss Functions: [pytorch.org/docs/stable/nn.html#loss-functions](https://pytorch.org/docs/stable/nn.html#loss-functions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CustomMSE(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CustomMSE, self).__init__()\n",
        "\n",
        "    def forward(self, y_pred, y_true):\n",
        "        loss = torch.mean((y_pred - y_true) ** 2)\n",
        "        return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss_1: 0.25902360677719116\n",
            "loss_2: 0.25902360677719116\n"
          ]
        }
      ],
      "source": [
        "# split dataset into (data, labels)\n",
        "X = dataset_1[:][0]\n",
        "y_true = dataset_1[:][1]\n",
        "\n",
        "# feed-forward\n",
        "y_pred = model_1(X)\n",
        "\n",
        "# MSE loss function\n",
        "criterion_1 = CustomMSE()   # custom\n",
        "criterion_2 = nn.MSELoss()  # built-in\n",
        "\n",
        "# compute the loss\n",
        "loss_1 = criterion_1(y_pred, y_true)\n",
        "loss_2 = criterion_2(y_pred, y_true)\n",
        "\n",
        "# log\n",
        "print(f\"loss_1: {loss_1}\")\n",
        "print(f\"loss_2: {loss_2}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Custom Optimizer\n",
        "   - PyTorch offers optimizers like SGD, Adam, etc.\n",
        "   - you can create your own optimizer by subclassing `torch.optim.Optimizer`.\n",
        "   - Use `torch.optim.Optimizer` as the parent class and override `step` method.\n",
        "\n",
        "\ud83d\udcdd **Docs & Tutorials** \ud83d\udcda:\n",
        "   - torch.optim: [pytorch.org/docs/stable/optim.html](https://pytorch.org/docs/stable/optim.html)\n",
        "   - torch.optim.Optimizer.step: [pytorch.org/docs/stable/generated/torch.optim.Optimizer.step.html](https://pytorch.org/docs/stable/generated/torch.optim.Optimizer.step.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "# this implementation might not be the same as SGD\n",
        "class CustomSGD(optim.Optimizer):\n",
        "    def __init__(self, params, lr=0.01, momentum=0):\n",
        "        defaults = dict(lr=lr, momentum=momentum)\n",
        "        super(CustomSGD, self).__init__(params, defaults)\n",
        "\n",
        "    def step(self):\n",
        "        for group in self.param_groups:\n",
        "            lr = group['lr']\n",
        "            momentum = group['momentum']\n",
        "\n",
        "            for p in group['params']:\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "                d_p = p.grad.data\n",
        "\n",
        "                if momentum != 0:\n",
        "                    param_state = self.state[p]\n",
        "                    if 'momentum_buffer' not in param_state:\n",
        "                        buf = param_state['momentum_buffer'] = torch.zeros_like(p.data)\n",
        "                        buf.mul_(momentum).add_(d_p)\n",
        "                    else:\n",
        "                        buf = param_state['momentum_buffer']\n",
        "                        buf.mul_(momentum).add_(d_p, alpha=1 - momentum)\n",
        "                    d_p = buf\n",
        "\n",
        "                p.data.add_(d_p, alpha=-lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "optimizer_1:\n",
            "CustomSGD (\n",
            "Parameter Group 0\n",
            "    lr: 0.01\n",
            "    momentum: 0\n",
            ")\n",
            "\n",
            "optimizer_2:\n",
            "SGD (\n",
            "Parameter Group 0\n",
            "    dampening: 0\n",
            "    differentiable: False\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.001\n",
            "    maximize: False\n",
            "    momentum: 0\n",
            "    nesterov: False\n",
            "    weight_decay: 0\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "optimizer_1 = CustomSGD(model_1.parameters())\n",
        "optimizer_2 = optim.SGD(model_1.parameters())\n",
        "\n",
        "# log\n",
        "print(f\"optimizer_1:\\n{optimizer_1}\\n\")\n",
        "print(f\"optimizer_2:\\n{optimizer_2}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Example: All In One"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "# load breast-cancer dataset\n",
        "X, y = load_breast_cancer(return_X_y=True)\n",
        "\n",
        "# create a custom Dataset class\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, data, labels):\n",
        "        self.data = data\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.data[index], self.labels[index]\n",
        "\n",
        "\n",
        "# convert numpy.ndarray to torch.Tensor\n",
        "X = torch.tensor(X, dtype=torch.float32)\n",
        "y = torch.tensor(y, dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "# create a dataset\n",
        "dataset = CustomDataset(X, y)\n",
        "\n",
        "# create a dataloader\n",
        "dataloader = DataLoader(dataset, batch_size=8, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "CustomLogisticRegression(\n",
              "  (fc1): Linear(in_features=30, out_features=2, bias=True)\n",
              "  (sigmoid1): CustomSigmoid()\n",
              "  (fc2): Linear(in_features=2, out_features=1, bias=True)\n",
              "  (sigmoid2): CustomSigmoid()\n",
              ")"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# custom sigmoid activation\n",
        "class CustomSigmoid(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CustomSigmoid, self).__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return torch.sigmoid(x)\n",
        "\n",
        "# model\n",
        "class CustomLogisticRegression(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(CustomLogisticRegression, self).__init__()\n",
        "\n",
        "        self.fc1 = nn.Linear(in_features=input_size, out_features=hidden_size)\n",
        "        self.sigmoid1 = CustomSigmoid()\n",
        "        self.fc2 = nn.Linear(in_features=hidden_size, out_features=output_size)\n",
        "        self.sigmoid2 = CustomSigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.sigmoid1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.sigmoid2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "input_size = X.shape[1]\n",
        "hidden_size = 2\n",
        "output_size = y.shape[1]\n",
        "\n",
        "# model\n",
        "model = CustomLogisticRegression(input_size, hidden_size, output_size)\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "# hyper parameters\n",
        "epochs = 10\n",
        "lr = 0.005\n",
        "criterion = CustomMSE()\n",
        "optimizer = CustomSGD(model.parameters(), lr=lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch  0  ->  loss: 0.34326 - accuracy: 37.26%\n",
            "epoch  1  ->  loss: 0.34738 - accuracy: 37.26%\n",
            "epoch  2  ->  loss: 0.25628 - accuracy: 37.26%\n",
            "epoch  3  ->  loss: 0.25216 - accuracy: 38.14%\n",
            "epoch  4  ->  loss: 0.24787 - accuracy: 62.74%\n",
            "epoch  5  ->  loss: 0.24429 - accuracy: 62.74%\n",
            "epoch  6  ->  loss: 0.24261 - accuracy: 62.74%\n",
            "epoch  7  ->  loss: 0.24102 - accuracy: 62.74%\n",
            "epoch  8  ->  loss: 0.23829 - accuracy: 62.74%\n",
            "epoch  9  ->  loss: 0.23698 - accuracy: 62.74%\n"
          ]
        }
      ],
      "source": [
        "# training loop\n",
        "model.train()\n",
        "total_loss = []\n",
        "total_acc = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    for x, y_true in dataloader:\n",
        "\n",
        "        # forward\n",
        "        y_pred = model(x)\n",
        "        loss = criterion(y_pred, y_true)\n",
        "\n",
        "        # backward\n",
        "        loss.backward()\n",
        "\n",
        "        # update parameters\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # store loss & accuracy\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += ((y_pred > .5).float() == y_true).sum().item()\n",
        "\n",
        "    total_loss.append(epoch_loss / len(dataloader))\n",
        "    total_acc.append(epoch_acc / len(X))\n",
        "\n",
        "    # log\n",
        "    print(f\"epoch {epoch:>2}  ->  loss: {total_loss[-1]:.5f} - accuracy: {total_acc[-1] * 100:.2f}%\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "author_name": "Amirhossein Heydari",
    "author_email": "AmirhosseinHeydari78@gmail.com",
    "author_github": "https://github.com/mr-pylin",
    "origin_repo": "https://github.com/mr-pylin/pytorch-workshop"
  },
  "nbformat": 4,
  "nbformat_minor": 2
}