{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìù **Author:** Amirhossein Heydari - üìß **Email:** amirhosseinheydari78@gmail.com - üìç **Linktree:** [linktr.ee/mr_pylin](https://linktr.ee/mr_pylin)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependensies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LeNet-5\n",
    "   - One of the pioneering convolutional neural network architectures developed in 1998 by [Yann LeCun](https://en.wikipedia.org/wiki/Yann_LeCun) and his colleagues\n",
    "   - It is based on the [Gradient-based learning applied to document recognition](https://ieeexplore.ieee.org/document/726791) paper\n",
    "   - It was trained on the [MNIST](http://yann.lecun.com/exdb/mnist/) dataset (28x28 images were padded to 32x32) [[MNIST viewer](https://observablehq.com/@davidalber/mnist-browser)]\n",
    "\n",
    "<figure style=\"text-align: center;\">\n",
    "    <img src=\"../../../assets/images/original/cnn/architectures/lenet5.svg\" alt=\"lenet5-architecture.svg\" style=\"width: 100%;\">\n",
    "    <figcaption>LeNet-5 Architecture</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom LeNet-5\n",
    "   - `Softmax` is missing due to internal implementation of `LogSoftmax` in the `CrossEntropyLoss` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLeNet5(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(CustomLeNet5, self).__init__()\n",
    "\n",
    "        # input : 1x32x32\n",
    "        # output: 120x1x1\n",
    "        # total trainable params: 156 + 0 + 2,416 + 0 + 48,120 = 50692\n",
    "        self.features = nn.Sequential(\n",
    "\n",
    "            # input : 1x32x32\n",
    "            # output: 6x28x28\n",
    "            # trainable params: (5 * 5 + 1) * 6 = 156\n",
    "            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5),\n",
    "\n",
    "            # input : 6x28x28\n",
    "            # output: 6x28x28\n",
    "            # trainable params: 0\n",
    "            nn.Sigmoid(),\n",
    "\n",
    "            # input : 6x28x28\n",
    "            # output: 6x14x14\n",
    "            # trainable params: 0\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # input : 6x14x14\n",
    "            # output: 16x10x10\n",
    "            # trainable params: (6 * 5 * 5 + 1) * 16 = 2,416\n",
    "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5),\n",
    "\n",
    "            # input : 16x10x10\n",
    "            # output: 16x10x10\n",
    "            # trainable params: 0\n",
    "            nn.Sigmoid(),\n",
    "\n",
    "            # input           : 16x10x10\n",
    "            # output          : 16x5x5\n",
    "            # trainable params: 0\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # input           : 16x5x5\n",
    "            # output          : 120x1x1\n",
    "            # trainable params: (16 * 5 * 5 + 1) * 120 = 48,120\n",
    "            nn.Conv2d(in_channels=16, out_channels=120, kernel_size=5),\n",
    "\n",
    "            # input : 120x1x1\n",
    "            # output: 120x1x1\n",
    "            # trainable params: 0\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        # flatten : 120x1x1 -> 120\n",
    "        # input           : 120\n",
    "        # output          : 10\n",
    "        self.classifier = nn.Sequential(\n",
    "\n",
    "        # input           : 120\n",
    "        # output          :  84\n",
    "        # trainable params: (120 + 1) * 84 = 10,164\n",
    "        nn.Linear(in_features=120, out_features=84),\n",
    "\n",
    "        # input : 84\n",
    "        # output: 84\n",
    "        # trainable params: 0\n",
    "        nn.Sigmoid(),\n",
    "\n",
    "        # input           : 84\n",
    "        # output          : 10\n",
    "        # trainable params: (84 + 1) * 10 = 850\n",
    "        nn.Linear(in_features=84, out_features=10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "\n",
    "        # feature extractor\n",
    "        x = self.features(x)\n",
    "\n",
    "        # flatten : 120x1x1 -> 120\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "\n",
    "        # classifier\n",
    "        x = self.classifier(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomLeNet5(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (1): Sigmoid()\n",
       "    (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (4): Sigmoid()\n",
       "    (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    (6): Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (7): Sigmoid()\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=120, out_features=84, bias=True)\n",
       "    (1): Sigmoid()\n",
       "    (2): Linear(in_features=84, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CustomLeNet5()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "CustomLeNet5                             [1, 10]                   --\n",
       "‚îú‚îÄSequential: 1-1                        [1, 120, 1, 1]            --\n",
       "‚îÇ    ‚îî‚îÄConv2d: 2-1                       [1, 6, 28, 28]            156\n",
       "‚îÇ    ‚îî‚îÄSigmoid: 2-2                      [1, 6, 28, 28]            --\n",
       "‚îÇ    ‚îî‚îÄAvgPool2d: 2-3                    [1, 6, 14, 14]            --\n",
       "‚îÇ    ‚îî‚îÄConv2d: 2-4                       [1, 16, 10, 10]           2,416\n",
       "‚îÇ    ‚îî‚îÄSigmoid: 2-5                      [1, 16, 10, 10]           --\n",
       "‚îÇ    ‚îî‚îÄAvgPool2d: 2-6                    [1, 16, 5, 5]             --\n",
       "‚îÇ    ‚îî‚îÄConv2d: 2-7                       [1, 120, 1, 1]            48,120\n",
       "‚îÇ    ‚îî‚îÄSigmoid: 2-8                      [1, 120, 1, 1]            --\n",
       "‚îú‚îÄSequential: 1-2                        [1, 10]                   --\n",
       "‚îÇ    ‚îî‚îÄLinear: 2-9                       [1, 84]                   10,164\n",
       "‚îÇ    ‚îî‚îÄSigmoid: 2-10                     [1, 84]                   --\n",
       "‚îÇ    ‚îî‚îÄLinear: 2-11                      [1, 10]                   850\n",
       "==========================================================================================\n",
       "Total params: 61,706\n",
       "Trainable params: 61,706\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 0.42\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.05\n",
       "Params size (MB): 0.25\n",
       "Estimated Total Size (MB): 0.30\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model, (1, 1, 32, 32), device='cpu')"
   ]
  }
 ],
 "metadata": {
  "author_email": "AmirhosseinHeydari78@gmail.com",
  "author_github": "https://github.com/mr-pylin",
  "author_name": "Amirhossein Heydari",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "origin_repo": "https://github.com/mr-pylin/pytorch-workshop"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
