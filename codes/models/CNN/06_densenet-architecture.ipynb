{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ud83d\udcdd **Author:** Amirhossein Heydari - \ud83d\udce7 **Email:** amirhosseinheydari78@gmail.com - \ud83d\udccd **Linktree:** [linktr.ee/mr_pylin](https://linktr.ee/mr_pylin)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Dependencies\n",
        "   - torchvision models:\n",
        "      - class\n",
        "         - brings in the model class directly\n",
        "         - Allows more control and customization since you are dealing directly with the class. You can override methods, customize initialization, etc.\n",
        "      - function\n",
        "         - This import brings in a function that returns an instance of the model\n",
        "         - Easier and quicker to use, especially for standard models\n",
        "   - [pytorch.org/vision/stable/models.html](https://pytorch.org/vision/stable/models.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.functional import F\n",
        "from torchinfo import summary\n",
        "from torchvision.models import DenseNet, densenet121, densenet161, densenet169, densenet201"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DenseNet\n",
        "   - Densely Connected Convolutional Network (DenseNet), developed in 2017 by [Gao Huang](https://scholar.google.com.hk/citations?user=-P9LwcgAAAAJ&hl) and collaborators from [Cornell University](https://www.cornell.edu/) and [Tsinghua University](https://www.tsinghua.edu.cn/en/)\n",
        "   - It is based on the [Densely Connected Convolutional Networks](https://openaccess.thecvf.com/content_cvpr_2017/papers/Huang_Densely_Connected_Convolutional_CVPR_2017_paper.pdf) paper\n",
        "   - It was trained on the [ImageNet](https://www.image-net.org/) dataset (first resized to 256x256 then center cropped to 224x224) [[ImageNet viewer](https://navigu.net/#imagenet)]\n",
        "   - Known for its innovative use of `dense connections` where each layer receives the feature maps of all preceding layers, enhancing gradient flow and feature reuse\n",
        "   - It comes in several variants, primarily `DenseNet-121`, `DenseNet-161`, `DenseNet-169` and `DenseNet-201`, indicating the depth and complexity of the network\n",
        "   - Achieved high performance in various benchmarks and demonstrated significant parameter efficiency and feature reuse due to its dense connectivity\n",
        "\n",
        "<figure style=\"text-align: center;\">\n",
        "    <img src=\"../../../assets/images/svgs/densenet-architecture.svg\" alt=\"densenet-architecture.svg\" style=\"width: 100%;\">\n",
        "    <figcaption>DenseNet Architecture</figcaption>\n",
        "</figure>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Custom DenseNet\n",
        "   - `Softmax` is missing due to internal implementation of `LogSoftmax` in the `CrossEntropyLoss` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "class DenseLayer(nn.Module):\n",
        "    def __init__(self, in_channels, growth_rate) -> None:\n",
        "        super(DenseLayer, self).__init__()\n",
        "        self.bn1 = nn.BatchNorm2d(in_channels)\n",
        "        self.conv1 = nn.Conv2d(in_channels, 4 * growth_rate, kernel_size=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(4 * growth_rate)\n",
        "        self.conv2 = nn.Conv2d(4 * growth_rate, growth_rate, kernel_size=3, padding=1, bias=False)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        out = self.conv1(F.relu(self.bn1(x)))\n",
        "        out = self.conv2(F.relu(self.bn2(out)))\n",
        "        out = torch.cat([x, out], 1)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "class DenseBlock(nn.Module):\n",
        "    def __init__(self, num_layers, in_channels, growth_rate) -> None:\n",
        "        super(DenseBlock, self).__init__()\n",
        "        layers = []\n",
        "        for i in range(num_layers):\n",
        "            layers.append(DenseLayer(in_channels + i * growth_rate, growth_rate))\n",
        "        self.block = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        return self.block(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TransitionLayer(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels) -> None:\n",
        "        super(TransitionLayer, self).__init__()\n",
        "        self.bn = nn.BatchNorm2d(in_channels)\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n",
        "        self.pool = nn.AvgPool2d(2, stride=2)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        out = self.conv(F.relu(self.bn(x)))\n",
        "        out = self.pool(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CustomDenseNet(nn.Module):\n",
        "    def __init__(self, num_layers_per_block, growth_rate, num_classes=1000) -> None:\n",
        "        super(CustomDenseNet, self).__init__()\n",
        "        self.growth_rate = growth_rate\n",
        "        num_channels = 2 * growth_rate\n",
        "\n",
        "        # densenet-121, densenet-169, densenet-201 : 3x224x224 -> 64x112x112\n",
        "        # densenet-161                             : 3x224x224 -> 96x112x112\n",
        "        self.conv1 = nn.Conv2d(3, num_channels, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(num_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        # densenet-121, densenet-169, densenet-201 : 64x112x112 -> 64x56x56\n",
        "        # densenet-161                             : 96x112x112 -> 96x56x56\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        # densenet-121 : 64x56x56 -> 1024x7x7\n",
        "        # densenet-161 : 96x56x56 -> 2208x7x7\n",
        "        # densenet-169 : 64x56x56 -> 1664x7x7\n",
        "        # densenet-201 : 64x56x56 -> 1920x7x7\n",
        "        blocks = []\n",
        "        for i in range(len(num_layers_per_block)):\n",
        "            blocks.append(DenseBlock(num_layers_per_block[i], num_channels, growth_rate))\n",
        "            num_channels += num_layers_per_block[i] * growth_rate\n",
        "            if i != len(num_layers_per_block) - 1:\n",
        "                blocks.append(TransitionLayer(num_channels, num_channels // 2))\n",
        "                num_channels = num_channels // 2\n",
        "\n",
        "        self.blocks = nn.Sequential(*blocks)\n",
        "        self.bn2 = nn.BatchNorm2d(num_channels)\n",
        "\n",
        "        # densenet-121 : 1024x7x7 -> 1024x1x1\n",
        "        # densenet-161 : 2208x7x7 -> 2208x1x1\n",
        "        # densenet-169 : 1664x7x7 -> 1664x1x1\n",
        "        # densenet-201 : 1920x7x7 -> 1920x1x1\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "\n",
        "        # densenet-121 : 1024 -> 1000\n",
        "        # densenet-161 : 2208 -> 1000\n",
        "        # densenet-169 : 1664 -> 1000\n",
        "        # densenet-201 : 1920 -> 1000\n",
        "        self.fc = nn.Linear(num_channels, num_classes)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        # feature extractor\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.pool1(out)\n",
        "        out = self.blocks(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        # adaptive average pooling\n",
        "        out = self.avgpool(out)\n",
        "\n",
        "        # flatten:\n",
        "        # densenet-121 : 1024x1x1 -> 1024\n",
        "        # densenet-161 : 1536x1x1 -> 1536\n",
        "        # densenet-169 : 1664x1x1 -> 1664\n",
        "        # densenet-201 : 1920x1x1 -> 1920\n",
        "        out = torch.flatten(out, 1)\n",
        "\n",
        "        # classifier\n",
        "        out = self.fc(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### DenseNet-121"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "densenet_121_1 = CustomDenseNet(num_layers_per_block=[6, 12, 24, 16], growth_rate=32)\n",
        "densenet_121_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "===============================================================================================\n",
              "Layer (type:depth-idx)                        Output Shape              Param #\n",
              "===============================================================================================\n",
              "CustomDenseNet                                [1, 1000]                 --\n",
              "\u251c\u2500Conv2d: 1-1                                 [1, 64, 112, 112]         9,408\n",
              "\u251c\u2500BatchNorm2d: 1-2                            [1, 64, 112, 112]         128\n",
              "\u251c\u2500ReLU: 1-3                                   [1, 64, 112, 112]         --\n",
              "\u251c\u2500MaxPool2d: 1-4                              [1, 64, 56, 56]           --\n",
              "\u251c\u2500Sequential: 1-5                             [1, 1024, 7, 7]           --\n",
              "\u2502    \u2514\u2500DenseBlock: 2-1                        [1, 256, 56, 56]          --\n",
              "\u2502    \u2502    \u2514\u2500Sequential: 3-1                   [1, 256, 56, 56]          335,040\n",
              "\u2502    \u2514\u2500TransitionLayer: 2-2                   [1, 128, 28, 28]          --\n",
              "\u2502    \u2502    \u2514\u2500BatchNorm2d: 3-2                  [1, 256, 56, 56]          512\n",
              "\u2502    \u2502    \u2514\u2500Conv2d: 3-3                       [1, 128, 56, 56]          32,768\n",
              "\u2502    \u2502    \u2514\u2500AvgPool2d: 3-4                    [1, 128, 28, 28]          --\n",
              "\u2502    \u2514\u2500DenseBlock: 2-3                        [1, 512, 28, 28]          --\n",
              "\u2502    \u2502    \u2514\u2500Sequential: 3-5                   [1, 512, 28, 28]          919,680\n",
              "\u2502    \u2514\u2500TransitionLayer: 2-4                   [1, 256, 14, 14]          --\n",
              "\u2502    \u2502    \u2514\u2500BatchNorm2d: 3-6                  [1, 512, 28, 28]          1,024\n",
              "\u2502    \u2502    \u2514\u2500Conv2d: 3-7                       [1, 256, 28, 28]          131,072\n",
              "\u2502    \u2502    \u2514\u2500AvgPool2d: 3-8                    [1, 256, 14, 14]          --\n",
              "\u2502    \u2514\u2500DenseBlock: 2-5                        [1, 1024, 14, 14]         --\n",
              "\u2502    \u2502    \u2514\u2500Sequential: 3-9                   [1, 1024, 14, 14]         2,837,760\n",
              "\u2502    \u2514\u2500TransitionLayer: 2-6                   [1, 512, 7, 7]            --\n",
              "\u2502    \u2502    \u2514\u2500BatchNorm2d: 3-10                 [1, 1024, 14, 14]         2,048\n",
              "\u2502    \u2502    \u2514\u2500Conv2d: 3-11                      [1, 512, 14, 14]          524,288\n",
              "\u2502    \u2502    \u2514\u2500AvgPool2d: 3-12                   [1, 512, 7, 7]            --\n",
              "\u2502    \u2514\u2500DenseBlock: 2-7                        [1, 1024, 7, 7]           --\n",
              "\u2502    \u2502    \u2514\u2500Sequential: 3-13                  [1, 1024, 7, 7]           2,158,080\n",
              "\u251c\u2500BatchNorm2d: 1-6                            [1, 1024, 7, 7]           2,048\n",
              "\u251c\u2500ReLU: 1-7                                   [1, 1024, 7, 7]           --\n",
              "\u251c\u2500AdaptiveAvgPool2d: 1-8                      [1, 1024, 1, 1]           --\n",
              "\u251c\u2500Linear: 1-9                                 [1, 1000]                 1,025,000\n",
              "===============================================================================================\n",
              "Total params: 7,978,856\n",
              "Trainable params: 7,978,856\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (Units.GIGABYTES): 2.83\n",
              "===============================================================================================\n",
              "Input size (MB): 0.60\n",
              "Forward/backward pass size (MB): 180.54\n",
              "Params size (MB): 31.92\n",
              "Estimated Total Size (MB): 213.06\n",
              "==============================================================================================="
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "summary(densenet_121_1, (1, 3, 224, 224), device='cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### DenseNet-161"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "densenet_161_1 = CustomDenseNet(num_layers_per_block=[6, 12, 36, 24], growth_rate=48)\n",
        "densenet_161_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "===============================================================================================\n",
              "Layer (type:depth-idx)                        Output Shape              Param #\n",
              "===============================================================================================\n",
              "CustomDenseNet                                [1, 1000]                 --\n",
              "\u251c\u2500Conv2d: 1-1                                 [1, 96, 112, 112]         14,112\n",
              "\u251c\u2500BatchNorm2d: 1-2                            [1, 96, 112, 112]         192\n",
              "\u251c\u2500ReLU: 1-3                                   [1, 96, 112, 112]         --\n",
              "\u251c\u2500MaxPool2d: 1-4                              [1, 96, 56, 56]           --\n",
              "\u251c\u2500Sequential: 1-5                             [1, 2208, 7, 7]           --\n",
              "\u2502    \u2514\u2500DenseBlock: 2-1                        [1, 384, 56, 56]          --\n",
              "\u2502    \u2502    \u2514\u2500Sequential: 3-1                   [1, 384, 56, 56]          751,392\n",
              "\u2502    \u2514\u2500TransitionLayer: 2-2                   [1, 192, 28, 28]          --\n",
              "\u2502    \u2502    \u2514\u2500BatchNorm2d: 3-2                  [1, 384, 56, 56]          768\n",
              "\u2502    \u2502    \u2514\u2500Conv2d: 3-3                       [1, 192, 56, 56]          73,728\n",
              "\u2502    \u2502    \u2514\u2500AvgPool2d: 3-4                    [1, 192, 28, 28]          --\n",
              "\u2502    \u2514\u2500DenseBlock: 2-3                        [1, 768, 28, 28]          --\n",
              "\u2502    \u2502    \u2514\u2500Sequential: 3-5                   [1, 768, 28, 28]          2,061,504\n",
              "\u2502    \u2514\u2500TransitionLayer: 2-4                   [1, 384, 14, 14]          --\n",
              "\u2502    \u2502    \u2514\u2500BatchNorm2d: 3-6                  [1, 768, 28, 28]          1,536\n",
              "\u2502    \u2502    \u2514\u2500Conv2d: 3-7                       [1, 384, 28, 28]          294,912\n",
              "\u2502    \u2502    \u2514\u2500AvgPool2d: 3-8                    [1, 384, 14, 14]          --\n",
              "\u2502    \u2514\u2500DenseBlock: 2-5                        [1, 2112, 14, 14]         --\n",
              "\u2502    \u2502    \u2514\u2500Sequential: 3-9                   [1, 2112, 14, 14]         11,548,224\n",
              "\u2502    \u2514\u2500TransitionLayer: 2-6                   [1, 1056, 7, 7]           --\n",
              "\u2502    \u2502    \u2514\u2500BatchNorm2d: 3-10                 [1, 2112, 14, 14]         4,224\n",
              "\u2502    \u2502    \u2514\u2500Conv2d: 3-11                      [1, 1056, 14, 14]         2,230,272\n",
              "\u2502    \u2502    \u2514\u2500AvgPool2d: 3-12                   [1, 1056, 7, 7]           --\n",
              "\u2502    \u2514\u2500DenseBlock: 2-7                        [1, 2208, 7, 7]           --\n",
              "\u2502    \u2502    \u2514\u2500Sequential: 3-13                  [1, 2208, 7, 7]           9,486,720\n",
              "\u251c\u2500BatchNorm2d: 1-6                            [1, 2208, 7, 7]           4,416\n",
              "\u251c\u2500ReLU: 1-7                                   [1, 2208, 7, 7]           --\n",
              "\u251c\u2500AdaptiveAvgPool2d: 1-8                      [1, 2208, 1, 1]           --\n",
              "\u251c\u2500Linear: 1-9                                 [1, 1000]                 2,209,000\n",
              "===============================================================================================\n",
              "Total params: 28,681,000\n",
              "Trainable params: 28,681,000\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (Units.GIGABYTES): 7.73\n",
              "===============================================================================================\n",
              "Input size (MB): 0.60\n",
              "Forward/backward pass size (MB): 323.83\n",
              "Params size (MB): 114.72\n",
              "Estimated Total Size (MB): 439.16\n",
              "==============================================================================================="
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "summary(densenet_161_1, (1, 3, 224, 224), device='cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### DenseNet-169"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "densenet_169_1 = CustomDenseNet(num_layers_per_block=[6, 12, 32, 32], growth_rate=32)\n",
        "densenet_169_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "===============================================================================================\n",
              "Layer (type:depth-idx)                        Output Shape              Param #\n",
              "===============================================================================================\n",
              "CustomDenseNet                                [1, 1000]                 --\n",
              "\u251c\u2500Conv2d: 1-1                                 [1, 64, 112, 112]         9,408\n",
              "\u251c\u2500BatchNorm2d: 1-2                            [1, 64, 112, 112]         128\n",
              "\u251c\u2500ReLU: 1-3                                   [1, 64, 112, 112]         --\n",
              "\u251c\u2500MaxPool2d: 1-4                              [1, 64, 56, 56]           --\n",
              "\u251c\u2500Sequential: 1-5                             [1, 1664, 7, 7]           --\n",
              "\u2502    \u2514\u2500DenseBlock: 2-1                        [1, 256, 56, 56]          --\n",
              "\u2502    \u2502    \u2514\u2500Sequential: 3-1                   [1, 256, 56, 56]          335,040\n",
              "\u2502    \u2514\u2500TransitionLayer: 2-2                   [1, 128, 28, 28]          --\n",
              "\u2502    \u2502    \u2514\u2500BatchNorm2d: 3-2                  [1, 256, 56, 56]          512\n",
              "\u2502    \u2502    \u2514\u2500Conv2d: 3-3                       [1, 128, 56, 56]          32,768\n",
              "\u2502    \u2502    \u2514\u2500AvgPool2d: 3-4                    [1, 128, 28, 28]          --\n",
              "\u2502    \u2514\u2500DenseBlock: 2-3                        [1, 512, 28, 28]          --\n",
              "\u2502    \u2502    \u2514\u2500Sequential: 3-5                   [1, 512, 28, 28]          919,680\n",
              "\u2502    \u2514\u2500TransitionLayer: 2-4                   [1, 256, 14, 14]          --\n",
              "\u2502    \u2502    \u2514\u2500BatchNorm2d: 3-6                  [1, 512, 28, 28]          1,024\n",
              "\u2502    \u2502    \u2514\u2500Conv2d: 3-7                       [1, 256, 28, 28]          131,072\n",
              "\u2502    \u2502    \u2514\u2500AvgPool2d: 3-8                    [1, 256, 14, 14]          --\n",
              "\u2502    \u2514\u2500DenseBlock: 2-5                        [1, 1280, 14, 14]         --\n",
              "\u2502    \u2502    \u2514\u2500Sequential: 3-9                   [1, 1280, 14, 14]         4,316,160\n",
              "\u2502    \u2514\u2500TransitionLayer: 2-6                   [1, 640, 7, 7]            --\n",
              "\u2502    \u2502    \u2514\u2500BatchNorm2d: 3-10                 [1, 1280, 14, 14]         2,560\n",
              "\u2502    \u2502    \u2514\u2500Conv2d: 3-11                      [1, 640, 14, 14]          819,200\n",
              "\u2502    \u2502    \u2514\u2500AvgPool2d: 3-12                   [1, 640, 7, 7]            --\n",
              "\u2502    \u2514\u2500DenseBlock: 2-7                        [1, 1664, 7, 7]           --\n",
              "\u2502    \u2502    \u2514\u2500Sequential: 3-13                  [1, 1664, 7, 7]           5,913,600\n",
              "\u251c\u2500BatchNorm2d: 1-6                            [1, 1664, 7, 7]           3,328\n",
              "\u251c\u2500ReLU: 1-7                                   [1, 1664, 7, 7]           --\n",
              "\u251c\u2500AdaptiveAvgPool2d: 1-8                      [1, 1664, 1, 1]           --\n",
              "\u251c\u2500Linear: 1-9                                 [1, 1000]                 1,665,000\n",
              "===============================================================================================\n",
              "Total params: 14,149,480\n",
              "Trainable params: 14,149,480\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (Units.GIGABYTES): 3.36\n",
              "===============================================================================================\n",
              "Input size (MB): 0.60\n",
              "Forward/backward pass size (MB): 210.60\n",
              "Params size (MB): 56.60\n",
              "Estimated Total Size (MB): 267.80\n",
              "==============================================================================================="
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "summary(densenet_169_1, (1, 3, 224, 224), device='cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### DenseNet-201"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "densenet_201_1 = CustomDenseNet(num_layers_per_block=[6, 12, 48, 32], growth_rate=32)\n",
        "densenet_201_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "===============================================================================================\n",
              "Layer (type:depth-idx)                        Output Shape              Param #\n",
              "===============================================================================================\n",
              "CustomDenseNet                                [1, 1000]                 --\n",
              "\u251c\u2500Conv2d: 1-1                                 [1, 64, 112, 112]         9,408\n",
              "\u251c\u2500BatchNorm2d: 1-2                            [1, 64, 112, 112]         128\n",
              "\u251c\u2500ReLU: 1-3                                   [1, 64, 112, 112]         --\n",
              "\u251c\u2500MaxPool2d: 1-4                              [1, 64, 56, 56]           --\n",
              "\u251c\u2500Sequential: 1-5                             [1, 1920, 7, 7]           --\n",
              "\u2502    \u2514\u2500DenseBlock: 2-1                        [1, 256, 56, 56]          --\n",
              "\u2502    \u2502    \u2514\u2500Sequential: 3-1                   [1, 256, 56, 56]          335,040\n",
              "\u2502    \u2514\u2500TransitionLayer: 2-2                   [1, 128, 28, 28]          --\n",
              "\u2502    \u2502    \u2514\u2500BatchNorm2d: 3-2                  [1, 256, 56, 56]          512\n",
              "\u2502    \u2502    \u2514\u2500Conv2d: 3-3                       [1, 128, 56, 56]          32,768\n",
              "\u2502    \u2502    \u2514\u2500AvgPool2d: 3-4                    [1, 128, 28, 28]          --\n",
              "\u2502    \u2514\u2500DenseBlock: 2-3                        [1, 512, 28, 28]          --\n",
              "\u2502    \u2502    \u2514\u2500Sequential: 3-5                   [1, 512, 28, 28]          919,680\n",
              "\u2502    \u2514\u2500TransitionLayer: 2-4                   [1, 256, 14, 14]          --\n",
              "\u2502    \u2502    \u2514\u2500BatchNorm2d: 3-6                  [1, 512, 28, 28]          1,024\n",
              "\u2502    \u2502    \u2514\u2500Conv2d: 3-7                       [1, 256, 28, 28]          131,072\n",
              "\u2502    \u2502    \u2514\u2500AvgPool2d: 3-8                    [1, 256, 14, 14]          --\n",
              "\u2502    \u2514\u2500DenseBlock: 2-5                        [1, 1792, 14, 14]         --\n",
              "\u2502    \u2502    \u2514\u2500Sequential: 3-9                   [1, 1792, 14, 14]         8,071,680\n",
              "\u2502    \u2514\u2500TransitionLayer: 2-6                   [1, 896, 7, 7]            --\n",
              "\u2502    \u2502    \u2514\u2500BatchNorm2d: 3-10                 [1, 1792, 14, 14]         3,584\n",
              "\u2502    \u2502    \u2514\u2500Conv2d: 3-11                      [1, 896, 14, 14]          1,605,632\n",
              "\u2502    \u2502    \u2514\u2500AvgPool2d: 3-12                   [1, 896, 7, 7]            --\n",
              "\u2502    \u2514\u2500DenseBlock: 2-7                        [1, 1920, 7, 7]           --\n",
              "\u2502    \u2502    \u2514\u2500Sequential: 3-13                  [1, 1920, 7, 7]           6,978,560\n",
              "\u251c\u2500BatchNorm2d: 1-6                            [1, 1920, 7, 7]           3,840\n",
              "\u251c\u2500ReLU: 1-7                                   [1, 1920, 7, 7]           --\n",
              "\u251c\u2500AdaptiveAvgPool2d: 1-8                      [1, 1920, 1, 1]           --\n",
              "\u251c\u2500Linear: 1-9                                 [1, 1000]                 1,921,000\n",
              "===============================================================================================\n",
              "Total params: 20,013,928\n",
              "Trainable params: 20,013,928\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (Units.GIGABYTES): 4.29\n",
              "===============================================================================================\n",
              "Input size (MB): 0.60\n",
              "Forward/backward pass size (MB): 260.47\n",
              "Params size (MB): 80.06\n",
              "Estimated Total Size (MB): 341.13\n",
              "==============================================================================================="
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "summary(densenet_201_1, (1, 3, 224, 224), device='cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## PyTorch DenseNet\n",
        "   - DenseNet is available in PyTorch: [pytorch.org/vision/main/models/densenet.html](https://pytorch.org/vision/main/models/densenet.html)\n",
        "   <!-- - There is a bug with executing `torchsummary` for DenseNet [[details](https://github.com/sksq96/pytorch-summary/issues/2)] (`torch v2.3.1+cu121`, `torchsummary v1.5.1`)\n",
        "      ```python\n",
        "      summary(densenet_121_2, (1, 3, 224, 224), device= 'cpu')\n",
        "      AttributeError: 'list' object has no attribute 'size'\n",
        "      ``` -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### DenseNet-121"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "densenet_121_2 = densenet121()\n",
        "densenet_121_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "summary(densenet_121_2, (1, 3, 224, 224), device='cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### DenseNet-161"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "densenet_161_2 = densenet161()\n",
        "densenet_161_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "summary(densenet_161_2, (1, 3, 224, 224), device='cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### DenseNet-169"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "densenet_169_2 = densenet169()\n",
        "densenet_169_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "summary(densenet_169_2, (1, 3, 224, 224), device='cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### DenseNet-201"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "densenet_201_2 = densenet201()\n",
        "densenet_201_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "summary(densenet_201_2, (1, 3, 224, 224), device='cpu')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "author_name": "Amirhossein Heydari",
    "author_email": "AmirhosseinHeydari78@gmail.com",
    "author_github": "https://github.com/mr-pylin",
    "origin_repo": "https://github.com/mr-pylin/pytorch-workshop"
  },
  "nbformat": 4,
  "nbformat_minor": 2
}