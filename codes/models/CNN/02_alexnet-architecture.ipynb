{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìù **Author:** Amirhossein Heydari - üìß **Email:** amirhosseinheydari78@gmail.com - üìç **Linktree:** [linktr.ee/mr_pylin](https://linktr.ee/mr_pylin)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies\n",
    "   - torchvision models:\n",
    "      - class\n",
    "         - brings in the model class directly\n",
    "         - Allows more control and customization since you are dealing directly with the class. You can override methods, customize initialization, etc.\n",
    "      - function\n",
    "         - This import brings in a function that returns an instance of the model\n",
    "         - Easier and quicker to use, especially for standard models\n",
    "   - [pytorch.org/vision/stable/models.html](https://pytorch.org/vision/stable/models.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchinfo import summary\n",
    "from torchvision.models import AlexNet, alexnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AlexNet\n",
    "   - One of the pioneering convolutional neural network architectures developed in 2012 by [Alex Krizhevsky](https://en.wikipedia.org/wiki/Alex_Krizhevsky), [Ilya Sutskever](https://en.wikipedia.org/wiki/Ilya_Sutskever), and [Geoffrey Hinton](https://en.wikipedia.org/wiki/Geoffrey_Hinton)\n",
    "   - It is based on the [ImageNet Classification with Deep Convolutional Neural Networks](https://papers.nips.cc/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html) paper\n",
    "   - It was trained on the [ImageNet](https://www.image-net.org/) dataset (first resized to 256x256 then center cropped to 227x227) [[ImageNet viewer](https://navigu.net/#imagenet)]\n",
    "   - The winner of the ImageNet Large Scale Visual Recognition Challenge ([ILSVRC](https://image-net.org/challenges/LSVRC/2012/)) in 2012\n",
    "\n",
    "<figure style=\"text-align: center;\">\n",
    "    <img src=\"../../../assets/images/original/cnn/architectures/alexnet.svg\" alt=\"alexnet-architecture.svg\" style=\"width: 100%;\">\n",
    "    <figcaption>AlexNet Architecture</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom AlexNet\n",
    "   - `Softmax` is missing due to internal implementation of `LogSoftmax` in the `CrossEntropyLoss` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomAlexNet(nn.Module):\n",
    "    def __init__(self, num_classes: int = 1000, dropout: float = 0.5) -> None:\n",
    "        super(CustomAlexNet, self).__init__()\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "\n",
    "            # 3x227x227 -> 64x55x55\n",
    "            # trainable params: (3 * 11 * 11 + 1) * 64 = 23,296\n",
    "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
    "\n",
    "            # 64x55x55 -> 64x55x55\n",
    "            # trainable params: 0\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            # 64x55x55 -> 64x27x27\n",
    "            # trainable params: 0\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "\n",
    "            # 64x27x27 -> 192x27x27\n",
    "            # trainable params: (64 * 5 * 5 + 1) * 192 = 307,392\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "\n",
    "            # 192x27x27 -> 192x27x27\n",
    "            # trainable params: 0\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            # 192x27x27 -> 192x13x13\n",
    "            # trainable params: 0\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "\n",
    "            # 192x13x13 -> 384x13x13\n",
    "            # trainable params: (192 * 3 * 3 + 1) * 384 = 663,936\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "\n",
    "            # 384x13x13 -> 384x13x13\n",
    "            # trainable params: 0\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            # 384x13x13 -> 256x13x13\n",
    "            # trainable params: (384 * 3 * 3 + 1) * 256 = 884,992\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "\n",
    "            # 256x13x13 -> 256x13x13\n",
    "            # trainable params: 0\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            # 256x13x13 -> 256x13x13\n",
    "            # trainable params: (256 * 3 * 3 + 1) * 256 = 590,080\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "\n",
    "            # 256x13x13 -> 256x13x13\n",
    "            # trainable params: 0\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            # 256x13x13 -> 256x6x6\n",
    "            # trainable params: 0\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "\n",
    "        # 256x6x6 -> 256x6x6\n",
    "        # trainable params: 0\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(output_size=(6, 6))\n",
    "\n",
    "        # flatten : 256x6x6 -> 9216\n",
    "        # 9216 -> 1000\n",
    "        self.classifier = nn.Sequential(\n",
    "\n",
    "            # 9216 -> 9216\n",
    "            # trainable params: 0\n",
    "            nn.Dropout(p=dropout),\n",
    "\n",
    "            # 9216 -> 4096\n",
    "            # trainable params: (9216 + 1) * 4096 = 37,752,832\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "\n",
    "            # 4096 -> 4096\n",
    "            # trainable params: 0\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            # 4096 -> 4096\n",
    "            # trainable params: 0\n",
    "            nn.Dropout(p=dropout),\n",
    "\n",
    "            # 4096 -> 4096\n",
    "            # trainable params: (4096 + 1) * 4096 = 16,781,312\n",
    "            nn.Linear(4096, 4096),\n",
    "\n",
    "            # 4096 -> 4096\n",
    "            # trainable params: 0\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            # 4096 -> 1000\n",
    "            # trainable params: (4096 + 1) * 1000 = 4,097,000\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "\n",
    "        # feature extractor\n",
    "        x = self.features(x)\n",
    "\n",
    "        # adaptive average pooling\n",
    "        x = self.avgpool(x)\n",
    "\n",
    "        # flatten : 256x6x6 -> 9216\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "\n",
    "        # classifier\n",
    "        x = self.classifier(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = CustomAlexNet(num_classes=1000, dropout=0.5)\n",
    "model_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model_1, (1, 3, 227, 227), device='cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch AlexNet\n",
    "   - AlexNet is available in PyTorch: [pytorch.org/vision/stable/models/alexnet.html](https://pytorch.org/vision/stable/models/alexnet.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = alexnet()\n",
    "model_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model_2, (1, 3, 227, 227), device='cpu')"
   ]
  }
 ],
 "metadata": {
  "author_email": "AmirhosseinHeydari78@gmail.com",
  "author_github": "https://github.com/mr-pylin",
  "author_name": "Amirhossein Heydari",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "origin_repo": "https://github.com/mr-pylin/pytorch-workshop"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
