{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìù **Author:** Amirhossein Heydari - üìß **Email:** amirhosseinheydari78@gmail.com - üìç **Linktree:** [linktr.ee/mr_pylin](https://linktr.ee/mr_pylin)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# array_like Sequences\n",
    "   - `list`\n",
    "      - Used for storing elements of different data types\n",
    "      - Flexible: there is no length & shape limit\n",
    "      - Not optimized for mathematical operations\n",
    "   - `numpy.ndarray`\n",
    "      - Implemented in C\n",
    "      - Used for mathematical operations\n",
    "      - Arrays are homogeneous: they can store elements of the same data type\n",
    "   - `troch.Tensor`\n",
    "      - PyTorch's core functionality is implemented in C++\n",
    "      - Optimized for deep learning operations e.g. auto gradient\n",
    "      - Support GPU acceleration [NVIDIA/AMD GPUs]\n",
    "\n",
    "üìù **Docs**:\n",
    "   - More on Lists: [docs.python.org/3/tutorial/datastructures.html#more-on-lists](https://docs.python.org/3/tutorial/datastructures.html#more-on-lists)\n",
    "   - `numpy.ndarray`: [numpy.org/doc/stable/reference/generated/numpy.ndarray.html](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html)\n",
    "   - `torch.Tensor`: [pytorch.org/docs/stable/tensors.html](https://pytorch.org/docs/stable/tensors.html)\n",
    "\n",
    "üìö **Tutorials**:\n",
    "   - Tensors: [pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html](https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scalar_1: 2 | ndim: 0 | dtype: <class 'int'>\n",
      "scalar_2: 2 | ndim: 0 | dtype: numpy.int32\n",
      "scalar_3: 2 | ndim: 0 | dtype: torch.int64\n"
     ]
    }
   ],
   "source": [
    "# scalar : 0-dimensional array/tensor\n",
    "scalar_1 = 2\n",
    "scalar_2 = np.array(2)\n",
    "scalar_3 = torch.tensor(2)\n",
    "\n",
    "# log\n",
    "print(f\"scalar_1: {scalar_1} | ndim: 0 | dtype: {type(scalar_1)}\")\n",
    "print(f\"scalar_2: {scalar_2} | ndim: {scalar_2.ndim} | dtype: numpy.{scalar_2.dtype}\")\n",
    "print(f\"scalar_3: {scalar_3} | ndim: {scalar_3.ndim} | dtype: {scalar_3.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector_1: [1, 2, 3]         | ndim: 1 | dtype: <class 'int'>\n",
      "vector_2: [1 2 3]           | ndim: 1 | dtype: numpy.int32\n",
      "vector_3: tensor([1, 2, 3]) | ndim: 1 | dtype: torch.int64\n"
     ]
    }
   ],
   "source": [
    "# vector : 1-dimensional list/array/tensor\n",
    "vector_1 = [1, 2, 3]\n",
    "vector_2 = np.array(vector_1)\n",
    "vector_3 = torch.tensor(vector_1)\n",
    "\n",
    "# log\n",
    "print(f\"vector_1: {str(vector_1):<17} | ndim: 1 | dtype: {type(vector_1[0])}\")\n",
    "print(f\"vector_2: {str(vector_2):<17} | ndim: {vector_2.ndim} | dtype: numpy.{vector_2.dtype}\")\n",
    "print(f\"vector_3: {vector_3} | ndim: {vector_3.ndim} | dtype: {vector_3.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matrix_1:\n",
      "[[0, 1], [2, 3]]\n",
      "ndim : 2\n",
      "dtype: <class 'int'>\n",
      "--------------------------------------------------\n",
      "matrix_2:\n",
      "[[0 1]\n",
      " [2 3]]\n",
      "matrix_2.ndim : 2\n",
      "matrix_2.shape: (2, 2)\n",
      "matrix_2.dtype: numpy.int32\n",
      "--------------------------------------------------\n",
      "matrix_3:\n",
      "tensor([[0, 1],\n",
      "        [2, 3]])\n",
      "matrix_3.ndim : 2\n",
      "matrix_3.shape: torch.Size([2, 2])\n",
      "matrix_3.dtype: torch.int64\n"
     ]
    }
   ],
   "source": [
    "# matrix : 2-dimensional list/array/tensor\n",
    "matrix_1 = [[0, 1], [2, 3]]\n",
    "matrix_2 = np.array(matrix_1)\n",
    "matrix_3 = torch.tensor(matrix_1)\n",
    "\n",
    "# log\n",
    "print(f\"matrix_1:\\n{matrix_1}\\nndim : 2\\ndtype: {type(matrix_1[0][0])}\")\n",
    "print('-' * 50)\n",
    "print(f\"matrix_2:\\n{matrix_2}\\nmatrix_2.ndim : {matrix_2.ndim}\\nmatrix_2.shape: {matrix_2.shape}\\nmatrix_2.dtype: numpy.{matrix_2.dtype}\")\n",
    "print('-' * 50)\n",
    "print(f\"matrix_3:\\n{matrix_3}\\nmatrix_3.ndim : {matrix_3.ndim}\\nmatrix_3.shape: {matrix_3.shape}\\nmatrix_3.dtype: {matrix_3.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lst:\n",
      "[[[0, 1], [2, 3]], [[4, 5], [6, 7]]]\n",
      "ndim : 3\n",
      "dtype: <class 'int'>\n",
      "--------------------------------------------------\n",
      "arr:\n",
      "[[[0 1]\n",
      "  [2 3]]\n",
      "\n",
      " [[4 5]\n",
      "  [6 7]]]\n",
      "arr.ndim : 3\n",
      "arr.shape: (2, 2, 2)\n",
      "arr.dtype: numpy.int32\n",
      "--------------------------------------------------\n",
      "tsr:\n",
      "tensor([[[0, 1],\n",
      "         [2, 3]],\n",
      "\n",
      "        [[4, 5],\n",
      "         [6, 7]]])\n",
      "tsr.ndim : 3\n",
      "tsr.shape: torch.Size([2, 2, 2])\n",
      "tsr.dtype: torch.int64\n"
     ]
    }
   ],
   "source": [
    "# 3-dimensional list/array/tensor\n",
    "list_3d_1 = [[[0, 1], [2, 3]], [[4, 5], [6, 7]]]\n",
    "array_3d_1 = np.array(list_3d_1)\n",
    "tensor_3d_1 = torch.tensor(list_3d_1)\n",
    "\n",
    "# log\n",
    "print(f\"lst:\\n{list_3d_1}\\nndim : 3\\ndtype: {type(list_3d_1[0][0][0])}\")\n",
    "print('-' * 50)\n",
    "print(f\"arr:\\n{array_3d_1}\\narr.ndim : {array_3d_1.ndim}\\narr.shape: {array_3d_1.shape}\\narr.dtype: numpy.{array_3d_1.dtype}\")\n",
    "print('-' * 50)\n",
    "print(f\"tsr:\\n{tensor_3d_1}\\ntsr.ndim : {tensor_3d_1.ndim}\\ntsr.shape: {tensor_3d_1.shape}\\ntsr.dtype: {tensor_3d_1.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ones, Zeros, Full, Empty\n",
    "üìù **Docs**:\n",
    "   - Creation Ops: [pytorch.org/docs/stable/torch.html#creation-ops](https://pytorch.org/docs/stable/torch.html#creation-ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ones_1:\n",
      "1.0\n",
      "ones_1.size() : torch.Size([])\n",
      "ones_1.ndim   : 0\n",
      "ones_1.dtype  : torch.float32\n",
      "type(ones_1)  : <class 'torch.Tensor'>\n",
      "--------------------------------------------------\n",
      "ones_2:\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n",
      "ones_2.size() : torch.Size([2, 2])\n",
      "ones_2.ndim   : 2\n",
      "ones_2.dtype  : torch.float32\n",
      "type(ones_2)  : <class 'torch.Tensor'>\n",
      "--------------------------------------------------\n",
      "zeros_1:\n",
      "tensor([0., 0.])\n",
      "zeros_1.size() : torch.Size([2])\n",
      "zeros_1.ndim   : 1\n",
      "zeros_1.dtype  : torch.float32\n",
      "type(zeros_1)  : <class 'torch.Tensor'>\n",
      "--------------------------------------------------\n",
      "zeros_2:\n",
      "tensor([0, 0, 0], dtype=torch.int16)\n",
      "zeros_2.size() : torch.Size([3])\n",
      "zeros_2.ndim   : 1\n",
      "zeros_2.dtype  : torch.int16\n",
      "type(zeros_2)  : <class 'torch.Tensor'>\n",
      "--------------------------------------------------\n",
      "full_1:\n",
      "tensor([3, 3, 3], dtype=torch.int16)\n",
      "full_1.size() : torch.Size([3])\n",
      "full_1.ndim   : 1\n",
      "full_1.dtype  : torch.int16\n",
      "type(full_1)  : <class 'torch.Tensor'>\n",
      "--------------------------------------------------\n",
      "empty_1:\n",
      "tensor([[nan, nan, nan],\n",
      "        [nan, nan, nan]])\n",
      "empty_1.size() : torch.Size([2, 3])\n",
      "empty_1.ndim   : 2\n",
      "empty_1.dtype  : torch.float32\n",
      "type(empty_1)  : <class 'torch.Tensor'>\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ones\n",
    "ones_1 = torch.ones(size=())\n",
    "ones_2 = torch.ones(size=(2, 2))\n",
    "\n",
    "# zeros\n",
    "zeros_1 = torch.zeros(size=(2,))\n",
    "zeros_2 = torch.zeros(size=(3,), dtype=torch.int16)\n",
    "\n",
    "# full\n",
    "full_1 = torch.full(size=(3,), fill_value=3, dtype=torch.int16)\n",
    "\n",
    "# empty\n",
    "empty_1 = torch.empty(size=(2, 3))\n",
    "\n",
    "# log\n",
    "for variable in ['ones_1', 'ones_2', 'zeros_1', 'zeros_2', 'full_1', 'empty_1']:\n",
    "    print(f\"{variable}:\\n{eval(variable)}\")\n",
    "    print(f\"{variable}.size() : {eval(variable).size()}\")\n",
    "    print(f\"{variable}.ndim   : {eval(variable).ndim}\")\n",
    "    print(f\"{variable}.dtype  : {eval(variable).dtype}\")\n",
    "    print(f\"type({variable})  : {type(eval(variable))}\")\n",
    "    print('-' * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index & Slice\n",
    "   - Indexing a tensor in the PyTorch C++ API works very similar to the Python API.\n",
    "   - All index types such as `None` / `...` / `integer` / `boolean` / `slice` / `tensor` are available in the C++ API, making translation from Python indexing code to C++ very simple.\n",
    "   \n",
    "üìù **Docs**:\n",
    "   - Tensor Indexing API: [pytorch.org/cppdocs/notes/tensor_indexing.html](https://pytorch.org/cppdocs/notes/tensor_indexing.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index_1: tensor([1, 2, 3, 4])\n",
      "index_2: tensor([5, 6, 7, 8])\n",
      "index_3: tensor([ 9, 10, 11, 12])\n",
      "index_4: 1\n",
      "index_5: 11\n"
     ]
    }
   ],
   "source": [
    "tensor_2d_1 = torch.tensor([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]])\n",
    "\n",
    "# index\n",
    "index_1 = tensor_2d_1[0]\n",
    "index_2 = tensor_2d_1[1]\n",
    "index_3 = tensor_2d_1[-1]\n",
    "index_4 = tensor_2d_1[0, 0]\n",
    "index_5 = tensor_2d_1[2, -2]\n",
    "\n",
    "# log\n",
    "print(f\"index_1: {index_1}\")\n",
    "print(f\"index_2: {index_2}\")\n",
    "print(f\"index_3: {index_3}\")\n",
    "print(f\"index_4: {index_4}\")\n",
    "print(f\"index_5: {index_5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slice_1:\n",
      "tensor([0, 1, 2, 3])\n",
      "\n",
      "slice_2:\n",
      "tensor([1, 5, 9])\n",
      "\n",
      "slice_3:\n",
      "tensor([[2, 3],\n",
      "        [6, 7]])\n",
      "\n",
      "slice_4:\n",
      "tensor([8])\n"
     ]
    }
   ],
   "source": [
    "tensor_2d_2 = torch.arange(12).reshape((3, 4))\n",
    "\n",
    "# slice\n",
    "slice_1 = tensor_2d_2[0, :]    # same as tensor_2d_2[0]\n",
    "slice_2 = tensor_2d_2[:, 1]\n",
    "slice_3 = tensor_2d_2[:2, 2:]\n",
    "slice_4 = tensor_2d_2[-1:, 0]\n",
    "\n",
    "# log\n",
    "print(f\"slice_1:\\n{slice_1}\\n\")\n",
    "print(f\"slice_2:\\n{slice_2}\\n\")\n",
    "print(f\"slice_3:\\n{slice_3}\\n\")\n",
    "print(f\"slice_4:\\n{slice_4}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Math operations\n",
    "\n",
    "üìù **Docs**:\n",
    "   - Math operations: [pytorch.org/docs/stable/torch.html#math-operations](https://pytorch.org/docs/stable/torch.html#math-operations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pointwise Ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor_2d_3:\n",
      "tensor([[0, 1],\n",
      "        [2, 3]])\n",
      "\n",
      "tensor_2d_4:\n",
      "tensor([[2, 2],\n",
      "        [2, 2]])\n",
      "--------------------------------------------------\n",
      "arithmetic_1:\n",
      "tensor([[2, 3],\n",
      "        [4, 5]])\n",
      "\n",
      "arithmetic_2:\n",
      "tensor([[-2, -1],\n",
      "        [ 0,  1]])\n",
      "\n",
      "arithmetic_3:\n",
      "tensor([[0, 2],\n",
      "        [4, 6]])\n",
      "\n",
      "arithmetic_4:\n",
      "tensor([[0.0000, 0.5000],\n",
      "        [1.0000, 1.5000]])\n",
      "\n",
      "arithmetic_5:\n",
      "tensor([[0, 0],\n",
      "        [1, 1]])\n",
      "\n",
      "arithmetic_6:\n",
      "tensor([[0, 1],\n",
      "        [0, 1]])\n",
      "\n",
      "arithmetic_7:\n",
      "tensor([[0, 1],\n",
      "        [4, 9]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tensor_2d_3 = torch.arange(4).reshape(2, 2)\n",
    "tensor_2d_4 = torch.full(size=(2, 2), fill_value=2, dtype=torch.int64)\n",
    "\n",
    "# arithmetic operations\n",
    "arithmetic_1 = tensor_2d_3 + tensor_2d_4   # torch.add\n",
    "arithmetic_2 = tensor_2d_3 - tensor_2d_4   # torch.sub\n",
    "arithmetic_3 = tensor_2d_3 * tensor_2d_4   # torch.multiply\n",
    "arithmetic_4 = tensor_2d_3 / tensor_2d_4   # torch.divide\n",
    "arithmetic_5 = tensor_2d_3 // tensor_2d_4  # torch.floor_divide\n",
    "arithmetic_6 = tensor_2d_3 % tensor_2d_4   # torch.remainder\n",
    "arithmetic_7 = tensor_2d_3 ** tensor_2d_4  # torch.power\n",
    "\n",
    "# log\n",
    "print(f\"tensor_2d_3:\\n{tensor_2d_3}\\n\")\n",
    "print(f\"tensor_2d_4:\\n{tensor_2d_4}\")\n",
    "print('-' * 50)\n",
    "for i in range(7):\n",
    "    print(f\"arithmetic_{i+1}:\\n{eval(f'arithmetic_{i+1}')}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Broadcasting\n",
    "   - [pytorch.org/docs/stable/notes/broadcasting.html](https://pytorch.org/docs/stable/notes/broadcasting.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor_2d_5:\n",
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "\n",
      "tensor_2d_5:\n",
      "tensor([[1],\n",
      "        [2]])\n",
      "--------------------------------------------------\n",
      "broadcasting_1:\n",
      "tensor([[2, 3],\n",
      "        [4, 5]])\n",
      "\n",
      "broadcasting_2:\n",
      "tensor([[2, 3],\n",
      "        [5, 6]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tensor_2d_5 = torch.arange(4).reshape(2, 2) + 1\n",
    "tensor_2d_6 = torch.tensor([[1], [2]])\n",
    "\n",
    "# broadcasting\n",
    "broadcasting_1 = tensor_2d_5 + 1\n",
    "broadcasting_2 = tensor_2d_5 + tensor_2d_6\n",
    "\n",
    "# log\n",
    "print(f\"tensor_2d_5:\\n{tensor_2d_5}\\n\")\n",
    "print(f\"tensor_2d_5:\\n{tensor_2d_6}\")\n",
    "print('-' * 50)\n",
    "print(f\"broadcasting_1:\\n{broadcasting_1}\\n\")\n",
    "print(f\"broadcasting_2:\\n{broadcasting_2}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshape & View\n",
    "   - torch.Tensor.**view**:\n",
    "      - requires the tensor to be contiguous\n",
    "      - less flexible due to the contiguity requirement\n",
    "      - generally faster since it doesn't involve copying data, just changes the metadata\n",
    "      - [pytorch.org/docs/stable/generated/torch.Tensor.reshape.html](https://pytorch.org/docs/stable/generated/torch.Tensor.reshape.html)\n",
    "   - torch.Tensor.**reshape**:\n",
    "      - it can handle non-contiguous tensors by copying data if necessary\n",
    "      - more flexible as it can work with both contiguous and non-contiguous tensors\n",
    "      - might be slower if it needs to copy the data to create a contiguous block\n",
    "      - [pytorch.org/docs/stable/generated/torch.Tensor.view.html](https://pytorch.org/docs/stable/generated/torch.Tensor.view.html)\n",
    "\n",
    "**Note**:\n",
    "   - it is advisable to use `reshape`, which returns a `view` if the shapes are compatible, and copies otherwise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor_2d_7:\n",
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11],\n",
      "        [12, 13, 14, 15]])\n",
      "\n",
      "--------------------------------------------------\n",
      "reshape_1:\n",
      "tensor([[ 0,  1,  2,  3,  4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11, 12, 13, 14, 15]])\n",
      "reshape_1.shape: torch.Size([2, 8])\n",
      "\n",
      "reshape_2:\n",
      "tensor([[[ 0,  1],\n",
      "         [ 2,  3],\n",
      "         [ 4,  5],\n",
      "         [ 6,  7]],\n",
      "\n",
      "        [[ 8,  9],\n",
      "         [10, 11],\n",
      "         [12, 13],\n",
      "         [14, 15]]])\n",
      "reshape_2.shape: torch.Size([2, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "tensor_2d_7 = torch.arange(16).reshape(4, 4)\n",
    "\n",
    "# reshape\n",
    "reshape_1 = tensor_2d_7.reshape(2, 8)\n",
    "reshape_2 = tensor_2d_7.reshape(2, -1, 2)\n",
    "\n",
    "# log\n",
    "print(f\"tensor_2d_7:\\n{tensor_2d_7}\\n\")\n",
    "print('-' * 50)\n",
    "print(f\"reshape_1:\\n{reshape_1}\")\n",
    "print(f\"reshape_1.shape: {reshape_1.shape}\\n\")\n",
    "print(f\"reshape_2:\\n{reshape_2}\")\n",
    "print(f\"reshape_2.shape: {reshape_2.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor_2d_7:\n",
      "tensor([[100,   1,   2,   3],\n",
      "        [  4,   5,   6,   7],\n",
      "        [  8,   9,  10,  11],\n",
      "        [ 12,  13,  14,  15]])\n",
      "\n",
      "reshape_1:\n",
      "tensor([[100,   1,   2,   3,   4,   5,   6,   7],\n",
      "        [  8,   9,  10,  11,  12,  13,  14,  15]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# assignment by index\n",
    "tensor_2d_7[0, 0] = 100\n",
    "\n",
    "# log\n",
    "print(f\"tensor_2d_7:\\n{tensor_2d_7}\\n\")\n",
    "print(f\"reshape_1:\\n{reshape_1}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mutable Objects\n",
    "   - mutable objects refer to objects that can be modified after they are created.\n",
    "   - For example, `list`, `numpy.ndarray`, `torch.Tensor` are mutable objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy Tensors\n",
    "   - `torch.clone`: \n",
    "      - creates a hard/deep copy\n",
    "      - This function is differentiable, so gradients will flow back from the result of this operation to `input`\n",
    "   - [pytorch.org/docs/stable/generated/torch.clone.html](https://pytorch.org/docs/stable/generated/torch.clone.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clone_1: tensor([0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "tensor_1d_1 = torch.zeros(size=(5,))\n",
    "\n",
    "# clone\n",
    "clone_1 = tensor_1d_1.clone()\n",
    "\n",
    "# assignment by index\n",
    "tensor_1d_1[0] = 1\n",
    "\n",
    "# log\n",
    "print(f\"clone_1: {clone_1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.Tensor to numpy.ndarray\n",
    "   - [pytorch.org/docs/stable/generated/torch.Tensor.numpy.html](https://pytorch.org/docs/stable/generated/torch.Tensor.numpy.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor_1d_2        : tensor([0, 2, 6, 3])\n",
      "type(tensor_1d_2)  : <class 'torch.Tensor'>\n",
      "--------------------------------------------------\n",
      "tensor_to_numpy_1        : [0 2 6 3]\n",
      "type(tensor_to_numpy_1)  : <class 'numpy.ndarray'>\n",
      "\n",
      "tensor_to_numpy_2        : [1 2 6 3]\n",
      "type(tensor_to_numpy_2)  : <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "tensor_1d_2 = torch.tensor([1, 2, 6, 3])\n",
    "\n",
    "# convert + shared memory\n",
    "tensor_to_numpy_1 = tensor_1d_2.numpy()\n",
    "\n",
    "# convert + copy\n",
    "tensor_to_numpy_2 = np.array(tensor_1d_2)\n",
    "\n",
    "# assignment by index\n",
    "tensor_1d_2[0] = 0\n",
    "\n",
    "# log\n",
    "print(f\"tensor_1d_2        : {tensor_1d_2}\")\n",
    "print(f\"type(tensor_1d_2)  : {type(tensor_1d_2)}\")\n",
    "print('-' * 50)\n",
    "print(f\"tensor_to_numpy_1        : {tensor_to_numpy_1}\")\n",
    "print(f\"type(tensor_to_numpy_1)  : {type(tensor_to_numpy_1)}\\n\")\n",
    "print(f\"tensor_to_numpy_2        : {tensor_to_numpy_2}\")\n",
    "print(f\"type(tensor_to_numpy_2)  : {type(tensor_to_numpy_2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### numpy.ndarray to torch.Tensor\n",
    "   - [pytorch.org/docs/stable/generated/torch.from_numpy.html](https://pytorch.org/docs/stable/generated/torch.from_numpy.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array_1d_1       : [0 4 2 3]\n",
      "type(array_1d_1) : <class 'numpy.ndarray'>\n",
      "--------------------------------------------------\n",
      "numpy_to_tensor_1       : tensor([0, 4, 2, 3], dtype=torch.int32)\n",
      "type(numpy_to_tensor_1) : <class 'torch.Tensor'>\n",
      "\n",
      "numpy_to_tensor_2       : tensor([1, 4, 2, 3], dtype=torch.int32)\n",
      "type(numpy_to_tensor_2) : <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "array_1d_1 = np.array([1, 4, 2, 3])\n",
    "\n",
    "# convert + shared memory\n",
    "numpy_to_tensor_1 = torch.from_numpy(array_1d_1)\n",
    "\n",
    "# convert + copy\n",
    "numpy_to_tensor_2 = torch.tensor(array_1d_1)\n",
    "\n",
    "# assignment by index\n",
    "array_1d_1[0] = 0\n",
    "\n",
    "# log\n",
    "print(f\"array_1d_1       : {array_1d_1}\")\n",
    "print(f\"type(array_1d_1) : {type(array_1d_1)}\")\n",
    "print('-' * 50)\n",
    "print(f\"numpy_to_tensor_1       : {numpy_to_tensor_1}\")\n",
    "print(f\"type(numpy_to_tensor_1) : {type(numpy_to_tensor_1)}\\n\")\n",
    "print(f\"numpy_to_tensor_2       : {numpy_to_tensor_2}\")\n",
    "print(f\"type(numpy_to_tensor_2) : {type(numpy_to_tensor_2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In-Place Operations\n",
    "   - Operations that have a `_` suffix are in-place.\n",
    "   - In-place operations save some memory, but can be problematic when computing derivatives because of an immediate loss of history.\n",
    "   - Hence, their use is discouraged.\n",
    "\n",
    "üìö **Tutorials**:\n",
    "   - in-place operations: [pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html](https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html#:~:text=3.%2C%203.%2C%203.%5D%5D\\)-,In%2Dplace%20operations,-Operations%20that%20have)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor_1d_3    : tensor([3., 4., 5., 6.])\n",
      "another_tensor : tensor([5., 6., 7., 8.])\n"
     ]
    }
   ],
   "source": [
    "tensor_1d_3 = torch.tensor([1.0, 2.0, 3.0, 4.0])\n",
    "\n",
    "# in-place addition\n",
    "tensor_1d_3.add_(2)  # tensor_1d_3 += 2\n",
    "\n",
    "# out-of-place addition\n",
    "another_tensor = torch.add(tensor_1d_3, 2)  # another_tensor = tensor_1d_3 + 2\n",
    "\n",
    "# log\n",
    "print(f\"tensor_1d_3    : {tensor_1d_3}\")\n",
    "print(f\"another_tensor : {another_tensor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU Acceleration\n",
    "   - PyTorch relies on the underlying [CUDA](https://developer.nvidia.com/cuda-gpus) [NVIDIA GPUs] and [ROCm](https://rocm.docs.amd.com/projects/install-on-linux/en/latest/reference/3rd-party-support-matrix.html#deep-learning) [AMD GPUs] libraries for GPU support\n",
    "   - [pytorch.org/docs/stable/notes/cuda.html](https://pytorch.org/docs/stable/notes/cuda.html)\n",
    "\n",
    "‚úçÔ∏è **Notes**:\n",
    "   - Tensors on the `GPU` cannot be directly converted to `np.ndarray` or other structures that do not support GPU operations.\n",
    "   - You can use `torch.backends.rocm.is_available()` instead of `torch.cuda.is_available()` for clarity if targeting AMD GPUs.\n",
    "   - The version of PyTorch you're using must include the ROCm-specific attribute to run `torch.backends.rocm.is_available()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# alternative\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# log\n",
    "print(f\"device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_cuda_devices  : 1\n",
      "cuda 0:\n",
      "\tname                  : NVIDIA GeForce GTX 1650\n",
      "\ttotal_memory          : 4294639616 bytes\n",
      "\tmulti_processor_count : 14\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "\n",
    "    # number of cuda devices\n",
    "    num_cuda_devices = torch.cuda.device_count()\n",
    "    print(f\"num_cuda_devices  : {num_cuda_devices}\")\n",
    "\n",
    "    # cuda models\n",
    "    for i in range(num_cuda_devices):\n",
    "        print(f\"cuda {i}:\")\n",
    "        print(f\"\\tname                  : {torch.cuda.get_device_properties(i).name}\")\n",
    "        print(f\"\\ttotal_memory          : {torch.cuda.get_device_properties(i).total_memory} bytes\")\n",
    "        print(f\"\\tmulti_processor_count : {torch.cuda.get_device_properties(i).multi_processor_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor_1d_4        : tensor([1., 1., 1., 1., 1.])\n",
      "tensor_1d_4.device : cpu\n",
      "\n",
      "tensor_1d_5        : tensor([1., 1., 1., 1., 1.], device='cuda:0')\n",
      "tensor_1d_5.device : cuda:0\n",
      "\n",
      "tensor_1d_6        : tensor([3., 4., 5., 6.], device='cuda:0')\n",
      "tensor_1d_6.device : cuda:0\n",
      "\n",
      "tensor_1d_7        : tensor([3., 4., 5., 6.], device='cuda:0')\n",
      "tensor_1d_7.device : cuda:0\n"
     ]
    }
   ],
   "source": [
    "tensor_1d_4 = torch.ones(5)                 # CPU                          [default]\n",
    "tensor_1d_5 = torch.ones(5, device=device)  # CPU/GPU (depends on device)  [dynamic]\n",
    "tensor_1d_6 = tensor_1d_3.to(device)        # CPU/GPU (depends on device)  [dynamic]\n",
    "tensor_1d_7 = tensor_1d_3.cuda()            # GPU                          [static]\n",
    "\n",
    "# log\n",
    "print(f\"tensor_1d_4        : {tensor_1d_4}\")\n",
    "print(f\"tensor_1d_4.device : {tensor_1d_4.device}\\n\")\n",
    "print(f\"tensor_1d_5        : {tensor_1d_5}\")\n",
    "print(f\"tensor_1d_5.device : {tensor_1d_5.device}\\n\")\n",
    "print(f\"tensor_1d_6        : {tensor_1d_6}\")\n",
    "print(f\"tensor_1d_6.device : {tensor_1d_6.device}\\n\")\n",
    "print(f\"tensor_1d_7        : {tensor_1d_7}\")\n",
    "print(f\"tensor_1d_7.device : {tensor_1d_7.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.\n"
     ]
    }
   ],
   "source": [
    "tensor_1d_8 = torch.ones(size=(5,), device=device)\n",
    "\n",
    "# torch.Tensor to numpy.ndarray\n",
    "try:\n",
    "    tensor_1d_8.numpy()\n",
    "except TypeError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor_to_numpy_3       : [1. 1. 1. 1. 1.]\n",
      "type(tensor_to_numpy_3) : <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "tensor_1d_9 = torch.ones(size=(5,), device=device)\n",
    "\n",
    "# torch.Tensor to numpy.ndarray\n",
    "tensor_to_numpy_3 = tensor_1d_9.cpu().numpy()\n",
    "\n",
    "# log\n",
    "print(f\"tensor_to_numpy_3       : {tensor_to_numpy_3}\")\n",
    "print(f\"type(tensor_to_numpy_3) : {type(tensor_to_numpy_3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproducibility\n",
    "   - **Seed**: An initial value used to initialize a pseudo-random number generator, ensuring reproducibility of random sequences.\n",
    "\n",
    "   - **Platform and Release Variations**:\n",
    "      - Completely reproducible results are not guaranteed across:\n",
    "         - Different PyTorch releases\n",
    "         - Individual commits\n",
    "         - Different platforms (e.g., CPU vs. GPU, different OS)\n",
    "\n",
    "   - **Performance Trade-offs**:\n",
    "      - Deterministic operations are often slower than nondeterministic operations.\n",
    "  \n",
    "   - **Benefits of Determinism**:\n",
    "      - Determinism can save time in development by facilitating:\n",
    "         - Experimentation\n",
    "         - Debugging\n",
    "         - Testing\n",
    "\n",
    "üìù **Docs**:\n",
    "   - Reproducibility: [pytorch.org/docs/stable/notes/randomness.html](https://pytorch.org/docs/stable/notes/randomness.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.get_rng_state()[0]      : 42\n",
      "torch.cuda.get_rng_state()[0] : 42\n"
     ]
    }
   ],
   "source": [
    "# set a seed for both CPU & GPU\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# log\n",
    "print(f\"torch.get_rng_state()[0]      : {torch.get_rng_state()[0]}\")\n",
    "print(f\"torch.cuda.get_rng_state()[0] : {torch.cuda.get_rng_state()[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.get_rng_state()[0]      : 42\n",
      "torch.cuda.get_rng_state()[0] : 0\n"
     ]
    }
   ],
   "source": [
    "# set a seed only for GPU\n",
    "torch.cuda.manual_seed(0)\n",
    "\n",
    "# log\n",
    "print(f\"torch.get_rng_state()[0]      : {torch.get_rng_state()[0]}\")\n",
    "print(f\"torch.cuda.get_rng_state()[0] : {torch.cuda.get_rng_state()[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `torch.backends.cudnn.deterministic`\n",
    "   - This flag ensures that the CUDA Deep Neural Network library (cuDNN) uses deterministic algorithms.\n",
    "   - the results will be the same for every run when the same input and seed are provided.\n",
    "   - Default value is `False`.\n",
    "\n",
    "üí• **Impact**\n",
    "   - When set to `True`, It can slow down your computations because deterministic algorithms are typically slower due to fewer optimizations\n",
    "\n",
    "üìù **Docs**:\n",
    "   - [pytorch.org/docs/stable/backends.html#torch.backends.cudnn.deterministic](https://pytorch.org/docs/stable/backends.html#torch.backends.cudnn.deterministic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `torch.backends.cudnn.benchmark`\n",
    "   - This flag enables the cuDNN auto-tuner to find the best algorithm for your hardware.\n",
    "   - It is useful when the input sizes to your model are changing or not fixed.\n",
    "   - Default value is `False`\n",
    "\n",
    "üí• **Impact**\n",
    "   - When set to `True`, cuDNN will select the best algorithm for your hardware, potentially improving performance.\n",
    "   - If you need exact reproducibility, you should not set benchmark to `True`!\n",
    "\n",
    "üìù **Docs**:\n",
    "   - [pytorch.org/docs/stable/backends.html#torch.backends.cudnn.benchmark](https://pytorch.org/docs/stable/backends.html#torch.backends.cudnn.benchmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `torch.use_deterministic_algorithms`\n",
    "   - This function ensures that all the operations that could be non-deterministic are forced to use deterministic algorithms.\n",
    "   - Default value is `False`.\n",
    "\n",
    "üí• **Impact**\n",
    "   - When set to `True`, This could lead to slower performance as deterministic algorithms are often slower due to the lack of certain optimizations.\n",
    "\n",
    "üìù **Docs**:\n",
    "   - [pytorch.org/docs/stable/generated/torch.use_deterministic_algorithms.html#torch.use_deterministic_algorithms](https://pytorch.org/docs/stable/generated/torch.use_deterministic_algorithms.html#torch.use_deterministic_algorithms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.are_deterministic_algorithms_enabled(): True\n"
     ]
    }
   ],
   "source": [
    "torch.use_deterministic_algorithms(True)\n",
    "\n",
    "# check\n",
    "print(f\"torch.are_deterministic_algorithms_enabled(): {torch.are_deterministic_algorithms_enabled()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Sampling from a Distribution\n",
    "   - Random sampling from a distribution refers to the process of generating random samples from a specific probability distribution.\n",
    "   - In most cases, the goal is to sample from these distributions to simulate or model real-world phenomena.\n",
    "\n",
    "üìù **Docs**:\n",
    "   - [pytorch.org/docs/stable/torch.html#random-sampling](https://pytorch.org/docs/stable/torch.html#random-sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rand_1       : tensor([0.8823, 0.9150, 0.3829, 0.9593, 0.3904])\n",
      "rand_1.dtype : torch.float32\n"
     ]
    }
   ],
   "source": [
    "# a tensor filled with random numbers from a uniform distribution on the interval [0,1)\n",
    "rand_1 = torch.rand(size=(5,))\n",
    "\n",
    "# log\n",
    "print(f\"rand_1       : {rand_1}\")\n",
    "print(f\"rand_1.dtype : {rand_1.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal_1        : tensor([ 0.0326, -0.0868,  0.1523,  0.0665, -0.1032])\n",
      "normal_1.mean() : 0.01226949505507946\n",
      "normal_1.std()  : 0.10736953467130661\n",
      "normal_1.dtype  : torch.float32\n"
     ]
    }
   ],
   "source": [
    "# a tensor of random numbers drawn from separate normal distributions\n",
    "normal_1 = torch.normal(mean=0, std=.1, size=(5,))\n",
    "\n",
    "# log\n",
    "print(f\"normal_1        : {normal_1}\")\n",
    "print(f\"normal_1.mean() : {normal_1.mean()}\")\n",
    "print(f\"normal_1.std()  : {normal_1.std()}\")\n",
    "print(f\"normal_1.dtype  : {normal_1.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `torch.Tensor.item()`\n",
    "   - What you see is not necessarily the actual value!\n",
    "   - [pytorch.org/docs/stable/generated/torch.Tensor.item.html](https://pytorch.org/docs/stable/generated/torch.Tensor.item.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor_1d_10: tensor([0.5739, 0.2666, 0.6274, 0.2696, 0.4414, 0.2969])\n",
      "--------------------------------------------------\n",
      "value_1       : 0.5739044547080994\n",
      "value_1.dtype : torch.float32\n",
      "\n",
      "value_2       : 0.5739044547080994\n",
      "type(value_2) : <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "tensor_1d_10 = torch.rand(size=(6,))\n",
    "\n",
    "# item()\n",
    "value_1 = tensor_1d_10[0]\n",
    "value_2 = tensor_1d_10[0].item()\n",
    "\n",
    "# log\n",
    "print(f\"tensor_1d_10: {tensor_1d_10}\")\n",
    "print('-' * 50)\n",
    "print(f\"value_1       : {value_1}\")\n",
    "print(f\"value_1.dtype : {value_1.dtype}\\n\")\n",
    "print(f\"value_2       : {value_2}\")\n",
    "print(f\"type(value_2) : {type(value_2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Miscellaneous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `torch.float32` is preferred over `torch.float64` in most deep learning tasks\n",
    "   1. **Performance and Speed**:\n",
    "      - Single-precision (`torch.float32`) operations are faster and require less computational effort compared to double-precision (`torch.float64`).\n",
    "   1. **Memory Usage**:\n",
    "      - `torch.float32` uses 32 bits (4 bytes) per value, while `torch.float64` uses 64 bits (8 bytes), leading to lower memory requirements for `float32`.\n",
    "   1. **Adequate Precision**:\n",
    "      - For most deep learning tasks, `torch.float32` offers sufficient precision. Double-precision (`torch.float64`) is often unnecessary.\n",
    "   1. **Energy Efficiency**:\n",
    "      - Single-precision arithmetic is more energy-efficient than double-precision, making it ideal for tasks that demand lower power consumption.\n",
    "   1. **Industry Standards**:\n",
    "      - `torch.float32` is the standard in deep learning frameworks and is widely used across research and production environments.\n",
    "   1. **Hardware Constraints**:\n",
    "      - Many hardware platforms, including embedded systems and mobile devices, have limited computational resources and memory, making `torch.float32` more suitable.\n",
    "\n",
    "‚úçÔ∏è **Notes**:\n",
    "- `torch.float32` is also called `float` or `single-precision`.\n",
    "- `torch.float64` is also called `double` or `double-precision`."
   ]
  }
 ],
 "metadata": {
  "author_email": "AmirhosseinHeydari78@gmail.com",
  "author_github": "https://github.com/mr-pylin",
  "author_name": "Amirhossein Heydari",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "origin_repo": "https://github.com/mr-pylin/pytorch-workshop"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
