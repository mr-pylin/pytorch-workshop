{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìù **Author:** Amirhossein Heydari - üìß **Email:** amirhosseinheydari78@gmail.com - üìç **Linktree:** [linktr.ee/mr_pylin](https://linktr.ee/mr_pylin)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "\n",
    "<div style=\"display:flex; margin-top:50px;\">\n",
    "   <div style=\"width:20%; margin-right:auto; margin-left:auto;\">\n",
    "      <table style=\"margin:0 auto; width:80%; text-align:center\">\n",
    "         <caption style=\"font-weight:bold;\">Dataset</caption>\n",
    "         <thead>\n",
    "            <tr>\n",
    "               <th style=\"width:25%;\"><span style=\"color:magenta;\">#</span></th>\n",
    "               <th style=\"width:25%;\"><span style=\"color:#9090ff;\">x<sub>1</sub></span></th>\n",
    "               <th style=\"width:25%;\"><span style=\"color:red;\">y</span></th>\n",
    "            </tr>\n",
    "         </thead>\n",
    "         <tbody>\n",
    "            <tr><th>1</th><td>1</td><td>2</td></tr>\n",
    "            <tr><th>2</th><td>2</td><td>4</td></tr>\n",
    "            <tr><th>3</th><td>3</td><td>6</td></tr>\n",
    "            <tr><th>4</th><td>4</td><td>8</td></tr>\n",
    "            <tr><th>5</th><td>5</td><td>10</td></tr>\n",
    "            <tr><th>6</th><td>6</td><td>12</td></tr>\n",
    "            <tr><th>7</th><td>7</td><td>14</td></tr>\n",
    "         </tbody>\n",
    "      </table>\n",
    "   </div>\n",
    "   <div style=\"width:80%; padding:10px;\">\n",
    "      <figure style=\"text-align:center; margin:0;\">\n",
    "         <img src=\"../assets/images/original/perceptron/linear-regression.svg\" alt=\"linear-regression.svg\" style=\"max-width:80%; height:auto;\">\n",
    "         <figcaption style=\"font-size:smaller; text-align:center;\">Linear Regression Model</figcaption>\n",
    "      </figure>\n",
    "   </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torch.tensor(\n",
    "    [\n",
    "        [1, 2],\n",
    "        [2, 4],\n",
    "        [3, 6],\n",
    "        [4, 8],\n",
    "        [5, 10],\n",
    "        [6, 12],\n",
    "        [7, 14]\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train: tensor([1., 2., 3., 4., 5.])\n",
      "y_train: tensor([ 2.,  4.,  6.,  8., 10.])\n"
     ]
    }
   ],
   "source": [
    "trainset = dataset[:5]\n",
    "\n",
    "x_train = trainset[:, 0].type(torch.float32)\n",
    "y_train = trainset[:, 1].type(torch.float32)\n",
    "\n",
    "# log\n",
    "print(f\"x_train: {x_train}\")\n",
    "print(f\"y_train: {y_train}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_test: tensor([6., 7.])\n",
      "y_test: tensor([12., 14.])\n"
     ]
    }
   ],
   "source": [
    "testset = dataset[5:]\n",
    "\n",
    "x_test = testset[:, 0].type(torch.float32)\n",
    "y_test = testset[:, 1].type(torch.float32)\n",
    "\n",
    "# log\n",
    "print(f\"x_test: {x_test}\")\n",
    "print(f\"y_test: {y_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "plt.scatter(trainset[:, 0], trainset[:, 1], c='blue')\n",
    "plt.scatter(testset[:, 0], testset[:, 1], c='red')\n",
    "plt.title(\"f(x) = 2x\")\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation 1\n",
    "<ul>\n",
    "    <li style=\"font-family: consolas;\">feed-forward &nbsp;&nbsp;&nbsp;&nbsp;: <span style=\"color: red\">Manual</span></li>\n",
    "    <li style=\"font-family: consolas;\">compute gradient : <span style=\"color: red\">Manual</span></li>\n",
    "    <li style=\"font-family: consolas;\">compute loss &nbsp;&nbsp;&nbsp;&nbsp;: <span style=\"color: red\">Manual</span></li>\n",
    "    <li style=\"font-family: consolas;\">update weights &nbsp;&nbsp;: <span style=\"color: red\">Manual</span></li>\n",
    "    \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0 -> loss= 44.00000 | w_old= 0.000 | step= -0.44000 | w_new= 0.440 | y_test= tensor([2.6400, 3.0800])\n",
      "epoch:  1 -> loss= 26.76960 | w_old= 0.440 | step= -0.34320 | w_new= 0.783 | y_test= tensor([4.6992, 5.4824])\n",
      "epoch:  2 -> loss= 16.28662 | w_old= 0.783 | step= -0.26770 | w_new= 1.051 | y_test= tensor([6.3054, 7.3563])\n",
      "epoch:  3 -> loss=  9.90878 | w_old= 1.051 | step= -0.20880 | w_new= 1.260 | y_test= tensor([7.5582, 8.8179])\n",
      "epoch:  4 -> loss=  6.02850 | w_old= 1.260 | step= -0.16287 | w_new= 1.423 | y_test= tensor([8.5354, 9.9580])\n",
      "epoch:  5 -> loss=  3.66774 | w_old= 1.423 | step= -0.12704 | w_new= 1.550 | y_test= tensor([ 9.2976, 10.8472])\n",
      "epoch:  6 -> loss=  2.23145 | w_old= 1.550 | step= -0.09909 | w_new= 1.649 | y_test= tensor([ 9.8921, 11.5408])\n",
      "epoch:  7 -> loss=  1.35762 | w_old= 1.649 | step= -0.07729 | w_new= 1.726 | y_test= tensor([10.3559, 12.0818])\n",
      "epoch:  8 -> loss=  0.82597 | w_old= 1.726 | step= -0.06029 | w_new= 1.786 | y_test= tensor([10.7176, 12.5038])\n",
      "epoch:  9 -> loss=  0.50252 | w_old= 1.786 | step= -0.04702 | w_new= 1.833 | y_test= tensor([10.9997, 12.8330])\n",
      "epoch: 10 -> loss=  0.30573 | w_old= 1.833 | step= -0.03668 | w_new= 1.870 | y_test= tensor([11.2198, 13.0897])\n",
      "epoch: 11 -> loss=  0.18601 | w_old= 1.870 | step= -0.02861 | w_new= 1.899 | y_test= tensor([11.3914, 13.2900])\n",
      "epoch: 12 -> loss=  0.11317 | w_old= 1.899 | step= -0.02231 | w_new= 1.921 | y_test= tensor([11.5253, 13.4462])\n",
      "epoch: 13 -> loss=  0.06885 | w_old= 1.921 | step= -0.01741 | w_new= 1.938 | y_test= tensor([11.6297, 13.5680])\n",
      "epoch: 14 -> loss=  0.04189 | w_old= 1.938 | step= -0.01358 | w_new= 1.952 | y_test= tensor([11.7112, 13.6631])\n",
      "epoch: 15 -> loss=  0.02549 | w_old= 1.952 | step= -0.01059 | w_new= 1.962 | y_test= tensor([11.7747, 13.7372])\n",
      "epoch: 16 -> loss=  0.01551 | w_old= 1.962 | step= -0.00826 | w_new= 1.971 | y_test= tensor([11.8243, 13.7950])\n",
      "epoch: 17 -> loss=  0.00943 | w_old= 1.971 | step= -0.00644 | w_new= 1.977 | y_test= tensor([11.8629, 13.8401])\n",
      "epoch: 18 -> loss=  0.00574 | w_old= 1.977 | step= -0.00503 | w_new= 1.982 | y_test= tensor([11.8931, 13.8753])\n",
      "epoch: 19 -> loss=  0.00349 | w_old= 1.982 | step= -0.00392 | w_new= 1.986 | y_test= tensor([11.9166, 13.9027])\n"
     ]
    }
   ],
   "source": [
    "# initial weight\n",
    "w = torch.tensor([0.0])\n",
    "\n",
    "# feed-forward\n",
    "def forward(x):\n",
    "    return w * x\n",
    "\n",
    "# MSE loss\n",
    "def loss(y_pred, y_train):\n",
    "    return ((y_pred - y_train) ** 2).mean()\n",
    "\n",
    "# backward\n",
    "def gradient(x, y_pred, y_train):\n",
    "    # MSE   = 1/N * (w*x - y) ** 2\n",
    "    # dl/dw = 1/N * 2x * (w*x - y)\n",
    "    return (2 * x * (y_pred - y_train)).mean()\n",
    "\n",
    "# hyper parameters\n",
    "lr = 0.01\n",
    "epoch = 20\n",
    "\n",
    "for i in range(epoch):\n",
    "\n",
    "    # forward\n",
    "    y_pred = forward(x_train)\n",
    "\n",
    "    # backward\n",
    "    l = loss(y_pred, y_train)\n",
    "    dw = gradient(x_train, y_pred, y_train)\n",
    "\n",
    "    # update parameters\n",
    "    w -= lr * dw\n",
    "\n",
    "    # test\n",
    "    y_pred = forward(x_test)\n",
    "\n",
    "    # log\n",
    "    print(f\"epoch: {i:>2} -> loss={l:>9.5f} | w_old= {(w + lr * dw).item():.3f} | step= {(lr * dw).item():.5f} | w_new= {w.item():.3f} | y_test= {y_pred.round(decimals=4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation 2\n",
    "<ul>\n",
    "    <li style=\"font-family: consolas;\">feed-forward &nbsp;&nbsp;&nbsp;&nbsp;: <span style=\"color: red\">Manual</span></li>\n",
    "    <li style=\"font-family: consolas;\">compute gradient : <span style=\"color: cyan\">PyTorch</span></li>\n",
    "    <li style=\"font-family: consolas;\">compute loss &nbsp;&nbsp;&nbsp;&nbsp;: <span style=\"color: red\">Manual</span></li>\n",
    "    <li style=\"font-family: consolas;\">update weights &nbsp;&nbsp;: <span style=\"color: red\">Manual</span></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0 -> loss= 44.00000 | w_old= 0.000 | step= -0.44000 | w_new= 0.440 | y_test= tensor([2.6400, 3.0800])\n",
      "epoch:  1 -> loss= 26.76960 | w_old= 0.440 | step= -0.34320 | w_new= 0.783 | y_test= tensor([4.6992, 5.4824])\n",
      "epoch:  2 -> loss= 16.28662 | w_old= 0.783 | step= -0.26770 | w_new= 1.051 | y_test= tensor([6.3054, 7.3563])\n",
      "epoch:  3 -> loss=  9.90878 | w_old= 1.051 | step= -0.20880 | w_new= 1.260 | y_test= tensor([7.5582, 8.8179])\n",
      "epoch:  4 -> loss=  6.02850 | w_old= 1.260 | step= -0.16287 | w_new= 1.423 | y_test= tensor([8.5354, 9.9580])\n",
      "epoch:  5 -> loss=  3.66774 | w_old= 1.423 | step= -0.12704 | w_new= 1.550 | y_test= tensor([ 9.2976, 10.8472])\n",
      "epoch:  6 -> loss=  2.23145 | w_old= 1.550 | step= -0.09909 | w_new= 1.649 | y_test= tensor([ 9.8921, 11.5408])\n",
      "epoch:  7 -> loss=  1.35762 | w_old= 1.649 | step= -0.07729 | w_new= 1.726 | y_test= tensor([10.3559, 12.0818])\n",
      "epoch:  8 -> loss=  0.82597 | w_old= 1.726 | step= -0.06029 | w_new= 1.786 | y_test= tensor([10.7176, 12.5038])\n",
      "epoch:  9 -> loss=  0.50252 | w_old= 1.786 | step= -0.04702 | w_new= 1.833 | y_test= tensor([10.9997, 12.8330])\n",
      "epoch: 10 -> loss=  0.30573 | w_old= 1.833 | step= -0.03668 | w_new= 1.870 | y_test= tensor([11.2198, 13.0897])\n",
      "epoch: 11 -> loss=  0.18601 | w_old= 1.870 | step= -0.02861 | w_new= 1.899 | y_test= tensor([11.3914, 13.2900])\n",
      "epoch: 12 -> loss=  0.11317 | w_old= 1.899 | step= -0.02231 | w_new= 1.921 | y_test= tensor([11.5253, 13.4462])\n",
      "epoch: 13 -> loss=  0.06885 | w_old= 1.921 | step= -0.01741 | w_new= 1.938 | y_test= tensor([11.6297, 13.5680])\n",
      "epoch: 14 -> loss=  0.04189 | w_old= 1.938 | step= -0.01358 | w_new= 1.952 | y_test= tensor([11.7112, 13.6631])\n",
      "epoch: 15 -> loss=  0.02549 | w_old= 1.952 | step= -0.01059 | w_new= 1.962 | y_test= tensor([11.7747, 13.7372])\n",
      "epoch: 16 -> loss=  0.01551 | w_old= 1.962 | step= -0.00826 | w_new= 1.971 | y_test= tensor([11.8243, 13.7950])\n",
      "epoch: 17 -> loss=  0.00943 | w_old= 1.971 | step= -0.00644 | w_new= 1.977 | y_test= tensor([11.8629, 13.8401])\n",
      "epoch: 18 -> loss=  0.00574 | w_old= 1.977 | step= -0.00503 | w_new= 1.982 | y_test= tensor([11.8931, 13.8753])\n",
      "epoch: 19 -> loss=  0.00349 | w_old= 1.982 | step= -0.00392 | w_new= 1.986 | y_test= tensor([11.9166, 13.9027])\n"
     ]
    }
   ],
   "source": [
    "# initial weight\n",
    "w = torch.tensor([0.0], requires_grad=True)\n",
    "\n",
    "# feed-forward\n",
    "def forward(x):\n",
    "    return w * x\n",
    "\n",
    "# MSE loss\n",
    "def loss(y_pred, y_train):\n",
    "    return ((y_pred - y_train) ** 2).mean()\n",
    "\n",
    "# hyper parameters\n",
    "lr = 0.01\n",
    "epoch = 20\n",
    "\n",
    "for i in range(epoch):\n",
    "\n",
    "    # forward\n",
    "    y_pred = forward(x_train)\n",
    "\n",
    "    # backward\n",
    "    l = loss(y_pred, y_train)\n",
    "    l.backward()\n",
    "\n",
    "    # update parameters\n",
    "    with torch.no_grad():\n",
    "        w -= lr * w.grad\n",
    "\n",
    "    # test\n",
    "    with torch.no_grad():\n",
    "        y_pred = forward(x_test)\n",
    "\n",
    "    # log\n",
    "    print(f\"epoch: {i:>2} -> loss={l:>9.5f} | w_old= {(w + lr * w.grad).item():.3f} | step= {(lr * w.grad).item():.5f} | w_new= {w.item():.3f} | y_test= {y_pred.round(decimals=4).detach()}\")\n",
    "\n",
    "    # remove previous gradients\n",
    "    w.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation 3\n",
    "<ul>\n",
    "    <li style=\"font-family: consolas;\">feed-forward &nbsp;&nbsp;&nbsp;&nbsp;: <span style=\"color: red\">Manual</span></li>\n",
    "    <li style=\"font-family: consolas;\">compute gradient : <span style=\"color: cyan\">PyTorch</span></li>\n",
    "    <li style=\"font-family: consolas;\">compute loss &nbsp;&nbsp;&nbsp;&nbsp;: <span style=\"color: cyan\">PyTorch</span></li>\n",
    "    <li style=\"font-family: consolas;\">update weights &nbsp;&nbsp;: <span style=\"color: cyan\">PyTorch</span></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0 -> loss= 44.00000 | w_old= 0.000 | step= -0.44000 | w_new= 0.440 | y_test= tensor([2.6400, 3.0800])\n",
      "epoch:  1 -> loss= 26.76960 | w_old= 0.440 | step= -0.34320 | w_new= 0.783 | y_test= tensor([4.6992, 5.4824])\n",
      "epoch:  2 -> loss= 16.28662 | w_old= 0.783 | step= -0.26770 | w_new= 1.051 | y_test= tensor([6.3054, 7.3563])\n",
      "epoch:  3 -> loss=  9.90878 | w_old= 1.051 | step= -0.20880 | w_new= 1.260 | y_test= tensor([7.5582, 8.8179])\n",
      "epoch:  4 -> loss=  6.02850 | w_old= 1.260 | step= -0.16287 | w_new= 1.423 | y_test= tensor([8.5354, 9.9580])\n",
      "epoch:  5 -> loss=  3.66774 | w_old= 1.423 | step= -0.12704 | w_new= 1.550 | y_test= tensor([ 9.2976, 10.8472])\n",
      "epoch:  6 -> loss=  2.23145 | w_old= 1.550 | step= -0.09909 | w_new= 1.649 | y_test= tensor([ 9.8921, 11.5408])\n",
      "epoch:  7 -> loss=  1.35762 | w_old= 1.649 | step= -0.07729 | w_new= 1.726 | y_test= tensor([10.3559, 12.0818])\n",
      "epoch:  8 -> loss=  0.82597 | w_old= 1.726 | step= -0.06029 | w_new= 1.786 | y_test= tensor([10.7176, 12.5038])\n",
      "epoch:  9 -> loss=  0.50252 | w_old= 1.786 | step= -0.04702 | w_new= 1.833 | y_test= tensor([10.9997, 12.8330])\n",
      "epoch: 10 -> loss=  0.30573 | w_old= 1.833 | step= -0.03668 | w_new= 1.870 | y_test= tensor([11.2198, 13.0897])\n",
      "epoch: 11 -> loss=  0.18601 | w_old= 1.870 | step= -0.02861 | w_new= 1.899 | y_test= tensor([11.3914, 13.2900])\n",
      "epoch: 12 -> loss=  0.11317 | w_old= 1.899 | step= -0.02231 | w_new= 1.921 | y_test= tensor([11.5253, 13.4462])\n",
      "epoch: 13 -> loss=  0.06885 | w_old= 1.921 | step= -0.01741 | w_new= 1.938 | y_test= tensor([11.6297, 13.5680])\n",
      "epoch: 14 -> loss=  0.04189 | w_old= 1.938 | step= -0.01358 | w_new= 1.952 | y_test= tensor([11.7112, 13.6631])\n",
      "epoch: 15 -> loss=  0.02549 | w_old= 1.952 | step= -0.01059 | w_new= 1.962 | y_test= tensor([11.7747, 13.7372])\n",
      "epoch: 16 -> loss=  0.01551 | w_old= 1.962 | step= -0.00826 | w_new= 1.971 | y_test= tensor([11.8243, 13.7950])\n",
      "epoch: 17 -> loss=  0.00943 | w_old= 1.971 | step= -0.00644 | w_new= 1.977 | y_test= tensor([11.8629, 13.8401])\n",
      "epoch: 18 -> loss=  0.00574 | w_old= 1.977 | step= -0.00503 | w_new= 1.982 | y_test= tensor([11.8931, 13.8753])\n",
      "epoch: 19 -> loss=  0.00349 | w_old= 1.982 | step= -0.00392 | w_new= 1.986 | y_test= tensor([11.9166, 13.9027])\n"
     ]
    }
   ],
   "source": [
    "# initial weight\n",
    "w = torch.tensor([0.0], requires_grad=True)\n",
    "\n",
    "# feed-forward\n",
    "def forward(x):\n",
    "    return w * x\n",
    "\n",
    "# hyper parameters\n",
    "lr = 0.01\n",
    "epoch = 20\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD([w], lr)\n",
    "\n",
    "for i in range(epoch):\n",
    "\n",
    "    # forward\n",
    "    y_pred = forward(x_train)\n",
    "\n",
    "    # backward\n",
    "    l = criterion(y_pred, y_train)\n",
    "    l.backward()\n",
    "\n",
    "    # update parameters\n",
    "    optimizer.step()\n",
    "\n",
    "    # test\n",
    "    with torch.no_grad():\n",
    "        y_pred = forward(x_test)\n",
    "\n",
    "    # log\n",
    "    print(f\"epoch: {i:>2} -> loss={l:>9.5f} | w_old= {(w + lr * w.grad).item():.3f} | step= {(lr * w.grad).item():.5f} | w_new= {w.item():.3f} | y_test= {y_pred.round(decimals=4).detach()}\")\n",
    "\n",
    "    # remove previous gradients\n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation 4\n",
    "<ul>\n",
    "    <li style=\"font-family: consolas;\">feed-forward &nbsp;&nbsp;&nbsp;&nbsp;: <span style=\"color: cyan\">PyTorch</span></li>\n",
    "    <li style=\"font-family: consolas;\">compute gradient : <span style=\"color: cyan\">PyTorch</span></li>\n",
    "    <li style=\"font-family: consolas;\">compute loss &nbsp;&nbsp;&nbsp;&nbsp;: <span style=\"color: cyan\">PyTorch</span></li>\n",
    "    <li style=\"font-family: consolas;\">update weights &nbsp;&nbsp;: <span style=\"color: cyan\">PyTorch</span></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0 -> loss= 44.00000 | w_old= 0.000 | step= -0.44000 | w_new= 0.440 | y_test= tensor([2.6400, 3.0800])\n",
      "epoch:  1 -> loss= 26.76960 | w_old= 0.440 | step= -0.34320 | w_new= 0.783 | y_test= tensor([4.6992, 5.4824])\n",
      "epoch:  2 -> loss= 16.28662 | w_old= 0.783 | step= -0.26770 | w_new= 1.051 | y_test= tensor([6.3054, 7.3563])\n",
      "epoch:  3 -> loss=  9.90878 | w_old= 1.051 | step= -0.20880 | w_new= 1.260 | y_test= tensor([7.5582, 8.8179])\n",
      "epoch:  4 -> loss=  6.02850 | w_old= 1.260 | step= -0.16287 | w_new= 1.423 | y_test= tensor([8.5354, 9.9580])\n",
      "epoch:  5 -> loss=  3.66774 | w_old= 1.423 | step= -0.12704 | w_new= 1.550 | y_test= tensor([ 9.2976, 10.8472])\n",
      "epoch:  6 -> loss=  2.23145 | w_old= 1.550 | step= -0.09909 | w_new= 1.649 | y_test= tensor([ 9.8921, 11.5408])\n",
      "epoch:  7 -> loss=  1.35762 | w_old= 1.649 | step= -0.07729 | w_new= 1.726 | y_test= tensor([10.3559, 12.0818])\n",
      "epoch:  8 -> loss=  0.82597 | w_old= 1.726 | step= -0.06029 | w_new= 1.786 | y_test= tensor([10.7176, 12.5038])\n",
      "epoch:  9 -> loss=  0.50252 | w_old= 1.786 | step= -0.04702 | w_new= 1.833 | y_test= tensor([10.9997, 12.8330])\n",
      "epoch: 10 -> loss=  0.30573 | w_old= 1.833 | step= -0.03668 | w_new= 1.870 | y_test= tensor([11.2198, 13.0897])\n",
      "epoch: 11 -> loss=  0.18601 | w_old= 1.870 | step= -0.02861 | w_new= 1.899 | y_test= tensor([11.3914, 13.2900])\n",
      "epoch: 12 -> loss=  0.11317 | w_old= 1.899 | step= -0.02231 | w_new= 1.921 | y_test= tensor([11.5253, 13.4462])\n",
      "epoch: 13 -> loss=  0.06885 | w_old= 1.921 | step= -0.01741 | w_new= 1.938 | y_test= tensor([11.6297, 13.5680])\n",
      "epoch: 14 -> loss=  0.04189 | w_old= 1.938 | step= -0.01358 | w_new= 1.952 | y_test= tensor([11.7112, 13.6631])\n",
      "epoch: 15 -> loss=  0.02549 | w_old= 1.952 | step= -0.01059 | w_new= 1.962 | y_test= tensor([11.7747, 13.7372])\n",
      "epoch: 16 -> loss=  0.01551 | w_old= 1.962 | step= -0.00826 | w_new= 1.971 | y_test= tensor([11.8243, 13.7950])\n",
      "epoch: 17 -> loss=  0.00943 | w_old= 1.971 | step= -0.00644 | w_new= 1.977 | y_test= tensor([11.8629, 13.8401])\n",
      "epoch: 18 -> loss=  0.00574 | w_old= 1.977 | step= -0.00503 | w_new= 1.982 | y_test= tensor([11.8931, 13.8753])\n",
      "epoch: 19 -> loss=  0.00349 | w_old= 1.982 | step= -0.00392 | w_new= 1.986 | y_test= tensor([11.9166, 13.9027])\n"
     ]
    }
   ],
   "source": [
    "# reshape dataset [row: num of samples - column: num of features]\n",
    "x_train, x_test, y_train, y_test = map(lambda x: x.reshape(-1, 1), [x_train, x_test, y_train, y_test])\n",
    "\n",
    "# linear regression model\n",
    "model = torch.nn.Linear(in_features=1, out_features=1, bias=False)\n",
    "\n",
    "# initial weight [educational purpose]\n",
    "with torch.no_grad():\n",
    "    model.weight.fill_(0.0)\n",
    "\n",
    "# hyper parameters\n",
    "lr = 0.01\n",
    "epoch = 20\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr)\n",
    "\n",
    "for i in range(epoch):\n",
    "\n",
    "    # forward\n",
    "    y_pred = model(x_train)\n",
    "\n",
    "    # backward\n",
    "    l = criterion(y_pred, y_train)\n",
    "    l.backward()\n",
    "\n",
    "    # update parameters\n",
    "    optimizer.step()\n",
    "\n",
    "    # test\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(x_test)\n",
    "\n",
    "    # log\n",
    "    print(f\"epoch: {i:>2} -> loss={l:>9.5f} | w_old= {(model.weight + lr * model.weight.grad).item():.3f} | step= {(lr * model.weight.grad).item():.5f} | w_new= {model.weight.item():.3f} | y_test= {y_pred.squeeze().round(decimals=4).detach()}\")\n",
    "\n",
    "    # remove previous gradients\n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: All In One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate artificial data\n",
    "n_samples, n_features = [100, 1]\n",
    "\n",
    "x, y = datasets.make_regression(n_samples, n_features, noise=5, random_state=42)\n",
    "\n",
    "# convert numpy.ndarray to torch.Tensor\n",
    "x_train = torch.from_numpy(x.astype(np.float32))\n",
    "y_train = torch.from_numpy(y.astype(np.float32)).view(-1, 1)\n",
    "\n",
    "# plot\n",
    "plt.scatter(x, y)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=1, out_features=1, bias=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# linear regression model\n",
    "model = torch.nn.Linear(n_features, 1)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot stuff\n",
    "W = torch.linspace(-100, 100, 500)\n",
    "L = torch.zeros(size=(500, ))\n",
    "\n",
    "for i, val in enumerate(W):\n",
    "    with torch.no_grad():\n",
    "        model.weight.fill_(val)\n",
    "        L[i] = loss(model(x_train), y_train)\n",
    "\n",
    "state = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0 -> loss: 3843.91992\n",
      "epoch:  1 -> loss: 3230.75024\n",
      "epoch:  2 -> loss: 2717.45850\n",
      "epoch:  3 -> loss: 2287.48486\n",
      "epoch:  4 -> loss: 1927.06812\n",
      "epoch:  5 -> loss: 1624.76355\n",
      "epoch:  6 -> loss: 1371.04517\n",
      "epoch:  7 -> loss: 1157.97668\n",
      "epoch:  8 -> loss:  978.94220\n",
      "epoch:  9 -> loss:  828.42169\n",
      "epoch: 10 -> loss:  701.80615\n",
      "epoch: 11 -> loss:  595.24371\n",
      "epoch: 12 -> loss:  505.51407\n",
      "epoch: 13 -> loss:  429.92212\n",
      "epoch: 14 -> loss:  366.21118\n",
      "epoch: 15 -> loss:  312.49017\n",
      "epoch: 16 -> loss:  267.17368\n",
      "epoch: 17 -> loss:  228.93135\n",
      "epoch: 18 -> loss:  196.64642\n",
      "epoch: 19 -> loss:  169.38078\n",
      "epoch: 20 -> loss:  146.34596\n"
     ]
    }
   ],
   "source": [
    "# initial weight [educational purpose]\n",
    "with torch.no_grad():\n",
    "    model.weight.fill_(-25)\n",
    "\n",
    "# hyper parameters\n",
    "epoch = 21\n",
    "lr = 0.05\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "loss = torch.nn.MSELoss()\n",
    "\n",
    "# training loop\n",
    "model.train()\n",
    "for i in range(epoch):\n",
    "\n",
    "    # forward\n",
    "    y_pred = model(x_train)\n",
    "\n",
    "    # backward\n",
    "    l = loss(y_pred, y_train)\n",
    "    l.backward()\n",
    "\n",
    "    # save new y_pred every 5 epochs [plot stuff]\n",
    "    if i % 5 == 0:\n",
    "        state.append([i, model.weight.item(), l.item(), y_pred.detach().numpy()])\n",
    "\n",
    "    # update parameters\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # log\n",
    "    print(f\"epoch: {i:>2} -> loss: {l.item():>10.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "rows = epoch // 5 + 1\n",
    "fig, axs = plt.subplots(nrows=rows, ncols=2, figsize=(10, 20), layout='compressed')\n",
    "\n",
    "for row in range(rows):\n",
    "    axs[row, 0].plot(x_train, y_train, 'ro')\n",
    "    axs[row, 0].plot(x_train, state[row][3], 'b')\n",
    "    axs[row, 0].set(title=f\"epoch: {state[row][0]}\", xlabel=\"x\", ylabel=\"f(x)\")\n",
    "    axs[row, 1].plot(state[row][1], state[row][2], 'ro')\n",
    "    axs[row, 1].plot(W, L, 'b')\n",
    "    axs[row, 1].set(title=\"loss function\", xlabel=\"w\", ylabel=\"L(w)\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "author_email": "AmirhosseinHeydari78@gmail.com",
  "author_github": "https://github.com/mr-pylin",
  "author_name": "Amirhossein Heydari",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "origin_repo": "https://github.com/mr-pylin/pytorch-workshop"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
