{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìù **Author:** Amirhossein Heydari - üìß **Email:** amirhosseinheydari78@gmail.com - üìç **Linktree:** [linktr.ee/mr_pylin](https://linktr.ee/mr_pylin)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set a seed for deterministic results\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "<div style=\"display:flex; margin-top:50px;\">\n",
    "   <div style=\"width:20%; margin-right:auto; margin-left:auto;\">\n",
    "      <table style=\"margin:0 auto; width:80%; text-align:center\">\n",
    "         <caption style=\"font-weight:bold;\">Dataset</caption>\n",
    "         <thead>\n",
    "            <tr>\n",
    "               <th style=\"width:25%; text-align:center\"><span style=\"color:magenta;\">#</span></th>\n",
    "               <th style=\"width:25%; text-align:center\"><span style=\"color:#9090ff;\">x<sub>1</sub></span></th>\n",
    "               <th style=\"width:25%; text-align:center\"><span style=\"color:#9090ff;\">x<sub>2</sub></span></th>\n",
    "               <th style=\"width:25%; text-align:center\"><span style=\"color:red;\">y</span></th>\n",
    "            </tr>\n",
    "         </thead>\n",
    "         <tbody>\n",
    "            <tr><th>1</th><td>1</td><td>1</td><td>0</td></tr>\n",
    "            <tr><th>2</th><td>2</td><td>3</td><td>1</td></tr>\n",
    "            <tr><th>3</th><td>1</td><td>2</td><td>0</td></tr>\n",
    "            <tr><th>4</th><td>3</td><td>1</td><td>0</td></tr>\n",
    "            <tr><th>5</th><td>2</td><td>4</td><td>1</td></tr>\n",
    "            <tr><th>6</th><td>3</td><td>2</td><td>1</td></tr>\n",
    "            <tr><th>7</th><td>4</td><td>1</td><td>1</td></tr>\n",
    "         </tbody>\n",
    "      </table>\n",
    "   </div>\n",
    "   <div style=\"width:80%; padding:10px;\">\n",
    "      <figure style=\"text-align:center; margin:0;\">\n",
    "         <img src=\"../assets/images/original/perceptron/logistic-regression.svg\" alt=\"logistic-regression.svg\" style=\"max-width:80%; height:auto;\">\n",
    "         <figcaption style=\"font-size:smaller; text-align:center;\">Logistic Regression Model</figcaption>\n",
    "      </figure>\n",
    "   </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate artificial data\n",
    "n_samples, n_features = 10, 2\n",
    "\n",
    "x, y = datasets.make_classification(\n",
    "    n_samples=n_samples,\n",
    "    n_features=n_features,\n",
    "    n_informative=2,\n",
    "    n_redundant=0,\n",
    "    n_clusters_per_class=1,\n",
    "    random_state=seed,\n",
    ")\n",
    "\n",
    "# convert numpy.ndarray to torch.Tensor\n",
    "x_train = torch.from_numpy(x.astype(np.float32))\n",
    "y_train = torch.from_numpy(y.astype(np.float32)).view(-1, 1)\n",
    "\n",
    "# plot\n",
    "plt.scatter(x[y == 0][:, 0], x[y == 0][:, 1], color=\"b\", label=\"Class 0\")\n",
    "plt.scatter(x[y == 1][:, 0], x[y == 1][:, 1], color=\"r\", label=\"Class 1\")\n",
    "plt.xlabel(\"x_1\")\n",
    "plt.ylabel(\"x_2\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression model\n",
    "model = torch.nn.Sequential(torch.nn.Linear(n_features, 1), torch.nn.Sigmoid())\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot stuff\n",
    "state = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial weights [educational purpose]\n",
    "with torch.no_grad():\n",
    "    # b [w_0] = +1\n",
    "    model[0].bias[0].fill_(1)\n",
    "\n",
    "    # w_1 = -1\n",
    "    model[0].weight[0, 0].fill_(-1)\n",
    "\n",
    "    # w_2 = +1\n",
    "    model[0].weight[0, 1].fill_(1)\n",
    "\n",
    "# hyper parameters\n",
    "epoch = 6\n",
    "lr = 0.5\n",
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "# training loop\n",
    "model.train()\n",
    "for i in range(epoch):\n",
    "\n",
    "    # forward\n",
    "    y_pred = model(x_train)\n",
    "\n",
    "    # backward\n",
    "    loss = criterion(y_pred, y_train)\n",
    "    loss.backward()\n",
    "\n",
    "    # save new y_pred every 5 epochs [plot stuff]\n",
    "    state.append([model[0].weight.clone().detach().numpy(), model[0].bias.clone().detach().numpy()])\n",
    "\n",
    "    # update parameters\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # log\n",
    "    print(f\"epoch {i+1:0{len(str(epoch))}:>2}/{epoch}  ->  loss: {loss.item():>7.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "fig, axs = plt.subplots(nrows=3, ncols=2, figsize=(12, 16), layout=\"compressed\")\n",
    "\n",
    "for row in range(3):\n",
    "    for col in range(2):\n",
    "        axs[row, col].scatter(x[y == 0][:, 0], x[y == 0][:, 1], color=\"b\", label=\"Class 0\")\n",
    "        axs[row, col].scatter(x[y == 1][:, 0], x[y == 1][:, 1], color=\"r\", label=\"Class 1\")\n",
    "        axs[row, col].set(\n",
    "            title=f\"epoch {row * 2 + col}, W: {state[row * 2 + col][0].squeeze()}, b: {state[row * 2 + col][1].squeeze():.3f}\",\n",
    "            xlim=(x[:, 0].min() - 1, x[:, 0].max() + 1),\n",
    "            ylim=(x[:, 1].min() - 1, x[:, 1].max() + 1),\n",
    "        )\n",
    "\n",
    "        # decision boundary\n",
    "        w, b = state[row * 2 + col]\n",
    "        slope = -w[0][0] / w[0][1]\n",
    "        intercept = -b[0] / w[0][1]\n",
    "        x_plot = np.array([np.min(x[:, 0]), np.max(x[:, 0])])\n",
    "        y_plot = slope * x_plot + intercept\n",
    "\n",
    "        axs[row, col].plot(x_plot, y_plot, color=\"g\", linestyle=\"--\", label=\"Decision Boundary\")\n",
    "        axs[row, col].legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "author_email": "AmirhosseinHeydari78@gmail.com",
  "author_github": "https://github.com/mr-pylin",
  "author_name": "Amirhossein Heydari",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "origin_repo": "https://github.com/mr-pylin/pytorch-workshop"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
