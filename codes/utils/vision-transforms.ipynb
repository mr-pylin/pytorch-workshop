{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìù **Author:** Amirhossein Heydari - üìß **Email:** amirhosseinheydari78@gmail.com - üìç **Linktree:** [linktr.ee/mr_pylin](https://linktr.ee/mr_pylin)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.transforms import v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set a seed for deterministic results\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = CIFAR10(root=\"../../datasets\", train=True, transform=None, download=False)\n",
    "\n",
    "x = trainset.data[:3]\n",
    "y = trainset.targets[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(12, 4), layout=\"compressed\")\n",
    "for i, (img, label) in enumerate(zip(x, y)):\n",
    "    axs[i].imshow(img)\n",
    "    axs[i].set(title=label)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforms\n",
    "   - [pytorch.org/vision/main/transforms.html](https://pytorch.org/vision/main/transforms.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common Transformations\n",
    "   - v2.ToImage\n",
    "   - v2.ToDtype\n",
    "   - v2.Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log\n",
    "for i in range(len(x)):\n",
    "    print(f\"x[{i}].shape : {x[i].shape}\")\n",
    "    print(f\"x[{i}].dtype : {x[i].dtype}\")\n",
    "    print(f\"type(x[{i}]) : {type(x[i])}\")\n",
    "    print(f\"x[{i}].min() : {x[i].min()}\")\n",
    "    print(f\"x[{i}].max() : {x[i].max()}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### v2.ToImage\n",
    "   - [pytorch.org/vision/main/generated/torchvision.transforms.v2.ToImage.html](https://pytorch.org/vision/main/generated/torchvision.transforms.v2.ToImage.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_image_transform = v2.ToImage()\n",
    "x_2 = [to_image_transform(img) for img in x]\n",
    "\n",
    "# log\n",
    "for i in range(len(x)):\n",
    "    print(f\"x_2[{i}].shape : {x_2[i].shape}\")\n",
    "    print(f\"x_2[{i}].dtype : {x_2[i].dtype}\")\n",
    "    print(f\"type(x_2[{i}]) : {type(x_2[i])}\")\n",
    "    print(f\"x_2[{i}].min() : {x_2[i].min()}\")\n",
    "    print(f\"x_2[{i}].max() : {x_2[i].max()}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### v2.ToDtype\n",
    "   - [pytorch.org/vision/main/generated/torchvision.transforms.v2.ToDtype.html#torchvision.transforms.v2.ToDtype](https://pytorch.org/vision/main/generated/torchvision.transforms.v2.ToDtype.html#torchvision.transforms.v2.ToDtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_dtype_transform = v2.ToDtype(dtype=torch.float32, scale=True)\n",
    "x_3 = [to_dtype_transform(img) for img in x_2]\n",
    "\n",
    "# log\n",
    "for i in range(len(x)):\n",
    "    print(f\"x_3[{i}].shape: {x_3[i].shape}\")\n",
    "    print(f\"x_3[{i}].dtype: {x_3[i].dtype}\")\n",
    "    print(f\"type(x_3[{i}]): {type(x_3[i])}\")\n",
    "    print(f\"x_3[{i}].min(): {x_3[i].min()}\")\n",
    "    print(f\"x_3[{i}].max(): {x_3[i].max()}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### v2.Normalize\n",
    "   - [pytorch.org/vision/main/generated/torchvision.transforms.v2.Normalize.html#torchvision.transforms.v2.Normalize](https://pytorch.org/vision/main/generated/torchvision.transforms.v2.Normalize.html#torchvision.transforms.v2.Normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mus = np.array(x_3).mean(axis=(0, 2, 3))\n",
    "stds = np.array(x_3).std(axis=(0, 2, 3))\n",
    "\n",
    "normalize_transform = v2.Normalize(mean=mus, std=stds)\n",
    "x_4 = [normalize_transform(img) for img in x_3]\n",
    "\n",
    "# log\n",
    "for i in range(len(x)):\n",
    "    print(f\"x_4[{i}].shape: {x_4[i].shape}\")\n",
    "    print(f\"x_4[{i}].dtype: {x_4[i].dtype}\")\n",
    "    print(f\"type(x_4[{i}]): {type(x_4[i])}\")\n",
    "    print(f\"x_4[{i}].min(): {x_4[i].min()}\")\n",
    "    print(f\"x_4[{i}].max(): {x_4[i].max()}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "fig, axs = plt.subplots(nrows=2, ncols=3, figsize=(12, 8), layout=\"compressed\")\n",
    "for i, (img1, img2, label) in enumerate(zip(x, x_4, y)):\n",
    "    axs[0, i].imshow(img1)\n",
    "    axs[0, i].set(title=\"Original\")\n",
    "    axs[1, i].imshow(img2.permute(1, 2, 0))\n",
    "    axs[1, i].set(title=\"Normalize(ToDtype(ToImage()))\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation Techniques\n",
    "   - v2.RandomCrop\n",
    "   - v2.Resize\n",
    "   - v2.RandomVerticalFlip\n",
    "   - v2.RandomHorizontalFlip\n",
    "   - v2.RandomRotation\n",
    "   - v2.ColorJitter\n",
    "   - v2.RandomAffine\n",
    "   - ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### v2.RandomCrop\n",
    "   - [pytorch.org/vision/main/generated/torchvision.transforms.RandomCrop.html#torchvision.transforms.RandomCrop](https://pytorch.org/vision/main/generated/torchvision.transforms.RandomCrop.html#torchvision.transforms.RandomCrop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_crop_transform = v2.RandomCrop(size=(int(x_4[0].shape[1] / 4 * 3), int(x_4[0].shape[2] / 4 * 3)))\n",
    "x_5 = [random_crop_transform(img) for img in x_4]\n",
    "\n",
    "# log\n",
    "for i in range(len(x)):\n",
    "    print(f\"x_5[{i}].shape: {x_5[i].shape}\")\n",
    "    print(f\"x_5[{i}].dtype: {x_5[i].dtype}\")\n",
    "    print(f\"type(x_5[{i}]): {type(x_5[i])}\")\n",
    "    print(f\"x_5[{i}].min(): {x_5[i].min()}\")\n",
    "    print(f\"x_5[{i}].max(): {x_5[i].max()}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "fig, axs = plt.subplots(nrows=2, ncols=3, figsize=(12, 8), layout=\"compressed\")\n",
    "for i, (img1, img2, label) in enumerate(zip(x_4, x_5, y)):\n",
    "    axs[0, i].imshow(img1.permute(1, 2, 0))\n",
    "    axs[0, i].set(title=\"x_4\")\n",
    "    axs[1, i].imshow(img2.permute(1, 2, 0))\n",
    "    axs[1, i].set(title=\"v2.RandomCrop\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### v2.Resize\n",
    "   - [pytorch.org/vision/main/generated/torchvision.transforms.v2.Resize.html#torchvision.transforms.v2.Resize](https://pytorch.org/vision/main/generated/torchvision.transforms.v2.Resize.html#torchvision.transforms.v2.Resize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_transform = v2.Resize(size=(x[0].shape[0], x[0].shape[1]))\n",
    "x_6 = [resize_transform(img) for img in x_5]\n",
    "\n",
    "# log\n",
    "for i in range(len(x)):\n",
    "    print(f\"x_6[{i}].shape: {x_6[i].shape}\")\n",
    "    print(f\"x_6[{i}].dtype: {x_6[i].dtype}\")\n",
    "    print(f\"type(x_6[{i}]): {type(x_6[i])}\")\n",
    "    print(f\"x_6[{i}].min(): {x_6[i].min()}\")\n",
    "    print(f\"x_6[{i}].max(): {x_6[i].max()}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "fig, axs = plt.subplots(nrows=2, ncols=3, figsize=(12, 8), layout=\"compressed\")\n",
    "for i, (img1, img2, label) in enumerate(zip(x_5, x_6, y)):\n",
    "    axs[0, i].imshow(img1.permute(1, 2, 0))\n",
    "    axs[0, i].set(title=\"x_5\")\n",
    "    axs[1, i].imshow(img2.permute(1, 2, 0))\n",
    "    axs[1, i].set(title=\"v2.Resize\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### v2.RandomVerticalFlip\n",
    "   - [pytorch.org/vision/main/generated/torchvision.transforms.v2.RandomVerticalFlip.html#torchvision.transforms.v2.RandomVerticalFlip](https://pytorch.org/vision/main/generated/torchvision.transforms.v2.RandomVerticalFlip.html#torchvision.transforms.v2.RandomVerticalFlip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_verical_flip_transform = v2.RandomVerticalFlip(p=0.6)\n",
    "x_7 = [random_verical_flip_transform(img) for img in x_6]\n",
    "\n",
    "# log\n",
    "for i in range(len(x)):\n",
    "    print(f\"x_7[{i}].shape: {x_7[i].shape}\")\n",
    "    print(f\"x_7[{i}].dtype: {x_7[i].dtype}\")\n",
    "    print(f\"type(x_7[{i}]): {type(x_7[i])}\")\n",
    "    print(f\"x_7[{i}].min(): {x_7[i].min()}\")\n",
    "    print(f\"x_7[{i}].max(): {x_7[i].max()}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "fig, axs = plt.subplots(nrows=2, ncols=3, figsize=(12, 8), layout=\"compressed\")\n",
    "for i, (img1, img2, label) in enumerate(zip(x_6, x_7, y)):\n",
    "    axs[0, i].imshow(img1.permute(1, 2, 0))\n",
    "    axs[0, i].set(title=\"x_6\")\n",
    "    axs[1, i].imshow(img2.permute(1, 2, 0))\n",
    "    axs[1, i].set(title=\"v2.RandomVerticalFlip\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### v2.RandomHorizontalFlip\n",
    "   - [pytorch.org/vision/main/generated/torchvision.transforms.RandomHorizontalFlip.html#torchvision.transforms.RandomHorizontalFlip](https://pytorch.org/vision/main/generated/torchvision.transforms.RandomHorizontalFlip.html#torchvision.transforms.RandomHorizontalFlip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_horizontal_flip_transform = v2.RandomHorizontalFlip(p=0.7)\n",
    "x_8 = [random_horizontal_flip_transform(img) for img in x_7]\n",
    "\n",
    "# log\n",
    "for i in range(len(x)):\n",
    "    print(f\"x_8[{i}].shape: {x_8[i].shape}\")\n",
    "    print(f\"x_8[{i}].dtype: {x_8[i].dtype}\")\n",
    "    print(f\"type(x_8[{i}]): {type(x_8[i])}\")\n",
    "    print(f\"x_8[{i}].min(): {x_8[i].min()}\")\n",
    "    print(f\"x_8[{i}].max(): {x_8[i].max()}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "fig, axs = plt.subplots(nrows=2, ncols=3, figsize=(12, 8), layout=\"compressed\")\n",
    "for i, (img1, img2, label) in enumerate(zip(x_7, x_8, y)):\n",
    "    axs[0, i].imshow(img1.permute(1, 2, 0))\n",
    "    axs[0, i].set(title=\"x_7\")\n",
    "    axs[1, i].imshow(img2.permute(1, 2, 0))\n",
    "    axs[1, i].set(title=\"v2.RandomHorizontalFlip\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### v2.RandomRotation\n",
    "   - [pytorch.org/vision/main/generated/torchvision.transforms.v2.RandomRotation.html#torchvision.transforms.v2.RandomRotation](https://pytorch.org/vision/main/generated/torchvision.transforms.v2.RandomRotation.html#torchvision.transforms.v2.RandomRotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_rotation_transform = v2.RandomRotation(degrees=[0, 45])\n",
    "x_9 = [random_rotation_transform(img) for img in x_8]\n",
    "\n",
    "# log\n",
    "for i in range(len(x)):\n",
    "    print(f\"x_9[{i}].shape: {x_9[i].shape}\")\n",
    "    print(f\"x_9[{i}].dtype: {x_9[i].dtype}\")\n",
    "    print(f\"type(x_9[{i}]): {type(x_9[i])}\")\n",
    "    print(f\"x_9[{i}].min(): {x_9[i].min()}\")\n",
    "    print(f\"x_9[{i}].max(): {x_9[i].max()}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "fig, axs = plt.subplots(nrows=2, ncols=3, figsize=(12, 8), layout=\"compressed\")\n",
    "for i, (img1, img2, label) in enumerate(zip(x_8, x_9, y)):\n",
    "    axs[0, i].imshow(img1.permute(1, 2, 0))\n",
    "    axs[0, i].set(title=\"x_8\")\n",
    "    axs[1, i].imshow(img2.permute(1, 2, 0))\n",
    "    axs[1, i].set(title=\"v2.RandomRotation\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### v2.ColorJitter\n",
    "   - [pytorch.org/vision/main/generated/torchvision.transforms.ColorJitter.html#torchvision.transforms.ColorJitter](https://pytorch.org/vision/main/generated/torchvision.transforms.ColorJitter.html#torchvision.transforms.ColorJitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_jitter_transform = v2.ColorJitter(brightness=0.7, contrast=0.5, saturation=0.9, hue=0.3)\n",
    "x_10 = [color_jitter_transform(img) for img in x_9]\n",
    "\n",
    "# log\n",
    "for i in range(len(x)):\n",
    "    print(f\"x_10[{i}].shape: {x_10[i].shape}\")\n",
    "    print(f\"x_10[{i}].dtype: {x_10[i].dtype}\")\n",
    "    print(f\"type(x_10[{i}]): {type(x_10[i])}\")\n",
    "    print(f\"x_10[{i}].min(): {x_10[i].min()}\")\n",
    "    print(f\"x_10[{i}].max(): {x_10[i].max()}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "fig, axs = plt.subplots(nrows=2, ncols=3, figsize=(12, 8), layout=\"compressed\")\n",
    "for i, (img1, img2, label) in enumerate(zip(x_9, x_10, y)):\n",
    "    axs[0, i].imshow(img1.permute(1, 2, 0))\n",
    "    axs[0, i].set(title=\"x_9\")\n",
    "    axs[1, i].imshow(img2.permute(1, 2, 0))\n",
    "    axs[1, i].set(title=\"v2.ColorJitter\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### v2.RandomAffine\n",
    "   - [pytorch.org/vision/main/generated/torchvision.transforms.v2.RandomAffine.html#torchvision.transforms.v2.RandomAffine](https://pytorch.org/vision/main/generated/torchvision.transforms.v2.RandomAffine.html#torchvision.transforms.v2.RandomAffine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_affine_transform = v2.RandomAffine(degrees=0, shear=0.5, scale=[0.5, 1.5])\n",
    "x_11 = [random_affine_transform(img) for img in x_10]\n",
    "\n",
    "# log\n",
    "for i in range(len(x)):\n",
    "    print(f\"x_11[{i}].shape: {x_11[i].shape}\")\n",
    "    print(f\"x_11[{i}].dtype: {x_11[i].dtype}\")\n",
    "    print(f\"type(x_11[{i}]): {type(x_11[i])}\")\n",
    "    print(f\"x_11[{i}].min(): {x_11[i].min()}\")\n",
    "    print(f\"x_11[{i}].max(): {x_11[i].max()}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "fig, axs = plt.subplots(nrows=2, ncols=3, figsize=(12, 8), layout=\"compressed\")\n",
    "for i, (img1, img2, label) in enumerate(zip(x_10, x_11, y)):\n",
    "    axs[0, i].imshow(img1.permute(1, 2, 0))\n",
    "    axs[0, i].set(title=\"x_10\")\n",
    "    axs[1, i].imshow(img2.permute(1, 2, 0))\n",
    "    axs[1, i].set(title=\"v2.RandomAffine\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mix transforms\n",
    "   - v2.Compose\n",
    "      - [pytorch.org/vision/main/generated/torchvision.transforms.v2.Compose.html#torchvision.transforms.v2.Compose](https://pytorch.org/vision/main/generated/torchvision.transforms.v2.Compose.html#torchvision.transforms.v2.Compose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = v2.Compose(\n",
    "    [\n",
    "        v2.ToImage(),\n",
    "        v2.ToDtype(dtype=torch.float32, scale=True),\n",
    "        v2.Normalize(mean=mus, std=stds),\n",
    "        v2.RandomCrop(size=(int(x_4[0].shape[1] / 4 * 3), int(x_4[0].shape[2] / 4 * 3))),\n",
    "        v2.Resize(size=(x[0].shape[0], x[0].shape[1])),\n",
    "        v2.RandomVerticalFlip(p=0.6),\n",
    "        v2.RandomHorizontalFlip(p=0.7),\n",
    "        v2.RandomRotation(degrees=[0, 45]),\n",
    "        v2.ColorJitter(brightness=0.7, contrast=0.5, saturation=0.9, hue=0.3),\n",
    "        v2.RandomAffine(degrees=0, shear=0.5, scale=[0.5, 1.5]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_12 = [transforms(img) for img in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "fig, axs = plt.subplots(nrows=2, ncols=3, figsize=(12, 8), layout=\"compressed\")\n",
    "for i, (img1, img2, label) in enumerate(zip(x, x_12, y)):\n",
    "    axs[0, i].imshow(img1)\n",
    "    axs[0, i].set(title=\"x\")\n",
    "    axs[1, i].imshow(img2.permute(1, 2, 0))\n",
    "    axs[1, i].set(title=\"x_12\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Effect of transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch dataset\n",
    "trainset = CIFAR10(root=\"../../datasets\", train=True, transform=None, download=False)\n",
    "\n",
    "# pytorch subset\n",
    "num_samples = 10\n",
    "trainsubset = Subset(trainset, indices=range(num_samples))\n",
    "\n",
    "# log\n",
    "print(\"trainset:\")\n",
    "print(f\"\\tlen(trainset)          : {len(trainset)}\")\n",
    "print(f\"\\ttrainset.transform     : {trainset.transform}\")\n",
    "print(f\"\\ttype(trainset[0][0])   : {type(trainset[0][0])}\")\n",
    "print(f\"\\ttype(trainset[0][1])   : {type(trainset[0][1])}\")\n",
    "print(f\"\\ttype(trainset.data[0]) : {type(trainset.data[0])}\")\n",
    "print(\"-\" * 50)\n",
    "print(\"trainsubset:\")\n",
    "print(f\"\\tlen(trainsubset)             : {len(trainsubset)}\")\n",
    "print(f\"\\trainsubset.dataset.transform : {trainsubset.dataset.transform}\")\n",
    "print(f\"\\ttype(trainsubset[0][0])      : {type(trainsubset[0][0])}\")\n",
    "print(f\"\\ttype(trainsubset[0][1])      : {type(trainsubset[0][1])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = v2.Compose(\n",
    "    [\n",
    "        v2.ToImage(),\n",
    "        v2.ToDtype(torch.float32),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# add transforms to the dataset\n",
    "trainset.transform = transforms\n",
    "\n",
    "# log\n",
    "print(\"trainset:\")\n",
    "print(f\"\\tlen(trainset): {len(trainset)}\")\n",
    "print(f\"\\ttrainset.transform:\\n{trainset.transform}\")\n",
    "print(f\"\\ttype(trainset[0][0])   : {type(trainset[0][0])}\")\n",
    "print(f\"\\ttrainset[0][0].dtype   : {trainset[0][0].dtype}\")\n",
    "print(f\"\\ttype(trainset[0][1])   : {type(trainset[0][1])}\")\n",
    "print(f\"\\ttype(trainset.data[0]) : {type(trainset.data[0])}\")\n",
    "print(\"-\" * 50)\n",
    "print(\"trainsubset:\")\n",
    "print(f\"\\tlen(trainsubset): {len(trainsubset)}\")\n",
    "print(f\"\\ttrainsubset.dataset.transform:\\n{trainsubset.dataset.transform}\")\n",
    "print(f\"\\ttype(trainsubset[0][0]) : {type(trainsubset[0][0])}\")\n",
    "print(f\"\\ttrainsubset[0][0].dtype : {trainsubset[0][0].dtype}\")\n",
    "print(f\"\\ttype(trainsubset[0][1]) : {type(trainsubset[0][1])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch dataloader\n",
    "trainloader = DataLoader(trainsubset, batch_size=num_samples, shuffle=False)\n",
    "next_iter_trainloader = next(iter(trainloader))\n",
    "\n",
    "print(\"trainloader:\")\n",
    "print(f\"\\ttype(next_iter_trainloader[0]) : {type(next_iter_trainloader[0])}\")\n",
    "print(f\"\\tnext_iter_trainloader[0].dtype : {next_iter_trainloader[0].dtype}\")\n",
    "print(f\"\\ttype(next_iter_trainloader[1]) : {type(next_iter_trainloader[1])}\")\n",
    "print(f\"\\tnext_iter_trainloader[1].dtype : {next_iter_trainloader[1].dtype}\")"
   ]
  }
 ],
 "metadata": {
  "author_email": "AmirhosseinHeydari78@gmail.com",
  "author_github": "https://github.com/mr-pylin",
  "author_name": "Amirhossein Heydari",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "origin_repo": "https://github.com/mr-pylin/pytorch-workshop"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
