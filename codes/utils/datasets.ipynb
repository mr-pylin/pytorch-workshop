{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìù **Author:** Amirhossein Heydari - üìß **Email:** amirhosseinheydari78@gmail.com - üìç **Linktree:** [linktr.ee/mr_pylin](https://linktr.ee/mr_pylin)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "$\n",
    "X = \\begin{bmatrix}\n",
    "        x_{1}^1 & x_{1}^2 & \\cdots & x_{1}^n \\\\\n",
    "        x_{2}^1 & x_{2}^2 & \\cdots & x_{2}^n \\\\\n",
    "        \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "        x_{m}^1 & x_{m}^2 & \\cdots & x_{m}^n \\\\\n",
    "    \\end{bmatrix}_{m \\times n} \\quad \\text{(m: number of samples, n: number of features)}\n",
    "$\n",
    "\n",
    "$\n",
    "Y = \\begin{bmatrix}\n",
    "        y_{1} \\\\\n",
    "        y_{2} \\\\\n",
    "        \\vdots \\\\\n",
    "        y_{m} \\\\\n",
    "    \\end{bmatrix}_{m \\times 1} \\quad \\text{(m: number of samples)}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape: (150, 4)\n",
      "x.dtype: float64\n",
      "y.shape: (150,)\n",
      "y.dtype: int32\n",
      "--------------------------------------------------\n",
      "classes          : [0 1 2]\n",
      "samples per class: [50 50 50]\n"
     ]
    }
   ],
   "source": [
    "# load iris dataset\n",
    "x, y = load_iris(return_X_y=True)\n",
    "\n",
    "# properties of the dataset\n",
    "num_samples, num_features = x.shape\n",
    "classes, samples_per_class = np.unique(y, return_counts=True)\n",
    "\n",
    "# log\n",
    "for i in ['x', 'y']:\n",
    "    print(f\"{i}.shape: {eval(f'{i}.shape')}\")\n",
    "    print(f\"{i}.dtype: {eval(f'{i}.dtype')}\")\n",
    "print('-' * 50)\n",
    "print(f\"classes          : {classes}\")\n",
    "print(f\"samples per class: {samples_per_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape: torch.Size([150, 4])\n",
      "x.dtype: torch.float32\n",
      "x.ndim : 2\n",
      "\n",
      "y.shape: torch.Size([150, 1])\n",
      "y.dtype: torch.float32\n",
      "y.ndim : 2\n"
     ]
    }
   ],
   "source": [
    "# convert numpy.ndarray to torch.Tensor\n",
    "x = torch.from_numpy(x.astype(np.float32))\n",
    "y = torch.from_numpy(y.astype(np.float32)).view(-1, 1)\n",
    "\n",
    "# log\n",
    "print(f\"x.shape: {x.shape}\")\n",
    "print(f\"x.dtype: {x.dtype}\")\n",
    "print(f\"x.ndim : {x.ndim}\\n\")\n",
    "print(f\"y.shape: {y.shape}\")\n",
    "print(f\"y.dtype: {y.dtype}\")\n",
    "print(f\"y.ndim : {y.ndim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torch Dataset\n",
    "<!-- <ul> -->\n",
    "<p style=\"font-family: consolas;\">TensorDataset : <span style=\"color: tomato\">torch.utils.data.TensorDataset</span> does inherit from <span style=\"color: cyan\">torch.utils.data.Dataset</span></p>\n",
    "<!-- </ul> -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset.tensors[0].shape : torch.Size([150, 4])\n",
      "dataset.tensors[1].shape : torch.Size([150, 1])\n",
      "--------------------------------------------------\n",
      "first sample:\n",
      "    -> x: tensor([5.1000, 3.5000, 1.4000, 0.2000])\n",
      "    -> y: tensor([0.])\n"
     ]
    }
   ],
   "source": [
    "# a torch dataset\n",
    "dataset = torch.utils.data.TensorDataset(x, y)\n",
    "\n",
    "# log\n",
    "print(f\"dataset.tensors[0].shape : {dataset.tensors[0].shape}\")\n",
    "print(f\"dataset.tensors[1].shape : {dataset.tensors[1].shape}\")\n",
    "print('-' * 50)\n",
    "print(f\"first sample:\")\n",
    "print(f\"    -> x: {dataset[0][0]}\")\n",
    "print(f\"    -> y: {dataset[0][1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torch DataLoader\n",
    "<ul>\n",
    "    <li>\n",
    "        A DataLoader(<span style=\"font-family: consolas;color: tomato;\">torch.utils.data.DataLoader</span>) is a utility that enables:\n",
    "        <ul>\n",
    "            <li>efficient loading datasets,</li>\n",
    "            <li>handling batching,</li>\n",
    "            <li>shuffling,</li>\n",
    "            <li>parallel data loading</li>\n",
    "        </ul>for training and evaluation in deep learning tasks.\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strategies for updating weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Stochastic Gradient Descent\n",
    "   - the model updates its weights after processing each individual sample from the training dataset.\n",
    "   - it is computationally efficient but can lead to noisy updates due to the variance in individual samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| #Epoch | batch size | #batch per epoch                    | #iteration per epoch                |\n",
    "|:------:|:----------:|:-----------------------------------:|:-----------------------------------:|\n",
    "| $ 2 $  | $ 1 $      | $ \\lceil\\frac{150}{1}\\rceil = 150 $ | $ \\lceil\\frac{150}{1}\\rceil = 150 $ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2\n",
    "batch_size = 1\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "# log\n",
    "for epoch in range(epochs):\n",
    "    print(f\"epoch {epoch}\")\n",
    "    for i, (x, y) in enumerate(dataloader):\n",
    "        print(f\"    iteration {i}\")\n",
    "        print(f\"        x.shape: {x.shape}\")\n",
    "        print(f\"        y.shape: {y.shape}\")\n",
    "        print(\"    weights are updated.\\n\")\n",
    "    print(f\"model saw the entire dataset\")\n",
    "    print('-' * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Batch Gradient Descent\n",
    "   - the model updates its weights after processing the entire training dataset (all samples).\n",
    "   - this method provides a more stable update direction, but it can be computationally expensive for large datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| #Epoch | batch size | #batch per epoch                    | #iteration per epoch                |\n",
    "|:------:|:----------:|:-----------------------------------:|:-----------------------------------:|\n",
    "| $ 2 $  | $ 150 $    | $ \\lceil\\frac{150}{150}\\rceil = 1 $ | $ \\lceil\\frac{150}{150}\\rceil = 1 $ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2\n",
    "batch_size = dataset.tensors[0].shape[0]\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "# log\n",
    "for epoch in range(epochs):\n",
    "    print(f\"epoch {epoch}\")\n",
    "    for i, (x, y) in enumerate(dataloader):\n",
    "        print(f\"    iteration {i}\")\n",
    "        print(f\"        x.shape: {x.shape}\")\n",
    "        print(f\"        y.shape: {y.shape}\")\n",
    "        print(\"    weights are updated.\\n\")\n",
    "    print(f\"model saw the entire dataset\")\n",
    "    print('-' * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Mini-Batch Gradient Descent\n",
    "   - the model updates its weights after processing a small batch of 'm' samples from the training dataset.\n",
    "   - this method combines the advantages of both SGD and Batch Gradient Descent by providing a balance between efficiency and stability during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| #Epoch | batch size | #batch per epoch                 | #iteration per epoch              |\n",
    "|:------:|:----------:|:--------------------------------:|:---------------------------------:|\n",
    "| $ 2 $  | $ 4 $    | $ \\lceil\\frac{150}{4}\\rceil = 38 $ | $ \\lceil\\frac{150}{4}\\rceil = 38 $ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2\n",
    "batch_size = 4\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "# log\n",
    "for epoch in range(epochs):\n",
    "    print(f\"epoch {epoch}\")\n",
    "    for i, (x, y) in enumerate(dataloader):\n",
    "        print(f\"    iteration {i}\")\n",
    "        print(f\"        x.shape: {x.shape}\")\n",
    "        print(f\"        y.shape: {y.shape}\")\n",
    "        print(\"    weights are updated.\\n\")\n",
    "    print(f\"model saw the entire dataset\")\n",
    "    print('-' * 50)"
   ]
  }
 ],
 "metadata": {
  "author_email": "AmirhosseinHeydari78@gmail.com",
  "author_github": "https://github.com/mr-pylin",
  "author_name": "Amirhossein Heydari",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "origin_repo": "https://github.com/mr-pylin/pytorch-workshop"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
