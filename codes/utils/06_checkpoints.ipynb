{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìù **Author:** Amirhossein Heydari - üìß **Email:** amirhosseinheydari78@gmail.com - üìç **Linktree:** [linktr.ee/mr_pylin](https://linktr.ee/mr_pylin)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consider An Initialized Model As Trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=4, out_features=2, bias=True)\n",
      "  (1): Sigmoid()\n",
      "  (2): Linear(in_features=2, out_features=1, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "trained_model = nn.Sequential(\n",
    "    nn.Linear(4, 2),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(2, 1),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "# log\n",
    "print(trained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Sequential                               [16, 1]                   --\n",
       "‚îú‚îÄLinear: 1-1                            [16, 2]                   10\n",
       "‚îú‚îÄSigmoid: 1-2                           [16, 2]                   --\n",
       "‚îú‚îÄLinear: 1-3                            [16, 1]                   3\n",
       "‚îú‚îÄSigmoid: 1-4                           [16, 1]                   --\n",
       "==========================================================================================\n",
       "Total params: 13\n",
       "Trainable params: 13\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 0.00\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.00\n",
       "Params size (MB): 0.00\n",
       "Estimated Total Size (MB): 0.00\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(trained_model, input_size=(16, 4), device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights (layer 1):\n",
      "tensor([[ 0.1658, -0.3584, -0.0057, -0.3216],\n",
      "        [ 0.2297,  0.4038, -0.1256,  0.3223]], requires_grad=True)\n",
      "\n",
      "biases (layer 1):\n",
      "tensor([-0.1368, -0.4269], requires_grad=True)\n",
      "\n",
      "weights (layer 2):\n",
      "tensor([[0.7063, 0.4341]], requires_grad=True)\n",
      "\n",
      "biases (layer 2):\n",
      "tensor([0.2903], requires_grad=True)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# weights and biases per layer (using model.parameters())\n",
    "for i, param in enumerate(trained_model.parameters()):\n",
    "    if i % 2 == 0:  # weights of the model\n",
    "        print(str(param).replace(\"Parameter containing:\", f\"weights (layer {i // 2 + 1}):\"), end='\\n\\n')\n",
    "    else:  # biases of the model\n",
    "        print(str(param).replace(\"Parameter containing:\", f\"biases (layer {(i-1) // 2 + 1}):\"), end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('0.weight', tensor([[ 0.1658, -0.3584, -0.0057, -0.3216],\n",
      "        [ 0.2297,  0.4038, -0.1256,  0.3223]]))\n",
      "('0.bias', tensor([-0.1368, -0.4269]))\n",
      "('2.weight', tensor([[0.7063, 0.4341]]))\n",
      "('2.bias', tensor([0.2903]))\n"
     ]
    }
   ],
   "source": [
    "# weights and biases per layer (using model.state_dict())\n",
    "for param in trained_model.state_dict().items():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save & Load\n",
    "   - The extension `.pth` has no specific meaning to PyTorch internally.\n",
    "   - `.pth` (or sometimes `.pt`) is used conventionally to indicate the file contains a PyTorch model or parameters.\n",
    "\n",
    "üìù **Docs & Tutorials** üìö:\n",
    "   - torch.save: [pytorch.org/docs/stable/generated/torch.save.html](https://pytorch.org/docs/stable/generated/torch.save.html)\n",
    "   - torch.load: [pytorch.org/docs/stable/generated/torch.load.html](https://pytorch.org/docs/stable/generated/torch.load.html)\n",
    "   - Saving and Loading Models: [pytorch.org/tutorials/beginner/saving_loading_models.html](https://pytorch.org/tutorials/beginner/saving_loading_models.html)\n",
    "   - Save and Load the Model: [pytorch.org/tutorials/beginner/basics/saveloadrun_tutorial.html](https://pytorch.org/tutorials/beginner/basics/saveloadrun_tutorial.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save and Load ONLY Parameters\n",
    "   - This is the recommended approach.\n",
    "   - Model architecture can be defined separately and changed without issues\n",
    "   - Efficient for saving memory and storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get model parameters\n",
    "trained_model_parameters = trained_model.state_dict()\n",
    "\n",
    "# save\n",
    "torch.save(obj=trained_model_parameters, f='../../assets/models/model_1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('0.weight',\n",
       "              tensor([[-0.4132, -0.3434, -0.2125,  0.4822],\n",
       "                      [-0.4512,  0.3472,  0.4492, -0.4743]])),\n",
       "             ('0.bias', tensor([-0.4894, -0.4634])),\n",
       "             ('2.weight', tensor([[-0.3045,  0.6727]])),\n",
       "             ('2.bias', tensor([-0.1564]))])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load\n",
    "weights = torch.load(f='../../assets/models/model_1.pth', weights_only=True)\n",
    "\n",
    "# log\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('0.weight', tensor([[-0.4132, -0.3434, -0.2125,  0.4822],\n",
      "        [-0.4512,  0.3472,  0.4492, -0.4743]]))\n",
      "('0.bias', tensor([-0.4894, -0.4634]))\n",
      "('2.weight', tensor([[-0.3045,  0.6727]]))\n",
      "('2.bias', tensor([-0.1564]))\n"
     ]
    }
   ],
   "source": [
    "# insert weights to the model\n",
    "model_1 = nn.Sequential(\n",
    "    nn.Linear(4, 2),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(2, 1),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "model_1.load_state_dict(weights)\n",
    "\n",
    "# log\n",
    "for param in model_1.state_dict().items():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save & Load the ENTIRE Model\n",
    "   - ‚úÖ Easier to use since you don‚Äôt need to redefine the model architecture.\n",
    "   - ‚ö†Ô∏è Not portable across different PyTorch versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=4, out_features=2, bias=True)\n",
       "  (1): Sigmoid()\n",
       "  (2): Linear(in_features=2, out_features=1, bias=True)\n",
       "  (3): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save\n",
    "torch.save(obj=trained_model, f='../../assets/models/model_2.pth')\n",
    "\n",
    "# load\n",
    "model_2 = torch.load(f='../../assets/models/model_2.pth', weights_only=False)\n",
    "\n",
    "# log\n",
    "model_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('0.weight', tensor([[-0.4132, -0.3434, -0.2125,  0.4822],\n",
      "        [-0.4512,  0.3472,  0.4492, -0.4743]]))\n",
      "('0.bias', tensor([-0.4894, -0.4634]))\n",
      "('2.weight', tensor([[-0.3045,  0.6727]]))\n",
      "('2.bias', tensor([-0.1564]))\n"
     ]
    }
   ],
   "source": [
    "# log\n",
    "for param in model_2.state_dict().items():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving & Loading a General Checkpoint for Inference and/or Resuming Training\n",
    "   - you can save a checkpoint whenever you are training the model at each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 10\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(params=trained_model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save both model and optimizer state_dict for resuming training\n",
    "torch.save(\n",
    "    obj={\n",
    "        'model_state_dict': trained_model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'epoch': epoch,  # Save the epoch to resume training\n",
    "        'criterion': criterion  # Optional, save the last loss\n",
    "    },\n",
    "    f='../../assets/models/model_3.pth'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the checkpoint\n",
    "checkpoint = torch.load('../../assets/models/model_3.pth', weights_only=False)\n",
    "\n",
    "# model\n",
    "model_3 = nn.Sequential(\n",
    "    nn.Linear(4, 2),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(2, 1),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "# optimizer\n",
    "optimizer = optim.SGD(model_3.parameters(), lr=0.01)\n",
    "\n",
    "# insert values\n",
    "model_3.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "criterion = checkpoint['criterion']\n",
    "epoch = checkpoint['epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('0.weight', tensor([[-0.4132, -0.3434, -0.2125,  0.4822],\n",
      "        [-0.4512,  0.3472,  0.4492, -0.4743]]))\n",
      "('0.bias', tensor([-0.4894, -0.4634]))\n",
      "('2.weight', tensor([[-0.3045,  0.6727]]))\n",
      "('2.bias', tensor([-0.1564]))\n"
     ]
    }
   ],
   "source": [
    "# log\n",
    "for param in model_3.state_dict().items():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    differentiable: False\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# log\n",
    "print(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 10\n"
     ]
    }
   ],
   "source": [
    "# log\n",
    "print(f\"epoch : {epoch}\")"
   ]
  }
 ],
 "metadata": {
  "author_email": "AmirhosseinHeydari78@gmail.com",
  "author_github": "https://github.com/mr-pylin",
  "author_name": "Amirhossein Heydari",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "origin_repo": "https://github.com/mr-pylin/pytorch-workshop"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
