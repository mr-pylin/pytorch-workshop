{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìù **Author:** Amirhossein Heydari - üìß **Email:** amirhosseinheydari78@gmail.com - üìç **Linktree:** [linktr.ee/mr_pylin](https://linktr.ee/mr_pylin)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Classes in PyTorch\n",
    "   - **PyTorch** is a **flexible** deep learning framework that allows developers to **customize** different components according to their **specific needs**.\n",
    "   - This flexibility is essential for **implementing** custom **datasets**, **models**, and **optimization** routines, which may not be covered by the **built-in classes**.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Breast Cancer Wisconsin (Diagnostic) Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>radius1</th>\n",
       "      <th>texture1</th>\n",
       "      <th>perimeter1</th>\n",
       "      <th>area1</th>\n",
       "      <th>smoothness1</th>\n",
       "      <th>compactness1</th>\n",
       "      <th>concavity1</th>\n",
       "      <th>concave_points1</th>\n",
       "      <th>...</th>\n",
       "      <th>radius3</th>\n",
       "      <th>texture3</th>\n",
       "      <th>perimeter3</th>\n",
       "      <th>area3</th>\n",
       "      <th>smoothness3</th>\n",
       "      <th>compactness3</th>\n",
       "      <th>concavity3</th>\n",
       "      <th>concave_points3</th>\n",
       "      <th>symmetry3</th>\n",
       "      <th>fractal_dimension3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID Diagnosis  radius1  texture1  perimeter1   area1  smoothness1  \\\n",
       "0    842302         M    17.99     10.38      122.80  1001.0      0.11840   \n",
       "1    842517         M    20.57     17.77      132.90  1326.0      0.08474   \n",
       "2  84300903         M    19.69     21.25      130.00  1203.0      0.10960   \n",
       "3  84348301         M    11.42     20.38       77.58   386.1      0.14250   \n",
       "4  84358402         M    20.29     14.34      135.10  1297.0      0.10030   \n",
       "\n",
       "   compactness1  concavity1  concave_points1  ...  radius3  texture3  \\\n",
       "0       0.27760      0.3001          0.14710  ...    25.38     17.33   \n",
       "1       0.07864      0.0869          0.07017  ...    24.99     23.41   \n",
       "2       0.15990      0.1974          0.12790  ...    23.57     25.53   \n",
       "3       0.28390      0.2414          0.10520  ...    14.91     26.50   \n",
       "4       0.13280      0.1980          0.10430  ...    22.54     16.67   \n",
       "\n",
       "   perimeter3   area3  smoothness3  compactness3  concavity3  concave_points3  \\\n",
       "0      184.60  2019.0       0.1622        0.6656      0.7119           0.2654   \n",
       "1      158.80  1956.0       0.1238        0.1866      0.2416           0.1860   \n",
       "2      152.50  1709.0       0.1444        0.4245      0.4504           0.2430   \n",
       "3       98.87   567.7       0.2098        0.8663      0.6869           0.2575   \n",
       "4      152.20  1575.0       0.1374        0.2050      0.4000           0.1625   \n",
       "\n",
       "   symmetry3  fractal_dimension3  \n",
       "0     0.4601             0.11890  \n",
       "1     0.2750             0.08902  \n",
       "2     0.3613             0.08758  \n",
       "3     0.6638             0.17300  \n",
       "4     0.2364             0.07678  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breast_cancer_dataset_url = r\"https://github.com/mr-pylin/datasets/raw/refs/heads/main/data/tabular-data/breast-cancer-wisconsin-diagnostic/dataset.csv\"\n",
    "\n",
    "# pandas data-frame\n",
    "df = pd.read_csv(breast_cancer_dataset_url, encoding='utf-8')\n",
    "\n",
    "# log\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: (569, 30)\n",
      "X.dtype: float64\n",
      "y.shape: (569,)\n",
      "y.dtype: int32\n",
      "--------------------------------------------------\n",
      "classes          : [0 1]\n",
      "samples per class: [212 357]\n"
     ]
    }
   ],
   "source": [
    "classes = df['Diagnosis'].unique()\n",
    "class_to_idx = {l: i for i, l in enumerate(classes)}\n",
    "\n",
    "# split dataset into features and labels\n",
    "X, y = df.iloc[:, 2:].values, df.iloc[:, 1].values\n",
    "\n",
    "# convert categorical labels into indices\n",
    "y = np.array([class_to_idx[l] for l in y])\n",
    "\n",
    "# properties of the dataset\n",
    "num_samples, num_features = X.shape\n",
    "classes, samples_per_class = np.unique(y, return_counts=True)\n",
    "\n",
    "# log\n",
    "print(f\"X.shape: {X.shape}\")\n",
    "print(f\"X.dtype: {X.dtype}\")\n",
    "print(f\"y.shape: {y.shape}\")\n",
    "print(f\"y.dtype: {y.dtype}\")\n",
    "print('-' * 50)\n",
    "print(f\"classes          : {classes}\")\n",
    "print(f\"samples per class: {samples_per_class}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Dataset\n",
    "   - PyTorch‚Äôs `Dataset` class can be easily subclassed to define custom datasets\n",
    "   - This allows you to load and preprocess your data according to your needs.\n",
    "   - Use `torch.utils.data.Dataset` as the parent class and override `__len__` and `__getitem__`.\n",
    "\n",
    "üìù **Docs & Tutorials** üìö:\n",
    "   - Data Loading Utility: [pytorch.org/docs/stable/data.html](https://pytorch.org/docs/stable/data.html)\n",
    "   - Datasets & DataLoaders: [pytorch.org/tutorials/beginner/basics/data_tutorial.html](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(X): <class 'torch.Tensor'>  |  X.dtype: torch.float32  |  X.shape: torch.Size([569, 30])\n",
      "type(y): <class 'torch.Tensor'>  |  y.dtype: torch.float32  |  y.shape: torch.Size([569, 1])\n"
     ]
    }
   ],
   "source": [
    "# convert numpy.ndarray to torch.Tensor\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# log\n",
    "print(f\"type(X): {type(X)}  |  X.dtype: {X.dtype}  |  X.shape: {X.shape}\")\n",
    "print(f\"type(y): {type(y)}  |  y.dtype: {y.dtype}  |  y.shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data: torch.Tensor, labels: torch.Tensor) -> None:\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index: int) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        return self.data[index], self.labels[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(dataset_1) : <class '__main__.CustomDataset'>\n",
      "len(dataset_1)  : 569\n",
      "dataset_1[0]    : (tensor([1.7990e+01, 1.0380e+01, 1.2280e+02, 1.0010e+03, 1.1840e-01, 2.7760e-01,\n",
      "        3.0010e-01, 1.4710e-01, 2.4190e-01, 7.8710e-02, 1.0950e+00, 9.0530e-01,\n",
      "        8.5890e+00, 1.5340e+02, 6.3990e-03, 4.9040e-02, 5.3730e-02, 1.5870e-02,\n",
      "        3.0030e-02, 6.1930e-03, 2.5380e+01, 1.7330e+01, 1.8460e+02, 2.0190e+03,\n",
      "        1.6220e-01, 6.6560e-01, 7.1190e-01, 2.6540e-01, 4.6010e-01, 1.1890e-01]), tensor([0.]))\n",
      "--------------------------------------------------\n",
      "type(dataset_2) : <class 'torch.utils.data.dataset.TensorDataset'>\n",
      "len(dataset_2)  : 569\n",
      "dataset_2[0]    : (tensor([1.7990e+01, 1.0380e+01, 1.2280e+02, 1.0010e+03, 1.1840e-01, 2.7760e-01,\n",
      "        3.0010e-01, 1.4710e-01, 2.4190e-01, 7.8710e-02, 1.0950e+00, 9.0530e-01,\n",
      "        8.5890e+00, 1.5340e+02, 6.3990e-03, 4.9040e-02, 5.3730e-02, 1.5870e-02,\n",
      "        3.0030e-02, 6.1930e-03, 2.5380e+01, 1.7330e+01, 1.8460e+02, 2.0190e+03,\n",
      "        1.6220e-01, 6.6560e-01, 7.1190e-01, 2.6540e-01, 4.6010e-01, 1.1890e-01]), tensor([0.]))\n"
     ]
    }
   ],
   "source": [
    "# create a pytorch dataset\n",
    "dataset_1 = CustomDataset(X, y)  # custom\n",
    "dataset_2 = TensorDataset(X, y)  # built-in\n",
    "\n",
    "# log\n",
    "print(f\"type(dataset_1) : {type(dataset_1)}\")\n",
    "print(f\"len(dataset_1)  : {len(dataset_1)}\")\n",
    "print(f\"dataset_1[0]    : {dataset_1[0]}\")\n",
    "print('-' * 50)\n",
    "print(f\"type(dataset_2) : {type(dataset_2)}\")\n",
    "print(f\"len(dataset_2)  : {len(dataset_2)}\")\n",
    "print(f\"dataset_2[0]    : {dataset_2[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Transform\n",
    "   - Transforms are used to modify the input data before feeding it into the model.\n",
    "   - PyTorch provides a lot of built-in transforms (like cropping, flipping, etc.) in `torchvision.transforms`.\n",
    "   - you can define your own transformation by implementing the `__call__` method.\n",
    "\n",
    "üìù **Docs & Tutorials** üìö:\n",
    "   - Transforming and augmenting images: [pytorch.org/vision/stable/transforms.html](https://pytorch.org/vision/stable/transforms.html)\n",
    "   - Transforms: [pytorch.org/tutorials/beginner/basics/transforms_tutorial.html](https://pytorch.org/tutorials/beginner/basics/transforms_tutorial.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumpyToTensor():\n",
    "    def __call__(self, sample: np.ndarray) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        converted_sample = torch.tensor(sample[0], dtype=torch.float32), torch.tensor(sample[1], dtype=torch.float32)\n",
    "        return converted_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NormalizeTo01():\n",
    "    def __init__(self) -> None:\n",
    "        self.min_val = None\n",
    "        self.max_val = None\n",
    "\n",
    "    def fit(self, data: np.ndarray) -> None:\n",
    "        self.min_val = np.min(data, axis=0).astype(np.float32)\n",
    "        self.max_val = np.max(data, axis=0).astype(np.float32)\n",
    "\n",
    "    def __call__(self, sample: tuple[torch.Tensor, torch.Tensor]):\n",
    "        normalized_sample = (sample[0] - self.min_val) / (self.max_val - self.min_val), sample[1]\n",
    "        return normalized_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Direct transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset : [(array([1, 2, 3]), array([0])), (array([5, 1, 2]), array([0])), (array([3, 3, 3]), array([1]))]\n"
     ]
    }
   ],
   "source": [
    "# dataset\n",
    "X = np.array([[1, 2, 3], [5, 1, 2], [3, 3, 3]])\n",
    "y = np.array([[0], [0], [1]])\n",
    "dataset = list(zip(X, y))\n",
    "\n",
    "# log\n",
    "print(f\"dataset : {dataset}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result          : (tensor([0.0000, 0.5000, 1.0000]), tensor([0.]))\n",
      "result[0].dtype : torch.float32\n",
      "result[1].dtype : torch.float32\n"
     ]
    }
   ],
   "source": [
    "# NumpyToTensor\n",
    "t_totensor = NumpyToTensor()\n",
    "\n",
    "# NormalizeTo01\n",
    "t_normalize = NormalizeTo01()\n",
    "t_normalize.fit(X)\n",
    "\n",
    "# transform the first input\n",
    "result = t_normalize(t_totensor(dataset[0]))\n",
    "\n",
    "# log\n",
    "print(f\"result          : {result}\")\n",
    "print(f\"result[0].dtype : {result[0].dtype}\")\n",
    "print(f\"result[1].dtype : {result[1].dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integrated transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# advanced Dataset with transform support\n",
    "class AdvancedCustomDataset(Dataset):\n",
    "    def __init__(self, data, labels, transform=None):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "        # if NormalizeTo01 is included, call <fit> method for that\n",
    "        if self.transform:\n",
    "            for t in self.transform.transforms:\n",
    "                if isinstance(t, NormalizeTo01):\n",
    "                    t.fit(self.data)\n",
    "                    break\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sample = self.data[index], self.labels[index]\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset[0]: (tensor([0.0000, 0.5000, 1.0000]), tensor([0.]))\n",
      "    -> input data : tensor([0.0000, 0.5000, 1.0000])\n",
      "    -> label      : tensor([0.])\n",
      "\n",
      "dataset[1]: (tensor([1., 0., 0.]), tensor([0.]))\n",
      "    -> input data : tensor([1., 0., 0.])\n",
      "    -> label      : tensor([0.])\n",
      "\n",
      "dataset[2]: (tensor([0.5000, 1.0000, 1.0000]), tensor([1.]))\n",
      "    -> input data : tensor([0.5000, 1.0000, 1.0000])\n",
      "    -> label      : tensor([1.])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[1, 2, 3], [5, 1, 2], [3, 3, 3]])\n",
    "y = np.array([[0], [0], [1]])\n",
    "\n",
    "transformations = transforms.Compose([\n",
    "    NumpyToTensor(),\n",
    "    NormalizeTo01(),\n",
    "])\n",
    "\n",
    "dataset = AdvancedCustomDataset(X, y, transformations)\n",
    "\n",
    "# log\n",
    "for i in range(len(y)):\n",
    "    print(f\"dataset[{i}]: {dataset[i]}\")\n",
    "    print(f\"    -> input data : {dataset[i][0]}\")\n",
    "    print(f\"    -> label      : {dataset[i][1]}\", end='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Activation Function\n",
    "   - you can create your own activation function by subclassing `torch.nn.Module`.\n",
    "   - Use `torch.nn.Module` as the parent class and implement  `forward` method.\n",
    "\n",
    "üìù **Docs & Tutorials** üìö:\n",
    "   - Non-linear Activations (weighted sum, nonlinearity): [pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity](https://pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity)\n",
    "   - Non-linear Activations (other): [pytorch.org/docs/stable/nn.html#non-linear-activations-other](https://pytorch.org/docs/stable/nn.html#non-linear-activations-other)\n",
    "   - Non-linear activation functions: [pytorch.org/docs/stable/nn.functional.html#non-linear-activation-functions](https://pytorch.org/docs/stable/nn.functional.html#non-linear-activation-functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSigmoid(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomSigmoid, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sig_1(values) : tensor([9.9995e-01, 5.0000e-01, 4.5398e-05])\n",
      "sig_2(values) : tensor([9.9995e-01, 5.0000e-01, 4.5398e-05])\n"
     ]
    }
   ],
   "source": [
    "sig_1 = CustomSigmoid()\n",
    "sig_2 = nn.Sigmoid()\n",
    "\n",
    "values = torch.tensor([10, 0, -10], dtype=torch.float32)\n",
    "\n",
    "# log\n",
    "print(f\"sig_1(values) : {sig_1(values)}\")\n",
    "print(f\"sig_2(values) : {sig_2(values)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Model\n",
    "   - Sequential Model:\n",
    "      - Useful for simpler models where the layers are stacked in a linear sequence\n",
    "      - The `torch.nn.Sequential` class allows you to stack layers in a sequence, passing the output of one layer directly to the next.\n",
    "      - This is great for simple models like fully-connected neural networks or basic CNNs.\n",
    "      - Key Points\n",
    "         - Layers are defined in the order they are passed to `Sequential`.\n",
    "         - You don't need to define the `forward` method manually; PyTorch handles it for you.\n",
    "   - Functional Model:\n",
    "      - Allowing for complex architectures where you might need non-linear layer connections (e.g., skip connections in ResNet)\n",
    "      - models are created by subclassing `torch.nn.Module`.\n",
    "      - This allows you to define any neural network architecture, from simple feedforward networks to complex architectures like GANs or transformers\n",
    "      - Key Points\n",
    "         - Use `torch.nn.Module` as the parent class and implement  `forward` method.\n",
    "\n",
    "üìù **Docs & Tutorials** üìö:\n",
    "   - Module: [pytorch.org/docs/stable/generated/torch.nn.Module.html](https://pytorch.org/docs/stable/generated/torch.nn.Module.html)\n",
    "   - torch.nn: [pytorch.org/docs/stable/nn.html](https://pytorch.org/docs/stable/nn.html)\n",
    "   - Building Models with PyTorch: [pytorch.org/tutorials/beginner/introyt/modelsyt_tutorial.html](https://pytorch.org/tutorials/beginner/introyt/modelsyt_tutorial.html)\n",
    "   - Build the Neural Network: [pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html](https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html)\n",
    "   - Neural Networks: [pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial](https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=30, out_features=16, bias=True)\n",
       "  (1): Sigmoid()\n",
       "  (2): Linear(in_features=16, out_features=1, bias=True)\n",
       "  (3): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a simple sequential model\n",
    "model_1 = nn.Sequential(\n",
    "    nn.Linear(in_features=30, out_features=16),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(in_features=16, out_features=1),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "# log\n",
    "model_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomLogisticRegression(\n",
       "  (fc1): Linear(in_features=30, out_features=16, bias=True)\n",
       "  (sigmoid1): CustomSigmoid()\n",
       "  (fc2): Linear(in_features=16, out_features=1, bias=True)\n",
       "  (sigmoid2): CustomSigmoid()\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a simple functional model\n",
    "class CustomLogisticRegression(nn.Module):\n",
    "    def __init__(self, input_size: int, hidden_size: int, output_size: int) -> None:\n",
    "        super(CustomLogisticRegression, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features=input_size, out_features=hidden_size)\n",
    "        self.sigmoid1 = CustomSigmoid()\n",
    "        self.fc2 = nn.Linear(in_features=hidden_size, out_features=output_size)\n",
    "        self.sigmoid2 = CustomSigmoid()\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.fc1(x)\n",
    "        x = self.sigmoid1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid2(x)\n",
    "        return x\n",
    "\n",
    "# initialize the model\n",
    "model_2 = CustomLogisticRegression(30, 16, 1)\n",
    "\n",
    "# log\n",
    "model_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Loss Function\n",
    "   - PyTorch comes with standard loss functions like MSE, Cross-Entropy, etc.\n",
    "   - you can create your own loss function by subclassing `torch.nn.Module`.\n",
    "   - Use `torch.nn.Module` as the parent class and implement  `forward` method.\n",
    "\n",
    "üìù **Docs & Tutorials** üìö:\n",
    "   - Loss Functions: [pytorch.org/docs/stable/nn.html#loss-functions](https://pytorch.org/docs/stable/nn.html#loss-functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomMSE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomMSE, self).__init__()\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        loss = torch.mean((y_pred - y_true) ** 2)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_1: 0.25902360677719116\n",
      "loss_2: 0.25902360677719116\n"
     ]
    }
   ],
   "source": [
    "# split dataset into (data, labels)\n",
    "X = dataset_1[:][0]\n",
    "y_true = dataset_1[:][1]\n",
    "\n",
    "# feed-forward\n",
    "y_pred = model_1(X)\n",
    "\n",
    "# MSE loss function\n",
    "criterion_1 = CustomMSE()   # custom\n",
    "criterion_2 = nn.MSELoss()  # built-in\n",
    "\n",
    "# compute the loss\n",
    "loss_1 = criterion_1(y_pred, y_true)\n",
    "loss_2 = criterion_2(y_pred, y_true)\n",
    "\n",
    "# log\n",
    "print(f\"loss_1: {loss_1}\")\n",
    "print(f\"loss_2: {loss_2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Optimizer\n",
    "   - PyTorch offers optimizers like SGD, Adam, etc.\n",
    "   - you can create your own optimizer by subclassing `torch.optim.Optimizer`.\n",
    "   - Use `torch.optim.Optimizer` as the parent class and override `step` method.\n",
    "\n",
    "üìù **Docs & Tutorials** üìö:\n",
    "   - torch.optim: [pytorch.org/docs/stable/optim.html](https://pytorch.org/docs/stable/optim.html)\n",
    "   - torch.optim.Optimizer.step: [pytorch.org/docs/stable/generated/torch.optim.Optimizer.step.html](https://pytorch.org/docs/stable/generated/torch.optim.Optimizer.step.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this implementation might not be the same as SGD\n",
    "class CustomSGD(optim.Optimizer):\n",
    "    def __init__(self, params, lr=0.01, momentum=0):\n",
    "        defaults = dict(lr=lr, momentum=momentum)\n",
    "        super(CustomSGD, self).__init__(params, defaults)\n",
    "\n",
    "    def step(self):\n",
    "        for group in self.param_groups:\n",
    "            lr = group['lr']\n",
    "            momentum = group['momentum']\n",
    "\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                d_p = p.grad.data\n",
    "\n",
    "                if momentum != 0:\n",
    "                    param_state = self.state[p]\n",
    "                    if 'momentum_buffer' not in param_state:\n",
    "                        buf = param_state['momentum_buffer'] = torch.zeros_like(p.data)\n",
    "                        buf.mul_(momentum).add_(d_p)\n",
    "                    else:\n",
    "                        buf = param_state['momentum_buffer']\n",
    "                        buf.mul_(momentum).add_(d_p, alpha=1 - momentum)\n",
    "                    d_p = buf\n",
    "\n",
    "                p.data.add_(d_p, alpha=-lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimizer_1:\n",
      "CustomSGD (\n",
      "Parameter Group 0\n",
      "    lr: 0.01\n",
      "    momentum: 0\n",
      ")\n",
      "\n",
      "optimizer_2:\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    differentiable: False\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "optimizer_1 = CustomSGD(model_1.parameters())\n",
    "optimizer_2 = optim.SGD(model_1.parameters())\n",
    "\n",
    "# log\n",
    "print(f\"optimizer_1:\\n{optimizer_1}\\n\")\n",
    "print(f\"optimizer_2:\\n{optimizer_2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: All In One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load breast-cancer dataset\n",
    "X, y = load_breast_cancer(return_X_y=True)\n",
    "\n",
    "# create a custom Dataset class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index], self.labels[index]\n",
    "\n",
    "\n",
    "# convert numpy.ndarray to torch.Tensor\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# create a dataset\n",
    "dataset = CustomDataset(X, y)\n",
    "\n",
    "# create a dataloader\n",
    "dataloader = DataLoader(dataset, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomLogisticRegression(\n",
       "  (fc1): Linear(in_features=30, out_features=2, bias=True)\n",
       "  (sigmoid1): CustomSigmoid()\n",
       "  (fc2): Linear(in_features=2, out_features=1, bias=True)\n",
       "  (sigmoid2): CustomSigmoid()\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# custom sigmoid activation\n",
    "class CustomSigmoid(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomSigmoid, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.sigmoid(x)\n",
    "\n",
    "# model\n",
    "class CustomLogisticRegression(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(CustomLogisticRegression, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features=input_size, out_features=hidden_size)\n",
    "        self.sigmoid1 = CustomSigmoid()\n",
    "        self.fc2 = nn.Linear(in_features=hidden_size, out_features=output_size)\n",
    "        self.sigmoid2 = CustomSigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.sigmoid1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "input_size = X.shape[1]\n",
    "hidden_size = 2\n",
    "output_size = y.shape[1]\n",
    "\n",
    "# model\n",
    "model = CustomLogisticRegression(input_size, hidden_size, output_size)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "epochs = 10\n",
    "lr = 0.005\n",
    "criterion = CustomMSE()\n",
    "optimizer = CustomSGD(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  0  ->  loss: 0.34326 - accuracy: 37.26%\n",
      "epoch  1  ->  loss: 0.34738 - accuracy: 37.26%\n",
      "epoch  2  ->  loss: 0.25628 - accuracy: 37.26%\n",
      "epoch  3  ->  loss: 0.25216 - accuracy: 38.14%\n",
      "epoch  4  ->  loss: 0.24787 - accuracy: 62.74%\n",
      "epoch  5  ->  loss: 0.24429 - accuracy: 62.74%\n",
      "epoch  6  ->  loss: 0.24261 - accuracy: 62.74%\n",
      "epoch  7  ->  loss: 0.24102 - accuracy: 62.74%\n",
      "epoch  8  ->  loss: 0.23829 - accuracy: 62.74%\n",
      "epoch  9  ->  loss: 0.23698 - accuracy: 62.74%\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "model.train()\n",
    "total_loss = []\n",
    "total_acc = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    for x, y_true in dataloader:\n",
    "\n",
    "        # forward\n",
    "        y_pred = model(x)\n",
    "        loss = criterion(y_pred, y_true)\n",
    "\n",
    "        # backward\n",
    "        loss.backward()\n",
    "\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # store loss & accuracy\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += ((y_pred > .5).float() == y_true).sum().item()\n",
    "\n",
    "    total_loss.append(epoch_loss / len(dataloader))\n",
    "    total_acc.append(epoch_acc / len(X))\n",
    "\n",
    "    # log\n",
    "    print(f\"epoch {epoch:>2}  ->  loss: {total_loss[-1]:.5f} - accuracy: {total_acc[-1] * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "author_email": "AmirhosseinHeydari78@gmail.com",
  "author_github": "https://github.com/mr-pylin",
  "author_name": "Amirhossein Heydari",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "origin_repo": "https://github.com/mr-pylin/pytorch-workshop"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
