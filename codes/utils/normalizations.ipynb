{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "üìù **Author:** Amirhossein Heydari - üìß **Email:** <amirhosseinheydari78@gmail.com> - üìç **Origin:** [mr-pylin/pytorch-workshop](https://github.com/mr-pylin/pytorch-workshop)\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Table of contents**<a id='toc0_'></a>    \n",
        "- [Dependencies](#toc1_)    \n",
        "- [Dataset Normalization](#toc2_)    \n",
        "  - [Min-Max](#toc2_1_)    \n",
        "  - [Z-score](#toc2_2_)    \n",
        "- [Network Normalization](#toc3_)    \n",
        "  - [Batch Normalization](#toc3_1_)    \n",
        "  - [Layer Normalization](#toc3_2_)    \n",
        "  - [Instance Normalization](#toc3_3_)    \n",
        "  - [Group Normalization](#toc3_4_)    \n",
        "\n",
        "<!-- vscode-jupyter-toc-config\n",
        "\tnumbering=false\n",
        "\tanchor=true\n",
        "\tflat=false\n",
        "\tminLevel=1\n",
        "\tmaxLevel=6\n",
        "\t/vscode-jupyter-toc-config -->\n",
        "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# <a id='toc1_'></a>[Dependencies](#toc0_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torchvision.transforms import v2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# <a id='toc2_'></a>[Dataset Normalization](#toc0_)\n",
        "\n",
        "- Min-Max normalization\n",
        "- Z-score normalization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainset = CIFAR10(\"../../datasets\", train=True, transform=None, download=False)\n",
        "\n",
        "# log\n",
        "print(f\"trainset.data.shape : {trainset.data.shape}\")\n",
        "print(f\"trainset.data.dtype : {trainset.data.dtype}\")\n",
        "print(f\"type(trainset.data) : {type(trainset.data)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## <a id='toc2_1_'></a>[Min-Max](#toc0_)\n",
        "\n",
        "- there is no any built-in feature for this type of normalization in pytorch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "min_value = trainset.data.min(axis=(0, 1, 2))\n",
        "max_value = trainset.data.max(axis=(0, 1, 2))\n",
        "\n",
        "# log\n",
        "print(f\"Minimum values per channel : {min_value}\")\n",
        "print(f\"Maximum values per channel : {max_value}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# normalize to the range: (0, 1)\n",
        "minmax_trainset_1 = (trainset.data - min_value) / (max_value - min_value)\n",
        "\n",
        "# normalize to the range: (-1, 1)\n",
        "minmax_trainset_2 = minmax_trainset_1 * 2 - 1\n",
        "\n",
        "# log\n",
        "print(f\"Minimum values for minmax_trainset_1 : {minmax_trainset_1.min(axis=(0, 1, 2))}\")\n",
        "print(f\"Maximum values for minmax_trainset_1 : {minmax_trainset_1.max(axis=(0, 1, 2))}\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"Minimum values for minmax_trainset_2 : {minmax_trainset_2.min(axis=(0, 1, 2))}\")\n",
        "print(f\"Maximum values for minmax_trainset_2 : {minmax_trainset_2.max(axis=(0, 1, 2))}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## <a id='toc2_2_'></a>[Z-score](#toc0_)\n",
        "\n",
        "- there is no any built-in feature for this type of normalization in pytorch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mean_value = trainset.data.mean(axis=(0, 1, 2))\n",
        "std_value = trainset.data.std(axis=(0, 1, 2))\n",
        "\n",
        "# log\n",
        "print(f\"Mean values per channel : {mean_value}\")\n",
        "print(f\"STD values per channel  : {std_value}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# standardize with mean:0 and std:1\n",
        "zscore_trainset_1 = (trainset.data - mean_value) / std_value\n",
        "\n",
        "# standardize with mean:2 and std:5\n",
        "zscore_trainset_2 = zscore_trainset_1 * 5 + 2\n",
        "\n",
        "# log\n",
        "print(f\"Mean values for minmax_trainset_1 : {zscore_trainset_1.mean(axis=(0, 1, 2))}\")\n",
        "print(f\"STD values for minmax_trainset_1  : {zscore_trainset_1.std(axis=(0, 1, 2))}\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"Mean values for minmax_trainset_2 : {zscore_trainset_2.mean(axis=(0, 1, 2))}\")\n",
        "print(f\"STD values for minmax_trainset_2  : {zscore_trainset_2.std(axis=(0, 1, 2))}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# <a id='toc3_'></a>[Network Normalization](#toc0_)\n",
        "\n",
        "- Batch normalization\n",
        "- Layer normalization\n",
        "- Instance normalization\n",
        "- group normalization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "transform = v2.Compose(\n",
        "    [\n",
        "        v2.ToImage(),\n",
        "        v2.ToDtype(torch.float32, scale=True),\n",
        "    ]\n",
        ")\n",
        "\n",
        "trainset = CIFAR10(\"../../datasets\", train=True, transform=transform, download=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_size = 8\n",
        "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "first_batch = next(iter(trainloader))[0]\n",
        "\n",
        "# log\n",
        "print(f\"first_batch.shape : {first_batch.shape}\")\n",
        "print(f\"first_batch.dtype : {first_batch.dtype}\")\n",
        "print(f\"type.first_batch) : {type(first_batch)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "in_channels = first_batch.shape[1]\n",
        "out_channels = 16\n",
        "\n",
        "model = torch.nn.Sequential(torch.nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=3))\n",
        "\n",
        "features_maps = model(first_batch)\n",
        "\n",
        "# log\n",
        "print(f\"features_maps.shape : {features_maps.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## <a id='toc3_1_'></a>[Batch Normalization](#toc0_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "bn_mean = features_maps.mean(dim=(0, 2, 3), keepdim=True)\n",
        "bn_std = features_maps.std(dim=(0, 2, 3), keepdim=True)\n",
        "\n",
        "bn_result_1 = (features_maps - bn_mean) / bn_std\n",
        "bn_result_2 = torch.nn.BatchNorm2d(out_channels, affine=False, eps=0)(features_maps)\n",
        "\n",
        "# log\n",
        "print(f\"bn_mean.shape : {bn_mean.shape}\")\n",
        "print(f\"bn_std.shape  : {bn_std.shape}\")\n",
        "print(torch.allclose(bn_result_1, bn_result_2, atol=1e-03))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## <a id='toc3_2_'></a>[Layer Normalization](#toc0_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ln_mean = features_maps.mean(dim=(1, 2, 3), keepdim=True)\n",
        "ln_std = features_maps.std(dim=(1, 2, 3), keepdim=True)\n",
        "\n",
        "ln_result_1 = (features_maps - ln_mean) / ln_std\n",
        "ln_result_2 = torch.nn.LayerNorm(features_maps.shape[1:], elementwise_affine=False, eps=0)(features_maps)\n",
        "\n",
        "# log\n",
        "print(f\"ln_mean.shape : {ln_mean.shape}\")\n",
        "print(f\"ln_std.shape  : {ln_std.shape}\")\n",
        "print(torch.allclose(ln_result_1, ln_result_2, atol=1e-03))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## <a id='toc3_3_'></a>[Instance Normalization](#toc0_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "in_mean = features_maps.mean(dim=(2, 3), keepdim=True)\n",
        "in_std = features_maps.std(dim=(2, 3), keepdim=True)\n",
        "\n",
        "in_result_1 = (features_maps - in_mean) / in_std\n",
        "in_result_2 = torch.nn.InstanceNorm2d(out_channels, affine=False, eps=0)(features_maps)\n",
        "\n",
        "# log\n",
        "print(f\"in_mean.shape : {in_mean.shape}\")\n",
        "print(f\"in_std.shape  : {in_std.shape}\")\n",
        "print(torch.allclose(in_result_1, in_result_2, atol=1e-02))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## <a id='toc3_4_'></a>[Group Normalization](#toc0_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "groups = [features_maps[:, :8, :, :], features_maps[:, 8:, :, :]]\n",
        "\n",
        "gn_mean_1 = groups[0].mean(dim=(1, 2, 3), keepdim=True)\n",
        "gn_std_1 = groups[0].std(dim=(1, 2, 3), keepdim=True)\n",
        "result_1 = (groups[0] - gn_mean_1) / gn_std_1\n",
        "\n",
        "gn_mean_2 = groups[1].mean(dim=(1, 2, 3), keepdim=True)\n",
        "gn_std_2 = groups[1].std(dim=(1, 2, 3), keepdim=True)\n",
        "result_2 = (groups[1] - gn_mean_2) / gn_std_2\n",
        "\n",
        "gn_result_1 = torch.concatenate([result_1, result_2], dim=1)\n",
        "gn_result_2 = torch.nn.GroupNorm(num_groups=2, num_channels=out_channels, affine=False)(features_maps)\n",
        "\n",
        "# log\n",
        "print(f\"gn_mean_1.shape : {gn_mean_1.shape}\")\n",
        "print(f\"gn_std_1.shape  : {gn_std_1.shape}\")\n",
        "print(f\"gn_mean_2.shape : {gn_mean_2.shape}\")\n",
        "print(f\"gn_std_2.shape  : {gn_std_2.shape}\")\n",
        "print(torch.allclose(gn_result_1, gn_result_2, atol=1e-03))"
      ]
    }
  ],
  "metadata": {
    "author_email": "AmirhosseinHeydari78@gmail.com",
    "author_github": "https://github.com/mr-pylin",
    "author_name": "Amirhossein Heydari",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "origin_repo": "https://github.com/mr-pylin/pytorch-workshop"
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
